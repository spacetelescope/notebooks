{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hubble Source Catalog SWEEPS Proper Motion Notebook\n",
    "### 2019 - 2022, Steve Lubow, Rick White, Trenton McKinney\n",
    "\n",
    "A [new MAST interface][1] supports queries to the current and previous versions of the [Hubble Source Catalog][2]. It allows searches of the summary table (with multi-filter mean photometry) and the detailed table (with all the multi-epoch measurements). It also has an associated [API][3], which is used in this notebook.\n",
    "\n",
    "The [web-based user interface][4] to the HSC does not currently include access to the new proper motions available for the [SWEEPS][5] field in version 3.1 of the [Hubble Source Catalog][2]. However those tables are accessible via the API. This notebook shows how to use them.\n",
    "\n",
    "This notebook is similar to the [previously released version][6] that uses CasJobs rather than the new API. The Casjobs interface is definitely more powerful and flexible, but the API is simpler to use for users who are not already experienced Casjobs users. Currently the API does not include easy access to the colors and magnitudes of the SWEEPS objects, but they will be added soon.\n",
    "\n",
    "Additional information is available on the [SWEEPS Proper Motions help page][7].\n",
    "\n",
    "A notebook that provides a quick introduction to the HSC API is also [available][8]. Another [notebook][9] generates a color-magnitude diagram for the Small Magellanic Cloud in only a couple of minutes.\n",
    "\n",
    "\n",
    "  [1]: https://catalogs.mast.stsci.edu/hsc\n",
    "  [2]: https://archive.stsci.edu/hst/hsc\n",
    "  [3]: https://catalogs.mast.stsci.edu/docs/hsc.html\n",
    "  [4]: https://catalogs.mast.stsci.edu/hsc\n",
    "  [5]: https://media.stsci.edu/news_release/news/2011-16\n",
    "  [6]: ../SWEEPS_HSCV3P1/sweeps_hscv3p1.ipynb\n",
    "  [7]: https://archive.stsci.edu/hst/hsc/help/sweeps/hsc_sweeps_pm.html\n",
    "  [8]: ../HSCV3_API/hscv3_api.ipynb\n",
    "  [9]: ../HSCV3_SMC_API/hscv3_smc_api.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions: \n",
    "* Complete the initialization steps [described below](#Initialization).\n",
    "* Run the notebook to completion. \n",
    "* Modify and rerun any sections of the Table of Contents below.\n",
    "\n",
    "Running the notebook from top to bottom takes about \n",
    "4 minutes (depending on the speed of your computer).\n",
    "\n",
    "\n",
    "# Table of Contents\n",
    "* [Initialization](#Initialization)\n",
    "* [Properties of Full Catalog](#fullcat)\n",
    "    * [Sky Coverage](#SkyCoverage)\n",
    "    * [Proper Motion Distributions](#pmhist)\n",
    "    * [Visit Distribution](#visitshist)\n",
    "    * [Time Coverage Distributions](#timehist)\n",
    "    * [Detection Positions](#detpos)\n",
    "    * [Positions for a Sample With Good PMs](#good_sample)\n",
    "* [Science Applications](#sciap)\n",
    "    * [High Proper Motion Objects](#hpm)\n",
    "    * [HLA Cutout Images for Selected Objects](#cutouts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization <a class=\"anchor\" id=\"Initialization\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Python modules\n",
    "\n",
    "1. _This notebook requires the use of **Python 3**._\n",
    "1. Modules can be installed with `conda`, if using the [Anaconda distribution][1] of python, or with `pip`.\n",
    "   - If you are using `conda`, do not install / update / remove a module with `pip`, that exists in a `conda` [channel][2].\n",
    "   - If a module is not available with `conda`, then it's okay to install it with `pip`\n",
    "\n",
    "\n",
    "  [1]: https://www.anaconda.com/products/distribution\n",
    "  [2]: https://docs.conda.io/projects/conda/en/latest/user-guide/concepts/channels.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from pathlib import Path\n",
    "\n",
    "## For handling ordinary astropy Tables\n",
    "from astropy.table import Table\n",
    "from astropy.io import fits, ascii\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "from fastkde import fastKDE\n",
    "from scipy.interpolate import RectBivariateSpline\n",
    "from astropy.modeling import models, fitting\n",
    "\n",
    "# There are a number of relatively unimportant warnings that \n",
    "# show up, so for now, suppress them:\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# set width for pprint\n",
    "astropy.conf.max_width = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set universal matplotlib parameters\n",
    "plt.rcParams.update({'font.size': 16})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAST API functions\n",
    "\n",
    "- Execute HSC searches and resolve names using [MAST query][1].\n",
    "- Here we define several interrelated functions for retrieving information from the MAST API.\n",
    "  - The `hcvcone(ra, dec, radius [, keywords])` function searches the HCV catalog near a position.\n",
    "  - The `hcvsearch()` function performs general non-positional queries.\n",
    "  - The `hcvmetadata()` function gives information about the columns available in a table. \n",
    "\n",
    "\n",
    "  [1]: https://mast.stsci.edu/api/v0/MastApiTutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hscapiurl = \"https://catalogs.mast.stsci.edu/api/v0.1/hsc\"\n",
    "\n",
    "\n",
    "def hsccone(ra, dec, radius, table=\"summary\", release=\"v3\", format=\"csv\", magtype=\"magaper2\",\n",
    "            columns=None, baseurl=hscapiurl, verbose=False, **kw):\n",
    "    \"\"\"Do a cone search of the HSC catalog\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ra (float): (degrees) J2000 Right Ascension\n",
    "    dec (float): (degrees) J2000 Declination\n",
    "    radius (float): (degrees) Search radius (<= 0.5 degrees)\n",
    "    table (string): summary, detailed, propermotions, or sourcepositions\n",
    "    release (string): v3 or v2\n",
    "    magtype (string): magaper2 or magauto (only applies to summary table)\n",
    "    format: csv, votable, json\n",
    "    columns: list of column names to include (None means use defaults)\n",
    "    baseurl: base URL for the request\n",
    "    verbose: print info about request\n",
    "    **kw: other parameters (e.g., 'numimages.gte':2)\n",
    "    \"\"\"\n",
    "    \n",
    "    data = kw.copy()\n",
    "    data['ra'] = ra\n",
    "    data['dec'] = dec\n",
    "    data['radius'] = radius\n",
    "    return hscsearch(table=table, release=release, format=format, magtype=magtype,\n",
    "                     columns=columns, baseurl=baseurl, verbose=verbose, **data)\n",
    "\n",
    "\n",
    "def hscsearch(table=\"summary\", release=\"v3\", magtype=\"magaper2\", format=\"csv\",\n",
    "              columns=None, baseurl=hscapiurl, verbose=False, **kw):\n",
    "    \"\"\"Do a general search of the HSC catalog (possibly without ra/dec/radius)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    table (string): summary, detailed, propermotions, or sourcepositions\n",
    "    release (string): v3 or v2\n",
    "    magtype (string): magaper2 or magauto (only applies to summary table)\n",
    "    format: csv, votable, json\n",
    "    columns: list of column names to include (None means use defaults)\n",
    "    baseurl: base URL for the request\n",
    "    verbose: print info about request\n",
    "    **kw: other parameters (e.g., 'numimages.gte':2).  Note this is required!\n",
    "    \"\"\"\n",
    "    \n",
    "    data = kw.copy()\n",
    "    if not data:\n",
    "        raise ValueError(\"You must specify some parameters for search\")\n",
    "    if format not in (\"csv\", \"votable\", \"json\"):\n",
    "        raise ValueError(\"Bad value for format\")\n",
    "    url = \"{}.{}\".format(cat2url(table, release, magtype, baseurl=baseurl), format)\n",
    "    if columns:\n",
    "        # check that column values are legal\n",
    "        # create a dictionary to speed this up\n",
    "        dcols = {}\n",
    "        for col in hscmetadata(table, release, magtype)['name']:\n",
    "            dcols[col.lower()] = 1\n",
    "        badcols = []\n",
    "        for col in columns:\n",
    "            if col.lower().strip() not in dcols:\n",
    "                badcols.append(col)\n",
    "        if badcols:\n",
    "            raise ValueError(f\"Some columns not found in table: {', '.join(badcols)}\")\n",
    "        # two different ways to specify a list of column values in the API\n",
    "        # data['columns'] = columns\n",
    "        data['columns'] = f\"[{','.join(columns)}]\"\n",
    "\n",
    "    # either get or post works\n",
    "    # r = requests.post(url, data=data)\n",
    "    r = requests.get(url, params=data)\n",
    "\n",
    "    if verbose:\n",
    "        print(r.url)\n",
    "    r.raise_for_status()\n",
    "    if format == \"json\":\n",
    "        return r.json()\n",
    "    else:\n",
    "        return r.text\n",
    "\n",
    "\n",
    "def hscmetadata(table=\"summary\", release=\"v3\", magtype=\"magaper2\", baseurl=hscapiurl):\n",
    "    \"\"\"Return metadata for the specified catalog and table\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    table (string): summary, detailed, propermotions, or sourcepositions\n",
    "    release (string): v3 or v2\n",
    "    magtype (string): magaper2 or magauto (only applies to summary table)\n",
    "    baseurl: base URL for the request\n",
    "    \n",
    "    Returns an astropy table with columns name, type, description\n",
    "    \"\"\"\n",
    "    url = \"{}/metadata\".format(cat2url(table, release, magtype, baseurl=baseurl))\n",
    "    r = requests.get(url)\n",
    "    r.raise_for_status()\n",
    "    v = r.json()\n",
    "    # convert to astropy table\n",
    "    tab = Table(rows=[(x['name'], x['type'], x['description']) for x in v],\n",
    "                names=('name', 'type', 'description'))\n",
    "    return tab\n",
    "\n",
    "\n",
    "def cat2url(table=\"summary\", release=\"v3\", magtype=\"magaper2\", baseurl=hscapiurl):\n",
    "    \"\"\"Return URL for the specified catalog and table\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    table (string): summary, detailed, propermotions, or sourcepositions\n",
    "    release (string): v3 or v2\n",
    "    magtype (string): magaper2 or magauto (only applies to summary table)\n",
    "    baseurl: base URL for the request\n",
    "    \n",
    "    Returns a string with the base URL for this request\n",
    "    \"\"\"\n",
    "    checklegal(table, release, magtype)\n",
    "    if table == \"summary\":\n",
    "        url = f\"{baseurl}/{release}/{table}/{magtype}\"\n",
    "    else:\n",
    "        url = f\"{baseurl}/{release}/{table}\"\n",
    "    return url\n",
    "\n",
    "\n",
    "def checklegal(table, release, magtype):\n",
    "    \"\"\"Checks if this combination of table, release and magtype is acceptable\n",
    "    \n",
    "    Raises a ValueError exception if there is problem\n",
    "    \"\"\"\n",
    "    \n",
    "    releaselist = (\"v2\", \"v3\")\n",
    "    if release not in releaselist:\n",
    "        raise ValueError(f\"Bad value for release (must be one of {', '.join(releaselist)})\")\n",
    "    if release == \"v2\":\n",
    "        tablelist = (\"summary\", \"detailed\")\n",
    "    else:\n",
    "        tablelist = (\"summary\", \"detailed\", \"propermotions\", \"sourcepositions\")\n",
    "    if table not in tablelist:\n",
    "        raise ValueError(f\"Bad value for table (for {release} must be one of {', '.join(tablelist)})\")\n",
    "    if table == \"summary\":\n",
    "        magtypelist = (\"magaper2\", \"magauto\")\n",
    "        if magtype not in magtypelist:\n",
    "            raise ValueError(f\"Bad value for magtype (must be one of {', '.join(magtypelist)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use metadata query to get information on available columns\n",
    "\n",
    "This query works for any of the tables in the API (summary, detailed, propermotions, sourcepositions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = hscmetadata(\"propermotions\")\n",
    "print(' '.join(meta['name']))\n",
    "meta[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve data on selected SWEEPS objects\n",
    "\n",
    "This makes a single large request to the HSC search interface to the get the contents of the proper motions table.  Despite its large size (460K rows), the query is relatively efficient: it takes about 25 seconds to retrieve the results from the server, and then another 20 seconds to convert it to an astropy table.  The speed of the table conversion will depend on your computer.\n",
    "\n",
    "Note that the query restricts the sample to objects with at least 20 images total spread over at least 10 different visits.\n",
    "These constraints can be modified depending on your science goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = \"\"\"ObjID,raMean,decMean,raMeanErr,decMeanErr,NumFilters,NumVisits,\n",
    "    pmLat,pmLon,pmLatErr,pmLonErr,pmLatDev,pmLonDev,epochMean,epochStart,epochEnd\"\"\".split(\",\")\n",
    "columns = [x.strip() for x in columns]\n",
    "columns = [x for x in columns if x and not x.startswith('#')]\n",
    "\n",
    "# missing -- impossible with current data I think\n",
    "# MagMed, n, MagMAD\n",
    "\n",
    "constraints = {'NumFilters.gt': 1, 'NumVisits.gt': 9, 'NumImages.gt': 19}\n",
    "\n",
    "# note the pagesize parameter, which allows retrieving very large results\n",
    "# the default pagesize is 50000 rows\n",
    "\n",
    "t0 = time.time()\n",
    "results = hscsearch(table=\"propermotions\", release='v3', columns=columns, verbose=True, pagesize=500000, **constraints)\n",
    "print(\"{:.1f} s: retrieved data\".format(time.time()-t0))\n",
    "tab = ascii.read(results)\n",
    "print(f\"{(time.time()-t0):.1f} s: converted to astropy table\")\n",
    "\n",
    "# change some column names for consistency with the Casjobs version of this notebook\n",
    "tab.rename_column(\"raMean\", \"RA\")\n",
    "tab.rename_column(\"decMean\", \"Dec\")\n",
    "tab.rename_column(\"raMeanErr\", \"RAerr\")\n",
    "tab.rename_column(\"decMeanErr\", \"Decerr\")\n",
    "tab.rename_column(\"pmLat\", \"bpm\")\n",
    "tab.rename_column(\"pmLon\", \"lpm\")\n",
    "tab.rename_column(\"pmLatErr\", \"bpmerr\")\n",
    "tab.rename_column(\"pmLonErr\", \"lpmerr\")\n",
    "\n",
    "# compute some additional columns\n",
    "\n",
    "tab['pmdev'] = np.sqrt(tab['pmLonDev']**2+tab['pmLatDev']**2)\n",
    "tab['yr'] = (tab['epochMean'] - 47892)/365.25+1990\n",
    "tab['dT'] = (tab['epochEnd']-tab['epochStart'])/365.25\n",
    "tab['yrStart'] = (tab['epochStart'] - 47892)/365.25+1990\n",
    "tab['yrEnd'] = (tab['epochEnd'] - 47892)/365.25+1990\n",
    "\n",
    "# delete some columns that are not needed after the computations\n",
    "del tab['pmLonDev'], tab['pmLatDev'], tab['epochEnd'], tab['epochStart'], tab['epochMean']\n",
    "\n",
    "tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Properties of Full Catalog  <a class=\"anchor\" id=\"fullcat\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sky Coverage  <a class=\"anchor\" id=\"SkyCoverage\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "ax.scatter('RA', 'Dec', data=tab, s=1, alpha=0.1)\n",
    "ax.set(xlabel='RA', ylabel='Dec', title=f'{len(tab)} stars in SWEEPS')\n",
    "ax.invert_xaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proper Motion Histograms <a class=\"anchor\" id=\"pmhist\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proper motion histograms for lon and lat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 0.2\n",
    "hrange = (-20, 20)\n",
    "bincount = int((hrange[1]-hrange[0])/bins + 0.5) + 1\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "for col, label in zip(['lpm', 'bpm'], ['Longitude', 'Latitude']):\n",
    "    ax.hist(col, data=tab, range=hrange, bins=bincount, label=label, histtype='step', linewidth=2)\n",
    "ax.set(xlabel='Proper motion [mas/yr]', ylabel=f'Number [in {bins:.2} mas bins]', title=f'{len(tab):,} stars in SWEEPS')\n",
    "_ = ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proper motion error cumulative histogram for lon and lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 0.01\n",
    "hrange = (0, 2)\n",
    "bincount = int((hrange[1]-hrange[0])/bins + 0.5) + 1\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "for col, label in zip(['lpmerr', 'bpmerr'], ['Longitude Error', 'Latitude Error']):\n",
    "    ax.hist(col, data=tab, range=hrange, bins=bincount, label=label, histtype='step', cumulative=1, linewidth=2)\n",
    "ax.set(xlabel='Proper motion error [mas/yr]', ylabel=f'Cumulative number [in {bins:0.2} mas bins]', title=f'{len(tab):,} stars in SWEEPS')\n",
    "_ = ax.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proper motion error log histogram for lon and lat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 0.01\n",
    "hrange = (0, 6)\n",
    "bincount = int((hrange[1]-hrange[0])/bins + 0.5) + 1\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "for col, label in zip(['lpmerr', 'bpmerr'], ['Longitude Error', 'Latitude Error']):\n",
    "    ax.hist(col, data=tab, range=hrange, bins=bincount, label=label, histtype='step', linewidth=2)\n",
    "ax.set(xlabel='Proper motion error [mas/yr]', ylabel=f'Number [in {bins:0.2} mas bins]', title=f'{len(tab):,} stars in SWEEPS', yscale='log')\n",
    "_ = ax.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proper motion error as a function of dT\n",
    "\n",
    "Exclude objects with dT near zero, and to improve the plotting add a bit of random noise to spread out the quanitized time values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restrict to sources with dT > 1 year\n",
    "dtmin = 1.0\n",
    "w = np.where(tab['dT'] > dtmin)[0]\n",
    "if ('rw' not in locals()) or len(rw) != len(w):\n",
    "    rw = np.random.random(len(w))\n",
    "x = np.array(tab['dT'][w]) + 0.5*(rw-0.5)\n",
    "y = np.log(np.array(tab['lpmerr'][w]))\n",
    "\n",
    "# Calculate the point density\n",
    "t0 = time.time()\n",
    "myPDF, axes = fastKDE.pdf(x, y, numPoints=2**9+1)\n",
    "print(f\"kde took {(time.time()-t0):.1f} sec\")\n",
    "\n",
    "# interpolate to get z values at points\n",
    "finterp = RectBivariateSpline(axes[1], axes[0], myPDF)\n",
    "z = finterp(y, x, grid=False)\n",
    "\n",
    "# Sort the points by density, so that the densest points are plotted last\n",
    "idx = z.argsort()\n",
    "xs, ys, zs = x[idx], y[idx], z[idx]\n",
    "\n",
    "# select a random subset of points in the most crowded regions to speed up plotting\n",
    "wran = np.where(np.random.random(len(zs))*zs < 0.05)[0]\n",
    "print(f\"Plotting {len(wran)} of {len(zs)} points\")\n",
    "xs = xs[wran]\n",
    "ys = ys[wran]\n",
    "zs = zs[wran]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "sc = ax.scatter(xs, np.exp(ys), c=zs, s=2, edgecolors='none', cmap='plasma')\n",
    "ax.set(xlabel='Date range [yr]', ylabel='Proper motion error [mas/yr]',\n",
    "       title=f'{len(tab):,} stars in SWEEPS\\nLongitude PM error', yscale='log')\n",
    "_ = fig.colorbar(sc, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proper motion error log histogram for lon and lat \n",
    "\n",
    "Divide sample into points with $<6$ years of data and points with more than 6 years of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 0.01\n",
    "hrange = (0, 6)\n",
    "bincount = int((hrange[1]-hrange[0])/bins + 0.5) + 1\n",
    "tsplit = 6\n",
    "\n",
    "# select the data to plot\n",
    "mask = tab['dT'] <= tsplit\n",
    "data1 = tab[mask]\n",
    "data2 = tab[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(12, 12), sharey=True)\n",
    "\n",
    "for ax, data in zip([ax1, ax2], [data1, data2]):\n",
    "    for col, label in zip(['lpmerr', 'bpmerr'], ['Longitude Error', 'Latitude Error']):\n",
    "        ax.hist(col, data=data, range=hrange, bins=bincount, label=label, histtype='step', linewidth=2)\n",
    "    \n",
    "ax1.set(xlabel='Proper motion error [mas/yr]', ylabel=f'Number [in {bins:0.2} mas bins]',\n",
    "        title=f'{len(data1):,} stars in SWEEPS with dT < {tsplit} yrs', yscale='log')\n",
    "ax2.set(xlabel='Proper motion error [mas/yr]', ylabel=f'Number [in {bins:0.2} mas bins]',\n",
    "        title=f'{len(data2):,} stars in SWEEPS with dT > {tsplit} yrs', yscale='log')\n",
    "\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "\n",
    "_ = fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of Visits Histogram <a class=\"anchor\" id=\"visitshist\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 1\n",
    "hrange = (0, 130)\n",
    "bincount = int((hrange[1]-hrange[0])/bins + 0.5) + 1\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "ax.hist('NumVisits', data=tab, range=hrange, bins=bincount, label='Number of visits ', histtype='step', linewidth=2)\n",
    "ax.set(xlabel='Number of visits', ylabel='Number of objects', title=f'{len(tab):,} stars in SWEEPS')\n",
    "_ = ax.margins(x=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Histograms <a class=\"anchor\" id=\"timehist\"></a>\n",
    "\n",
    "First plot histogram of observation dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 1\n",
    "hrange = (2000, 2020)\n",
    "bincount = int((hrange[1]-hrange[0])/bins + 0.5) + 1\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "ax.hist('yr', data=tab, range=hrange, bins=bincount, label='year ', histtype='step', linewidth=2)\n",
    "ax.set(xlabel='mean detection epoch (year)', ylabel='Number of objects', title=f'{len(tab):,} stars in SWEEPS')\n",
    "ax.set_xticks(ticks=range(2000, 2021, 2))\n",
    "_ = ax.margins(x=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then plot histogram of observation duration for the objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 0.25\n",
    "hrange = (0, 15)\n",
    "bincount = int((hrange[1]-hrange[0])/bins + 0.5) + 1\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "ax.hist('dT', data=tab, range=hrange, bins=bincount, label='year ', histtype='step', linewidth=2)\n",
    "_ = ax.set(xlabel='time span (years)', ylabel='Number of objects', title=f'{len(tab):,} stars in SWEEPS', yscale='log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection Positions <a class=\"anchor\" id=\"detpos\"></a>\n",
    "\n",
    "Define a function to plot the PM fit for an object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function\n",
    "def positions(Obj):\n",
    "    \"\"\"\n",
    "    input parameter Obj is the value of the ObjID \n",
    "    output plots change in (lon, lat) as a function of time\n",
    "    overplots proper motion fit\n",
    "    provides ObjID and proper motion information in labels\n",
    "    \"\"\"\n",
    "\n",
    "    # get the measured positions as a function of time\n",
    "    pos = ascii.read(hscsearch(\"sourcepositions\", columns=\"dT,dLon,dLat\".split(','), objid=Obj))\n",
    "    pos.sort('dT')\n",
    "    \n",
    "    # get the PM fit parameters\n",
    "    pm = ascii.read(hscsearch(\"propermotions\", columns=\"pmlon,pmlonerr,pmlat,pmlaterr\".split(','), objid=Obj))\n",
    "    \n",
    "    lpm = pm['pmlon'][0]\n",
    "    bpm = pm['pmlat'][0]\n",
    "    \n",
    "    # get the intercept for the proper motion fit referenced to the start time\n",
    "    # time between mean epoch and zero (ref) epoch (years)\n",
    "\n",
    "    x = pos['dT']\n",
    "    # xpm = np.linspace(0, max(x), 10)\n",
    "    xpm = np.array([x.min(), x.max()])\n",
    "        \n",
    "    y1 = pos['dLon']\n",
    "    ypm1 = lpm*xpm\n",
    "    \n",
    "    y2 = pos['dLat']\n",
    "    ypm2 = bpm*xpm\n",
    "\n",
    "    # plot figure \n",
    "    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(6, 3), tight_layout=True)\n",
    "    \n",
    "    ax1.scatter(x, y1, s=10)\n",
    "    ax1.plot(xpm, ypm1, '-r')\n",
    "    \n",
    "    ax2.scatter(x, y2, s=10)\n",
    "    ax2.plot(xpm, ypm2, '-r')\n",
    "    \n",
    "    ax1.set_xlabel('dT (yrs)', fontsize=10)\n",
    "    ax1.set_ylabel('dLon (mas)', fontsize=10)\n",
    "    ax2.set_xlabel('dT (yrs)', fontsize=10)\n",
    "    ax2.set_ylabel('dLat (mas)', fontsize=10)\n",
    "    \n",
    "    fig.suptitle(f'ObjID {Obj}'\n",
    "                 f'\\n{len(x)} detections,  (lpm, bpm) = ({lpm:.1f}, {bpm:.1f}) mas/yr', fontsize=10)\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot positions for a sample of objects with good proper motions  <a class=\"anchor\" id=\"good_sample\"></a>\n",
    "\n",
    "This selects objects that are detected in more than 90 visits with a median absolute deviation from the fit of less than 1.5 mas and proper motion error less than 1.0 mas/yr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = tab['NumVisits']\n",
    "dev = tab['pmdev']\n",
    "objid = tab['ObjID']\n",
    "lpmerr0 = np.array(tab['lpmerr'])\n",
    "bpmerr0 = np.array(tab['bpmerr'])\n",
    "wi = np.where((dev < 1.5) & (n > 90) & (np.sqrt(bpmerr0**2+lpmerr0**2) < 1.0))[0]\n",
    "print(f\"Plotting {len(wi)} objects\")\n",
    "for o in objid[wi]:\n",
    "    positions(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Science Applications <a class=\"anchor\" id=\"sciap\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High Proper Motion Objects  <a class=\"anchor\" id=\"hpm\"></a>\n",
    "\n",
    "Get a list of objects with high, accurately measured proper motions.\n",
    "Proper motions are measured relative to the Galactic center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpm_sgra = -6.379 # +- 0.026\n",
    "bpm_sgra = -0.202 # +- 0.019\n",
    "\n",
    "lpm0 = np.array(tab['lpm'])\n",
    "bpm0 = np.array(tab['bpm'])\n",
    "lpmerr0 = np.array(tab['lpmerr'])\n",
    "bpmerr0 = np.array(tab['bpmerr'])\n",
    "pmtot0 = np.sqrt((bpm0-bpm_sgra)**2+(lpm0-lpm_sgra)**2)\n",
    "pmerr0 = np.sqrt(bpmerr0**2+lpmerr0**2)\n",
    "dev = tab['pmdev']\n",
    "\n",
    "# sort samples by decreasing PM\n",
    "wpmh = np.where((pmtot0 > 15) & (pmerr0 < 1.0) & (dev < 5))[0]\n",
    "wpmh = wpmh[np.argsort(-pmtot0[wpmh])]\n",
    "\n",
    "print(f\"Plotting {len(wpmh)} objects\")\n",
    "for o in tab[\"ObjID\"][wpmh]:\n",
    "    positions(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get HLA cutout images for selected objects  <a class=\"anchor\" id=\"cutouts\"></a>\n",
    "\n",
    "Get HLA color cutout images for the high-PM objects.  The `query_hla` function gets a table of all the color images that are available at a given position using the f814w+f606w filters.  The `get_image` function reads a single cutout image (as a JPEG color image) and returns a PIL image object.\n",
    "\n",
    "See the documentation on [HLA VO services](http://hla.stsci.edu/hla_help.html#services) and the [fitscut image cutout service](http://hla.stsci.edu/fitscutcgi_interface.html) for more information on the web services being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_hla(ra, dec, size=0.0, imagetype=\"color\", inst=\"ACS\", format=\"image/jpeg\",\n",
    "              spectral_elt=(\"f814w\", \"f606w\"), autoscale=95.0, asinh=1, naxis=33):\n",
    "    # convert a list of filters to a comma-separated string\n",
    "    if not isinstance(spectral_elt, str):\n",
    "        spectral_elt = \",\".join(spectral_elt)\n",
    "    siapurl = (\"https://hla.stsci.edu/cgi-bin/hlaSIAP.cgi?\"\n",
    "               f\"pos={ra},{dec}&size={size}&imagetype={imagetype}&inst={inst}\"\n",
    "               f\"&format={format}&spectral_elt={spectral_elt}\"\n",
    "               f\"&autoscale={autoscale}&asinh={asinh}\"\n",
    "               f\"&naxis={naxis}\")\n",
    "    votable = Table.read(siapurl, format=\"votable\")\n",
    "    return votable\n",
    "\n",
    "\n",
    "def get_image(url):\n",
    "    \"\"\"Get image from a URL\"\"\"\n",
    "    r = requests.get(url)\n",
    "    im = Image.open(BytesIO(r.content))\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display earliest and latest images side-by-side\n",
    "# top 10 highest PM objects\n",
    "wsel = wpmh[:10]\n",
    "nim = len(wsel)\n",
    "icols = 1        # objects per row\n",
    "ncols = 2*icols  # two images for each object\n",
    "nrows = (nim+icols-1)//icols\n",
    "\n",
    "imsize = 33\n",
    "xcross = np.array([-1, 1, 0, 0, 0])*2 + imsize/2\n",
    "ycross = np.array([0, 0, 0, -1, 1])*2 + imsize/2\n",
    "\n",
    "# selected data from tab\n",
    "sd = tab[['RA', 'Dec', 'ObjID']][wsel]\n",
    "\n",
    "# create the figure\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(12, (12/ncols)*nrows))\n",
    "\n",
    "# iterate each observation, and each set of axes for the first and last image\n",
    "for (ax1, ax2), obj in zip(axes, sd):\n",
    "    \n",
    "    # get the image urls and observation datetime\n",
    "    hlatab = query_hla(obj[\"RA\"], obj[\"Dec\"], naxis=imsize)[['URL', 'StartTime']]\n",
    "    # sort the data by the observation datetime, and get the first and last observation url\n",
    "    (url1, time1), (url2, time2) = hlatab[np.argsort(hlatab['StartTime'])][[0, -1]]\n",
    "    \n",
    "    # get the images\n",
    "    im1 = get_image(url1)\n",
    "    im2 = get_image(url2)\n",
    "    \n",
    "    # plot the images\n",
    "    ax1.imshow(im1, origin=\"upper\")\n",
    "    ax2.imshow(im2, origin=\"upper\")\n",
    "    \n",
    "    # plot the center\n",
    "    ax1.plot(xcross, ycross, 'g')\n",
    "    ax2.plot(xcross, ycross, 'g')\n",
    "    \n",
    "    # labels and titles\n",
    "    ax1.set(ylabel=f'ObjID {obj[\"ObjID\"]}', title=time1)\n",
    "    ax2.set_title(time2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the entire collection of images for the highest PM object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = wpmh[0]\n",
    "\n",
    "# selected data\n",
    "sd = tab['ObjID', 'RA', 'Dec', 'bpm', 'lpm', 'yr', 'dT'][i]\n",
    "display(sd)\n",
    "\n",
    "imsize = 33\n",
    "# get the URL and StartTime data\n",
    "hlatab = query_hla(sd['RA'], sd['Dec'], naxis=imsize)[['URL', 'StartTime']]\n",
    "# sort the data\n",
    "hlatab = hlatab[np.argsort(hlatab['StartTime'])]\n",
    "\n",
    "nim = len(hlatab)\n",
    "ncols = 8\n",
    "nrows = (nim+ncols-1)//ncols\n",
    "\n",
    "xcross = np.array([-1, 1, 0, 0, 0])*2 + imsize/2\n",
    "ycross = np.array([0, 0, 0, -1, 1])*2 + imsize/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the images: takes about 90 seconds for 77 images\n",
    "images = [get_image(url) for url in hlatab['URL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the figure\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(20, (20/ncols)*nrows))\n",
    "# flatten the axes for easy iteration and zipping\n",
    "axes = axes.flat\n",
    "\n",
    "plt.rcParams.update({\"font.size\": 11})\n",
    "for ax, time1, img in zip(axes, hlatab['StartTime'], images):\n",
    "    # plot image\n",
    "    ax.imshow(img, origin=\"upper\")\n",
    "    # plot the center\n",
    "    ax.plot(xcross, ycross, 'g')\n",
    "    # set the title\n",
    "    ax.set_title(time1)\n",
    "    \n",
    "# remove the last 3 unused axes\n",
    "for ax in axes[nim:]:\n",
    "    ax.remove()\n",
    "\n",
    "fig.suptitle(f\"ObjectID: {sd['ObjID']}\\nRA: {sd['RA']:0.2f} Dec: {sd['Dec']:0.2f}\\nObservations: {nim}\", y=1, fontsize=14)\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stsci",
   "language": "python",
   "name": "stsci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
