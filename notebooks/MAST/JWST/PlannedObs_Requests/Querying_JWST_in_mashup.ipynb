{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Using the API to Query Planned JWST Observations in MAST</h2>\n",
    "<p><i>By Peter Forshay (pforshay@stsci.edu)</i></p>\n",
    "<p>In this Notebook we'll take a look at how to use the MAST API to find planned JWST observations from GTO and ERS programs.  We'll start with a basic filtered query to find all planned observations before moving on to constructing more specific requests:</p>\n",
    "<ul>\n",
    "    <li><a href=#search-by-pos>Searching by position</a></li>\n",
    "    <li><a href=#analyzing-results>Analyzing our results</a></li>\n",
    "    <li><a href=#save-to-file>Saving results to a file</a></li>\n",
    "    <li><a href=#query-multi-targs>Querying multiple positions at once</a></li>\n",
    "    <li><a href=#search-by-name>Resolving stationary target names</a></li>\n",
    "    <li><a href=#moving-targets>Searching for moving target names</a></li>\n",
    "    <li><a href=#send-to-aladin>Visualizing results using Aladin</a></li>\n",
    "</ul>\n",
    "<p>Be aware that MAST queries can take some time to run and get a response, so please be patient when running cells back to back.  If you encounter any errors, try to run the cell again when the previous cells have completed execution.</p>\n",
    "<p><b>IMPORTANT DISCLAIMER:</b>  To avoid unintentional duplications, JWST proposers are required to check their proposed observations against those already approved.  The tools provided here may be able to assist a user in identifying POTENTIAL observing conflicts for JWST programs.  It remains the PI's responsibility to determine whether or not the result provided by these tools constitutes an actual conflict, in accordance with the <a href=\"https://jwst-docs.stsci.edu/display/JSP/JWST+Duplicate+Observations+Policy\" target=\"_blank\">JWST Duplicate Observations Policy</a>.</p>\n",
    "<p><i>(Much of this code is based on the tutorials and examples provided in the <a href=\"https://mast.stsci.edu/api/v0/\" target=\"_blank\">MAST API documentation pages found here</a>)</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Standard import statements for a MAST Mashup API request</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "\n",
    "try: # Python 3.x\n",
    "    from urllib.parse import quote as urlencode\n",
    "    from urllib.request import urlretrieve\n",
    "except ImportError:  # Python 2.x\n",
    "    from urllib import pathname2url as urlencode\n",
    "    from urllib import urlretrieve\n",
    "\n",
    "try: # Python 3.x\n",
    "    import http.client as httplib \n",
    "except ImportError:  # Python 2.x\n",
    "    import httplib   \n",
    "\n",
    "from astropy.table import Table\n",
    "import numpy as np\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Define the MAST query module to handle appropriate formatting</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mastQuery(request):\n",
    "    \"\"\"Perform a MAST query.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        request (dictionary): The MAST request json object\n",
    "        \n",
    "        Returns head,content where head is the response HTTP headers, and content is the returned data\"\"\"\n",
    "    \n",
    "    server='mast.stsci.edu'\n",
    "\n",
    "    # Grab Python Version \n",
    "    version = \".\".join(map(str, sys.version_info[:3]))\n",
    "\n",
    "    # Create Http Header Variables\n",
    "    headers = {\"Content-type\": \"application/x-www-form-urlencoded\",\n",
    "               \"Accept\": \"text/plain\",\n",
    "               \"User-agent\":\"python-requests/\"+version}\n",
    "\n",
    "    # Encoding the request as a json string\n",
    "    requestString = json.dumps(request)\n",
    "    requestString = urlencode(requestString)\n",
    "    \n",
    "    # opening the https connection\n",
    "    conn = httplib.HTTPSConnection(server)\n",
    "\n",
    "    # Making the query\n",
    "    conn.request(\"POST\", \"/api/v0/invoke\", \"request=\"+requestString, headers)\n",
    "\n",
    "    # Getting the response\n",
    "    resp = conn.getresponse()\n",
    "    head = resp.getheaders()\n",
    "    content = resp.read().decode('utf-8')\n",
    "\n",
    "    # Close the https connection\n",
    "    conn.close()\n",
    "\n",
    "    return head,content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Here is where we begin to customize the code to perform our own queries:</h3>\n",
    "<p>The first search below sends a filtered query to count all planned observations, designated by a calibration level of -1.  In the 'data' entry, we can see 'Column1' returns with the number of results for the submitted query.</p>\n",
    "<ul>\n",
    "    <li>\"paramName\":\"calib_level\" allows us to filter based on calibration level.</li>\n",
    "    <li>\"values\":[\"-1\"] defines a planned observation.</li>\n",
    "</ul>\n",
    "<p>Additional parameters to filter on:</p>\n",
    "<ul>\n",
    "    <li>target_name</li>\n",
    "    <li>s_ra</li>\n",
    "    <li>s_dec</li>\n",
    "    <li>instrument</li>\n",
    "    <li>filters</li>\n",
    "    <li>proposal_id</li>\n",
    "    <li>target_classification</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mashupRequest = {\"service\":\"Mast.Caom.Filtered\",\n",
    "                 \"format\":\"json\",\n",
    "                 \"params\":{\"columns\":\"COUNT_BIG(*)\",    # \"COUNT_BIG(*)\" will only get a count of the results\n",
    "                           \"filters\":[{\"paramName\":\"calib_level\",\n",
    "                                       \"values\":[\"-1\"]\n",
    "                                      },\n",
    "                                      {\"paramName\":\"obs_collection\",\n",
    "                                       \"values\":[\"JWST\"]\n",
    "                                      }]\n",
    "                          }\n",
    "                }\n",
    "    \n",
    "headers,outString = mastQuery(mashupRequest)\n",
    "queryResults = json.loads(outString)\n",
    "\n",
    "pp.pprint(queryResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"search-by-pos\"></a>\n",
    "<h3>Searching by position</h3>\n",
    "<p>First off, in order to send a filtered position search via the API, we'll need to submit the position in question in degrees.  Converting a set of coordinates to degrees is made pretty easy by using the <a href=\"http://docs.astropy.org/en/stable/coordinates/\" target=\"_blank\">astropy.coordinates SkyCoord class</a>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "def convert_to_degrees(our_ra, our_dec):\n",
    "    \"\"\"\n",
    "    Convert a pair of coordinate entries to degrees.  Able to accept multiple input formats, \n",
    "    relying on SkyCoord class.\n",
    "    \n",
    "    :param our_ra:  Right Ascention\n",
    "    :type our_ra:  string\n",
    "    \n",
    "    :param our_dec:  Declination\n",
    "    :type our_dec:  string\n",
    "    \"\"\"\n",
    "    \n",
    "    coords = SkyCoord(our_ra, our_dec)\n",
    "    ra_deg = coords.ra.deg\n",
    "    dec_deg = coords.dec.deg\n",
    "    in_degrees = (ra_deg, dec_deg)\n",
    "    \n",
    "    return in_degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select our coordinates\n",
    "RA = '04h16m09.370s'\n",
    "DEC = '-24d04m20.50s'\n",
    "SAMPLE_COORDS = convert_to_degrees(RA, DEC)\n",
    "print(SAMPLE_COORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now that we have our RA and Dec available in degrees, we can define a radius (also in degrees) and submit a filtered position query.  Recommended search radii for various JWST observing modes are provided within the <a href=\"https://jwst-docs.stsci.edu/display/JSP/JWST+Duplicate+Observations+Policy#JWSTDuplicateObservationsPolicy-DuplicationCheckingandReviewProcedures\" target=\"_blank\">JWST Duplication Policy information found on JDox</a>.  By default, we keep the \"columns\":\"COUNT_BIG(*)\" to simply return a count of the results, in case we hit a large number of entries.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_position_query(coordinates, radius=0.2, count=True):\n",
    "    \"\"\"\n",
    "    Construct a filtered position mashup request to send to the mastQuery module.  Return \n",
    "    either the results of the query or just the results count.\n",
    "    \n",
    "    :param coordinates:  Expects a pair of coordinates in degrees.\n",
    "    :type coordinates:  tuple\n",
    "    \n",
    "    :param radius:  Defines the radius to search around the designated coordinates within.\n",
    "                    Also in degrees.\n",
    "    :type radius:  float\n",
    "    \n",
    "    :param count:  Flag to designate whether a full query is submitted, or just the count\n",
    "                   results.  Also affects the returned product.  Defaults to True.\n",
    "    :type count:  boolean\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unpack the coordinates tuple\n",
    "    ra_deg, dec_deg = coordinates\n",
    "    \n",
    "    # Determine whether this is a full query or just a count\n",
    "    if count:\n",
    "        columns = \"COUNT_BIG(*)\"    # \"COUNT_BIG(*)\" will only get a count of the results\n",
    "    else:\n",
    "        columns = \"*\"\n",
    "        \n",
    "    # Construct the mashup request\n",
    "    service = \"Mast.Caom.Filtered.Position\"\n",
    "    filters = [{\"paramName\":\"calib_level\", \"values\":[\"-1\"]},\n",
    "               {\"paramName\":\"obs_collection\", \"values\":[\"JWST\"]}\n",
    "              ]\n",
    "    position = \"{0}, {1}, {2}\".format(ra_deg, dec_deg, radius)\n",
    "    mashupRequest = {\"service\":service,\n",
    "                     \"format\":\"json\",\n",
    "                     \"params\":{\"columns\":columns,    \n",
    "                               \"filters\":filters,\n",
    "                               \"position\":position\n",
    "                              }\n",
    "                    }\n",
    "\n",
    "    # Send the query\n",
    "    headers,outString = mastQuery(mashupRequest)\n",
    "    queryResults = json.loads(outString)\n",
    "    \n",
    "    # Return either the full query results or just the results count\n",
    "    if count:\n",
    "        data = queryResults['data']\n",
    "        count = data[0]['Column1']\n",
    "        return count\n",
    "    else:\n",
    "        return queryResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_COUNT = filtered_position_query(SAMPLE_COORDS)\n",
    "print(TEST_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In the above result we see we get 152 results, so we can go ahead and submit the full request.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_QUERY = filtered_position_query(SAMPLE_COORDS, count=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>If we display the first few results from the returned 'data' dictionary, we see we have a number of different properties available from these search results.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def display_results(queryResults, num_rows):\n",
    "    \"\"\"Create a Pandas DataFrame from a MAST query results 'data' dictionary but just\n",
    "    return the first few rows.\n",
    "    \n",
    "    :param queryResults:  Full results from a MAST query.\n",
    "    :type queryResults:  dictionary\n",
    "    \n",
    "    :param num_rows:  The requested number of rows to return.\n",
    "    :type num_rows: int\n",
    "    \"\"\"\n",
    "    \n",
    "    frame = pd.DataFrame.from_dict(queryResults['data'])\n",
    "    \n",
    "    print(\"Returning {0} of {1} rows...\".format(num_rows, len(frame)))\n",
    "    return frame[0:num_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_results(TEST_QUERY, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"analyzing-results\"></a>\n",
    "<h3>Analyzing our results</h3>\n",
    "<p>Now that we have some full query results available, we'll want to extract some of the relevant information.  First, we'll want to see a list of any nearby pointings found by our position query.  Next, we'll also want to see a list of which programs these pointings are associated with.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_query_results(our_target, queryResults):\n",
    "    \"\"\"\n",
    "    Perform analysis of the query results.  Identify the nearby planned pointings and\n",
    "    identify the programs involved.\n",
    "    \n",
    "    :param our_target:  Expects a pair of coordinates in degrees.\n",
    "    :type our_target:  tuple\n",
    "    \n",
    "    :param queryResults:  Full results from a MAST query.\n",
    "    :type queryResults:  dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set up initial variables\n",
    "    data = queryResults['data']\n",
    "    ra_target, dec_target = our_target\n",
    "    targets = {}\n",
    "    programs = []\n",
    "    \n",
    "    # Create a dictionary of all unique coordinate pairs along with a count of how many times they\n",
    "    # are found\n",
    "    for current in data:\n",
    "        current_program = current['proposal_id']\n",
    "        current_ra = current['s_ra']\n",
    "        current_dec = current['s_dec']\n",
    "        current_coords = (current_ra, current_dec)\n",
    "        if current_coords in targets.keys():\n",
    "            targets[current_coords] += 1\n",
    "        else:\n",
    "            targets[current_coords] = 1\n",
    "            programs.append(current_program)\n",
    "\n",
    "    # For each unique coordinate pair, calculate the distance from the target and display our \n",
    "    # results\n",
    "    for x in sorted(targets.keys()):\n",
    "        num_obs = targets[x]\n",
    "        unique_ra, unique_dec = x\n",
    "        result = \"Found {0} planned observations at {1}, {2}\".format(num_obs, \n",
    "                                                                     unique_ra, \n",
    "                                                                     unique_dec)\n",
    "        distance_ra = abs(unique_ra - ra_target)\n",
    "        distance_dec = abs(unique_dec - dec_target)\n",
    "        distance = SkyCoord(distance_ra, distance_dec, frame=\"icrs\", unit='deg')\n",
    "        if distance_ra < 0.001 and distance_dec < 0.001:    # Account for rounding differences\n",
    "            result += \" (target match)\"\n",
    "        else:\n",
    "            result += \" ({0} away)\".format(distance.to_string('hmsdms'))\n",
    "        print(result)\n",
    "        \n",
    "    # Output a link for each program found\n",
    "    for p in sorted(list(set(programs))):\n",
    "        address = \"https://jwst.stsci.edu/observing-programs/program-information?id={0}\".format(p)\n",
    "        print(\"Found planned observations in {0}: {1}\".format(p, address))\n",
    "        \n",
    "    # Return the dictionary of coordinates and number of observations\n",
    "    return targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_RESULTS = analyze_query_results(SAMPLE_COORDS, TEST_QUERY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Instead of simply listing associated proposal ID's, our module creates a link to the program information page for any associated proposals found in the area.  On these pages, the user may access additional information on the program or the associated APT file itself.  <b>Examining the information provided on these program pages is a critical step to investigating any potential sources of conflict for your JWST observations.</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"save-to-file\"></a>\n",
    "<h3>Saving results to a file</h3>\n",
    "<p>This gives us a basic idea of how many observations are currently planned in the vicinity, but this does not necessarily mean these observations will conflict.  We still need to check which instruments and configurations are being used.  Much of this information is contained in the query results we've obtained, and would be more easily digestable in a CSV table.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def write_to_csv_file(queryResults, filename):\n",
    "    \"\"\"\n",
    "    Write MAST query results to a .csv file.\n",
    "    \n",
    "    :param queryResults:  Full results from a MAST query.\n",
    "    :type queryResults:  dictionary\n",
    "    \n",
    "    :param filename:  The desired filename to save the CSV table as.\n",
    "    :type filename:  string\n",
    "    \"\"\"\n",
    "    \n",
    "    # Column names are stored in the 'fields' dictionary\n",
    "    fields = queryResults['fields']\n",
    "    header = [entry['name'] for entry in fields]\n",
    "\n",
    "    # Use the DictWriter class to write the data dictionary to a .csv file\n",
    "    directory = os.getcwd()\n",
    "    filename = \"/\".join([directory, filename])\n",
    "    data = queryResults['data']\n",
    "    with open(filename, 'w') as output:\n",
    "        writer = csv.DictWriter(output, fieldnames=header)\n",
    "        writer.writeheader()\n",
    "        w = [writer.writerow(obs) for obs in data]\n",
    "        \n",
    "    # Return the filename created\n",
    "    print(\"Saved {0}\".format(filename))\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a filename for the resulting CSV table\n",
    "SAVE_AS = 'planned_obs_test.csv'\n",
    "SAVED = write_to_csv_file(TEST_QUERY, SAVE_AS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"query-multi-targs\"></a>\n",
    "<h3>Process multiple targets</h3>\n",
    "<p>We now have a CSV table with all parameters available through the Portal for all observations found within a 0.2 degree radius of a set of sample coordinates.  The API allows us to now take this one step further and bring all these modules together and check multiple sets of coordinates back-to-back.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_multiple_targets(coordinates_list, coordinates_format, write):\n",
    "    \"\"\"\n",
    "    Handle the full process for checking a list of targets.  This includes converting\n",
    "    to degrees if necessary, sending an initial count query, sending the full MAST\n",
    "    query, analyzing the results, and writing the results to a file.\n",
    "    \n",
    "    :param coordinates_list:  Expects a list of coordinate tuples, not necessarily in\n",
    "                              degrees.\n",
    "    :type coordinates_list:  list\n",
    "    \n",
    "    :param coordinates_format:  Which format the list of coordinates is provided in\n",
    "                                will determine whether or not convert_to_degrees is run.\n",
    "    :type coordinates_format:  string\n",
    "    \n",
    "    :param write:  Flag to save results to a .csv file.\n",
    "    :type write:  boolean\n",
    "    \"\"\"\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Iterate through our list of coordinate tuples\n",
    "    for target in coordinates_list:\n",
    "        query_results = \"None\"\n",
    "        print(\"...checking {0}...\".format(target))\n",
    "        \n",
    "        # Convert each pair of coordinates to degrees if necessary\n",
    "        if coordinates_format.lower() == \"deg\":\n",
    "            in_degrees = target\n",
    "        else:\n",
    "            in_degrees = convert_to_degrees(target[0], target[1])\n",
    "        \n",
    "        # Submit an initial count query\n",
    "        count = filtered_position_query(in_degrees)\n",
    "        \n",
    "        # If the count is within a valid range, submit the full query\n",
    "        if count > 0 and count < 50000:\n",
    "            query_results = filtered_position_query(in_degrees, count=False)\n",
    "            nearby_targets = analyze_query_results(in_degrees, query_results)\n",
    "            \n",
    "            # Generate a filename and write CSV table if 'write' enabled\n",
    "            if write:\n",
    "                filename = \"results_{0}_{1}.csv\".format(target[0], target[1])\n",
    "                filename = write_to_csv_file(query_results, filename)\n",
    "            \n",
    "        # Skip if too many results are found\n",
    "        elif count > 50000:\n",
    "            print(\"More than 50,000 results found!  Please narrow your query.\")\n",
    "            \n",
    "        # Skip if no results are found\n",
    "        elif count == 0:\n",
    "            print(\"No nearby observations found for {0}\".format(target))\n",
    "            \n",
    "        results.append(query_results)\n",
    "            \n",
    "    # Return the list of all query result dictionaries\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUR_COORDINATES_LIST = [('04h16m09.370s', '-24d04m20.50s'),\n",
    "                        ('05h42m15s', '+48d22m43s'),\n",
    "                        ('19h45m01.190s', '-14d45m15.79s'),\n",
    "                        ('20h20m20.20s', '+20d20m20.20s')\n",
    "                       ]\n",
    "OUR_QUERY_RESULTS = check_multiple_targets(OUR_COORDINATES_LIST, \"icrs\", write=False)    # Change the 'write' flag to save .csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"search-by-name\"></a>\n",
    "<h3>Getting coordinates from stationary target names</h3>\n",
    "<p>Using the API also gives us access to the name-resolver service, which allows us to input a list of target names instead of coordinates.  The returned coordinates are already in degrees, so we can also skip the convert_to_degrees module.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_target_names(target_list):\n",
    "    \"\"\"\n",
    "    Look up a list of target names using the MAST lookup service and return\n",
    "    a list of coordinates.\n",
    "    \n",
    "    :param target_list:  The list of targets to be resolved.\n",
    "    :type target_list:  list\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set up an empty list for coordinate results and iterate through the list of target names\n",
    "    coordinates_list = []\n",
    "    for target_name in target_list:\n",
    "        \n",
    "        # Make a resolver request with the current target name\n",
    "        resolverRequest = {'service':'Mast.Name.Lookup',\n",
    "                           'params':{'input':target_name,\n",
    "                                     'format':'json'}\n",
    "                          }\n",
    "        headers, resolvedObjectString = mastQuery(resolverRequest)\n",
    "        resolvedObject = json.loads(resolvedObjectString)\n",
    "        \n",
    "        # If the target name was not found, we will run into IndexErrors when we try to set these \n",
    "        # variables\n",
    "        try:\n",
    "            target_ra = resolvedObject['resolvedCoordinate'][0]['ra']\n",
    "            target_dec = resolvedObject['resolvedCoordinate'][0]['decl']\n",
    "            canonical_name = resolvedObject['resolvedCoordinate'][0]['canonicalName']\n",
    "        except IndexError:\n",
    "            print(\"{0} not found\".format(target_name))\n",
    "            continue\n",
    "            \n",
    "        # Add the coordinates as a tuple to the list\n",
    "        target_coords = (target_ra, target_dec)\n",
    "        coordinates_list.append(target_coords)\n",
    "        print(\"Found {0} at {1}\".format(canonical_name, target_coords))\n",
    "        \n",
    "    # Return the list of coordinate tuples\n",
    "    return coordinates_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUR_TARGETS_LIST = ['M92',\n",
    "                    '30 Doradus',\n",
    "                    'Dumbbell Nebula',\n",
    "                    'Fake Test Galaxy'\n",
    "                   ]\n",
    "NEW_COORDINATES_LIST = resolve_target_names(OUR_TARGETS_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>With our list of names resolved we can send our new list of coordinates to our previous query module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_QUERY_RESULTS = check_multiple_targets(NEW_COORDINATES_LIST, \"deg\", write=False)    # Change the 'write' flag to save .csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"moving-targets\"></a>\n",
    "<h3>Searching for moving targets (keyword searches on target_name)</h3>\n",
    "<p>Moving targets are a bit trickier since we do not have a single set of coordinates to search against.  Instead, we'll look for matching entries in the target_name field and we'll use the freeText paramter with wildcards to find any close matches.  Again, we'll begin with an initial \"COUNT_BIG(*)\" query to get a results count first.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_keyword_query(keyword, count=True):\n",
    "    \"\"\"\n",
    "    Construct a filtered mashup request to send to the mastQuery function.  This\n",
    "    will search for a given keyword within the 'target_name' field and return\n",
    "    any results including wildcards.\n",
    "    \n",
    "    :param keyword:  The keyword to search for within 'target_name'.\n",
    "    :type keyword:  string\n",
    "    \n",
    "    :param count:  Flag to submit a full query or a count query.  Sends count\n",
    "                   by default.\n",
    "    :type count:  boolean\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use count flag to determine the columns queried\n",
    "    if count:\n",
    "        columns = \"COUNT_BIG(*)\"    # \"COUNT_BIG(*)\" will only get a count of the results\n",
    "    else:\n",
    "        columns = \"*\"\n",
    "        \n",
    "    # Construct the mashup request\n",
    "    service = \"Mast.Caom.Filtered\"\n",
    "    filters = [{\"paramName\":\"calib_level\", \"values\":[\"-1\"]},\n",
    "               {\"paramName\":\"obs_collection\", \"values\":[\"JWST\"]},\n",
    "               {\"paramName\":\"target_name\", \"values\":[],\"freeText\":\"%\"+keyword+\"%\"}\n",
    "              ]\n",
    "    mashupRequest = {\"service\":service,\n",
    "                     \"format\":\"json\",\n",
    "                     \"params\":{\"columns\":columns,\n",
    "                               \"filters\":filters\n",
    "                              }\n",
    "                    }\n",
    "\n",
    "    # Submit the MAST query\n",
    "    headers,outString = mastQuery(mashupRequest)\n",
    "    queryResults = json.loads(outString)\n",
    "    \n",
    "    # Return the results, depending on the type of query submitted\n",
    "    if count:\n",
    "        data = queryResults['data']\n",
    "        count = data[0]['Column1']\n",
    "        return count\n",
    "    else:\n",
    "        return queryResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JUPITER_COUNT = filtered_keyword_query(\"Jupiter\")\n",
    "print(JUPITER_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We find 126 target names containing \"Jupiter\", so we'll go ahead and submit the full query.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JUPITER_QUERY = filtered_keyword_query(\"Jupiter\", count=False)\n",
    "display_results(JUPITER_QUERY, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>With query results in hand we'll build a module to analyze our moving target output.  We'll want lists of the target names we matched with and which programs these are found in.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_matches(queryResults):\n",
    "    \"\"\"\n",
    "    Create a list of the unique target names that were returned by the filtered_keyword_query.\n",
    "    Also generate a link to each nearby program found.\n",
    "    \n",
    "    :param queryResults:  Full results from a MAST query.\n",
    "    :type queryResults:  dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set up initial variables\n",
    "    data = queryResults['data']\n",
    "    targets = []\n",
    "    programs = []\n",
    "    \n",
    "    # For each query result, pull out the target_name and proposal_id values\n",
    "    for obs in data:\n",
    "        current_target = obs['target_name']\n",
    "        current_program = obs['proposal_id']\n",
    "        targets.append(current_target)\n",
    "        programs.append(current_program)\n",
    "        \n",
    "    # Get the unique sets of target_name and proposal_id values\n",
    "    unique_targets = sorted(list(set(targets)))\n",
    "    unique_programs = sorted(list(set(programs)))\n",
    "    \n",
    "    # Output our results\n",
    "    print(\"Matched the keyword to: {0}\".format(unique_targets))\n",
    "    for p in unique_programs:\n",
    "        address = \"https://jwst.stsci.edu/observing-programs/program-information?id={0}\".format(p)\n",
    "        print(\"Found planned observations in {0}: {1}\".format(p, address))\n",
    "        \n",
    "    # Return the list of unique target names\n",
    "    return unique_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JUPITER_MATCHES = keyword_matches(JUPITER_QUERY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Copying our multiple targets module from above, with a few tweaks we can now run back-to-back queries on a list of moving target names.  We can also incorporate the write_to_csv_file module to automatically save all our results for further inspection.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_multiple_keywords(keywords_list, write):\n",
    "    \"\"\"\n",
    "    Perform multiple filtered MAST queries based on a list of keywords to look\n",
    "    for within the 'target_name' field.  Analyze the results and write them to\n",
    "    a .csv file if requested.\n",
    "    \n",
    "    :param keywords_list:  List of target keywords to search for in the 'target_name'\n",
    "                           field.\n",
    "    :type keywords_list:  list\n",
    "    \n",
    "    :param write:  Flag whether or not the results are save in a .csv file.\n",
    "    :type write:  boolean\n",
    "    \"\"\"\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Iterate through our list of target_name keywords\n",
    "    for target in keywords_list:\n",
    "        query_results = \"None\"\n",
    "        print(\"...checking {0}...\".format(target))\n",
    "        \n",
    "        # Submit an initial count query\n",
    "        count = filtered_keyword_query(target)\n",
    "        \n",
    "        # If the count is within a valid range, submit the full query\n",
    "        if count > 0 and count < 50000:\n",
    "            query_results = filtered_keyword_query(target, count=False)\n",
    "            targ_names = keyword_matches(query_results)\n",
    "            \n",
    "            # Generate a filename and write CSV table if 'write' enabled\n",
    "            if write:\n",
    "                filename = \"results_{0}.csv\".format(target)\n",
    "                filename = write_to_csv_file(query_results, filename)\n",
    "            \n",
    "        # Skip if too many results are found\n",
    "        elif count > 50000:\n",
    "            print(\"More than 50,000 results found!  Please narrow your query.\")\n",
    "            \n",
    "        # Skip if no results are found\n",
    "        elif count == 0:\n",
    "            print(\"No target_name matches found for {0}\".format(target))\n",
    "            \n",
    "        results.append(query_results)\n",
    "        \n",
    "    # Return the list of query result dictionaries\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUR_MOVING_TARGETS = [\"Jupiter\",\n",
    "                      \"Titan\",\n",
    "                      \"Ceres\",\n",
    "                      \"Sun\"\n",
    "                     ]\n",
    "MOVING_MATCHES = check_multiple_keywords(OUR_MOVING_TARGETS, write=False)    # Change the 'write' flag to save .csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"send-to-aladin\"></a>\n",
    "<h3>Visualizing results with Aladin</h3>\n",
    "<p>Now that we have some idea which of our targets may have planned JWST observations nearby, it may help to plot the existing planned observations in the area.  The <a href=\"https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html\" target=\"_blank\">MAST Portal</a> handles this automatically, but we can also make a simple display with footprints here using Aladin Lite.  HOWEVER, these footprints do not currently take into account some factors such as telescope rotation/orientation, or offsets from the main pointing.  These footprints only represent an approximation of the instrument FOV's.</p>\n",
    "<p>First, we'll need a function to extract the provided region information from our previous query results.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polygons(queryResults):\n",
    "    \"\"\"\n",
    "    Extract 's_region' information from a set of MAST query results.  Only\n",
    "    returns the unique set of footprints found.\n",
    "    \n",
    "    :param queryResults:  Full results from a MAST query.\n",
    "    :type queryResults:  dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    # We're only interested in the 'data' dictionary from the query results here\n",
    "    data = queryResults['data']\n",
    "    polygons = []\n",
    "    \n",
    "    # Iterate through each observation\n",
    "    for obs in data:\n",
    "        region = obs['s_region']\n",
    "        individual = region[7:].split(\" \")    # Cut off prepending 'POLYGON'\n",
    "        individual = list(filter(None, individual))    # Eliminate empty entries from extra spaces\n",
    "        shape = []\n",
    "        \n",
    "        # Pair off the entries into RA, Dec coordinates\n",
    "        while len(individual) > 1:\n",
    "            coordinate = [individual[0], individual[1]]\n",
    "            shape.append(coordinate)\n",
    "            individual = individual[2:]\n",
    "            \n",
    "        # We can ignore repeated footprints\n",
    "        if shape in polygons:\n",
    "            continue\n",
    "        else:\n",
    "            print(shape)\n",
    "            polygons.append(shape)\n",
    "            \n",
    "    # Return the list of coordinate lists\n",
    "    return polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_TO_PLOT = OUR_QUERY_RESULTS[2]\n",
    "TEST_REGIONS = get_polygons(RESULTS_TO_PLOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>With our coordinates and footprint information, we'll construct a string to embed an Aladin Lite script into HTML.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_aladin_html(coordinates, footprints=None):\n",
    "    \"\"\"\n",
    "    Construct an HTML-formatted string to embed an Aladin Lite viewer script,\n",
    "    which will center on a set of given coordinates and draw any provided\n",
    "    footprints in overlays.\n",
    "    \n",
    "    :param coordinates:  A single set of coordinates in degrees.\n",
    "    :type coordinates:  tuple\n",
    "    \n",
    "    :param footprints:  A list of any polygon coordinates found in the 's_region'\n",
    "                        field from MAST query results.\n",
    "    :type footprints:  list\n",
    "    \"\"\"\n",
    "    \n",
    "    # Format an RA/Dec string for Aladin\n",
    "    ra = str(coordinates[0])\n",
    "    dec = str(coordinates[1])\n",
    "    coords = ra + \", \" + dec\n",
    "    \n",
    "    # Create a unique div ID, allowing for multiple windows\n",
    "    div = \"aladin-lite-\" + ra.replace(\".\", \"\") + dec.replace(\".\", \"\")\n",
    "    \n",
    "    # Begin constructing the HTML string with Aladin embedded\n",
    "    aladin_string = \"\"\"<!-- include Aladin Lite CSS file in the head section of your page -->\n",
    "    <link rel=\"stylesheet\" href=\"//aladin.u-strasbg.fr/AladinLite/api/v2/latest/aladin.min.css\" />\n",
    "\n",
    "    <!-- you can skip the following line if your page already integrates the jQuery library -->\n",
    "    <script type=\"text/javascript\" src=\"//code.jquery.com/jquery-1.12.1.min.js\" charset=\"utf-8\"></script>\n",
    "\n",
    "    <!-- insert this snippet where you want Aladin Lite viewer to appear and after the loading of jQuery -->\n",
    "    <div id='\"\"\" + div + \"\"\"' style=\"width:800px;height:800px;\"></div>\n",
    "    <script type=\"text/javascript\" src=\"//aladin.u-strasbg.fr/AladinLite/api/v2/latest/aladin.min.js\" charset=\"utf-8\"></script>\n",
    "    <script type=\"text/javascript\">\n",
    "        var aladin = A.aladin('#\"\"\" + div + \"\"\"', {survey: \"P/DSS2/color\", fov:0.5, target: '\"\"\" + coords + \"\"\"'});\n",
    "        var overlay = A.graphicOverlay({color: '#ee2345', lineWidth: 1});\n",
    "        aladin.addOverlay(overlay);\n",
    "    \"\"\"\n",
    "\n",
    "    # Add an overlay string for each footprint found\n",
    "    for region in footprints:\n",
    "        footprint = str(region)\n",
    "        overlay = \"overlay.addFootprints(A.polygon({0}));\".format(footprint)\n",
    "        aladin_string += overlay\n",
    "        \n",
    "    aladin_string += \"</script>\"\n",
    "    \n",
    "    # Return the full constructed string\n",
    "    return aladin_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COORDINATES_TO_PLOT = OUR_COORDINATES_LIST[2]\n",
    "PLOT_IN_DEGREES = convert_to_degrees(COORDINATES_TO_PLOT[0], COORDINATES_TO_PLOT[1])\n",
    "ALADIN_HTML = make_aladin_html(PLOT_IN_DEGREES, TEST_REGIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Next, we'll need to access IPython's core library for running HTML code inside a notebook.  Then we can use that to execute the HTML code we constructed and view the resulting plot, which retains Aladin Lite's pan and zoom capabilities as well as the 'Export view as PNG' feature.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(ALADIN_HTML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
