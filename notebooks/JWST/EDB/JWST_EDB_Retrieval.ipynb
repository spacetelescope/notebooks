{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JWST Engineering Data Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial will show you how to retrieve JWST engineeering data and use it in the context of a python session. The [Engineering Data](https://outerspace.stsci.edu/pages/viewpage.action?spaceKey=DraftMASTDOCS&title=.Engineering+Data+v1.3) chapter of the [JWST Archive Manual](https://outerspace.stsci.edu/pages/viewpage.action?spaceKey=DraftMASTDOCS&title=.JWST+Archive+Manual+v1.2) describes how data from thousands of engineering telemetry points on JWST are stored in the Engineering Database in the form of timeseries. These data may be searched by means of an identifier, or **mnenomic**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some quantities of interest require more than one mnemonic (a *tuple*) for meaningful analysis. This tutorial illustrates how to retrieve a tuple of mnenomics and visualize the result. In the following example timeseries will be retrieved for mnemonics: `SA_ZADUCMDX` and `SA_ZADUCMDY` which are the *x-* and *y-* positions of the JWST [Fine Steering Mirror](https://jwst-docs.stsci.edu/jwst-observatory-hardware/jwst-telescope). \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<span style=\"color:black\">\n",
    "    JWST Engineering data retrieval is restricted to authorized persons prior to the completion of instrument commissioning.  \n",
    "    \n",
    "</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The workflow consists of: \n",
    "* Fetch your MAST.auth token\n",
    "* Define the attributes for the mnemonics of interest \n",
    "* Construct the names of files to contain the mnemonic time series\n",
    "* Call the web service to fetch the data and return files containing the timeseries\n",
    "* Split the data into mini-series at time boundaries\n",
    "* Visualize the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Begin by importing the relevant python libraries to retrieve data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib.error\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a function to connect to the EDB web service and retrieve the data files. It will be used later in this tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_edb_datafiles(token, filenames, folder='testing', prefix=''):\n",
    "    '''\n",
    "    Download filenames to directory\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    token : str\n",
    "        Value of MAST.auth token\n",
    "    filenames : iterable\n",
    "        List of string-valued file names to contain the desired mnemonic timeseries\n",
    "    folder: str\n",
    "        Directory (relative to cwd) in which to write output files\n",
    "    prefix: str\n",
    "        Prefix in MAST server URL (blank except for developer testing)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "       Success status for each mnemonic retrieval\n",
    "    '''\n",
    "    \n",
    "    if not token:\n",
    "        msg = \"download_edb_datafiles() recieved an empty auth token\"\n",
    "        raise ValueError(msg)\n",
    "        \n",
    "    Path(folder).mkdir(exist_ok=True)\n",
    "    \n",
    "    opener = urllib.request.build_opener()\n",
    "    opener.addheaders = [(\"Authorization\", f\"token {token}\")]\n",
    "    urllib.request.install_opener(opener)\n",
    "    urlStr = \"https://mast.stsci.edu{}/api/v0.1/Download/file?uri=mast:jwstedb/{}\"\n",
    "    status = 0\n",
    "    for fname in filenames:\n",
    "        print(\n",
    "            f\"Downloading File: mast:jwstedb/{fname}\\n\",\n",
    "            f\" To: {folder}/{fname}\",\n",
    "        )\n",
    "        url = urlStr.format(prefix,fname)\n",
    "        try:\n",
    "            urllib.request.urlretrieve(url, filename=f\"{folder}/{fname}\")\n",
    "        except urllib.error.HTTPError:\n",
    "            print(\"  ***Error downloading file***\")\n",
    "            status = 1\n",
    "    \n",
    "    return status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch a MAST.auth Token\n",
    "\n",
    "You will need to pass a MAST.auth token for the webservice to authenticate your identity, and ensure that you are authorized to retrieve data. See https://auth.mast.stsci.edu/token to create one. The token is supplied as an argument to the calling routine, but it is best to retrieve it from the environment variable `$MAST_API_TOKEN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#token = 'Insert your token here'\n",
    "# But this is better:\n",
    "token = os.getenv(\"MAST_API_TOKEN\", '6363bc69796546ebb50aec529c2bb339')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Mnemonic Parameters\n",
    "\n",
    "Next, define the parameters of each mnemonic of interest. The parameters are:\n",
    "* The mnenomic name\n",
    "* Start time\n",
    "* End time\n",
    "\n",
    "The start and end times are in UTC and have a \"compact\" ISO-8601 formatting: `yyyymmddThhmmss`, where the **T** is a literal character. The definitions can be stored in multiple ways: here they will be stored in a python dictionary, which could be stored in an external `.yaml` file. In the companion script they are stored in an external `.csv` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the mnemonics of interest are a tuple, the start/end times are the same: from 0:00 on 2019 June to 0:00 the next day. Define these times first, followed by the full parameter dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SA_ZADUCMDX {'t_start': '20190601T000000', 't_end': '20190602T000000'}\n",
      "SA_ZADUCMDY {'t_start': '20190601T000000', 't_end': '20190602T000000'}\n"
     ]
    }
   ],
   "source": [
    "times = { \n",
    "         't_start': '20190601T000000',\n",
    "         't_end':   '20190602T000000'\n",
    "        }\n",
    "mnemonics = {\n",
    "            'SA_ZADUCMDX': times,\n",
    "            'SA_ZADUCMDY': times\n",
    "           }\n",
    "for m,v in mnemonics.items():\n",
    "    print(m, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct File Names\n",
    "\n",
    "The key to fetching data from the web service is to construct file names to contain the data for each mnemonic. The web service will parse the file names to determine how to query the engineering database and retrieve the timeseries of interest.\n",
    "\n",
    "The file names have the form: \n",
    "\n",
    "    `<mnemonic_name>-<t_start>-<t_end>.csv`\n",
    "    \n",
    "Use a dictionary comprehension to construct a list of file names; these will be passed to the webservice calling function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SA_ZADUCMDX-20190601T000000-20190602T000000.csv', 'SA_ZADUCMDY-20190601T000000-20190602T000000.csv']\n"
     ]
    }
   ],
   "source": [
    "fnames = ['-'.join([m, v['t_start'], v['t_end']]) + '.csv' for m,v in mnemonics.items()]\n",
    "print(fnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call the Webservice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the (optional) output folder name prior to the webservice call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub-directory where the data files will be written:\n",
    "subdir = 'edb_test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now call the EDB web service. The files containing data will be written to your local storage, in the specified subdirectory. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<span style=\"color:black\">\n",
    "    The webservice may take a long time (or timeout), depending upon the quantity of data in the timeseries within the chosen date range. The day-long time interval in this example returns nearly 340,000 rows.  \n",
    "    \n",
    "</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6363bc69796546ebb50aec529c2bb339'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading File: mast:jwstedb/SA_ZADUCMDX-20190601T000000-20190602T000000.csv\n",
      "  To: edb_test/SA_ZADUCMDX-20190601T000000-20190602T000000.csv\n",
      "  ***Error downloading file***\n",
      "Downloading File: mast:jwstedb/SA_ZADUCMDY-20190601T000000-20190602T000000.csv\n",
      "  To: edb_test/SA_ZADUCMDY-20190601T000000-20190602T000000.csv\n",
      "  ***Error downloading file***\n"
     ]
    }
   ],
   "source": [
    "status = download_edb_datafiles(token, fnames, folder=subdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data for Analysis\n",
    "\n",
    "Create a list of pandas dataframes from the mnemonics data that were just written to disk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = [pd.read_csv(subdir+'/'+f) for f in fnames]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the sizes of the dataframes are equal, and have a look at the first dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Dataframes have the same size? {}'.format(len(df[0]) == len(df[1])))\n",
    "df[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the Data Tuple\n",
    "\n",
    "Create an x-y plot for analysis. This is easy to do by plotting the Pandas dataframes. It is more interesting to add color to indicate successive moves of the FSM. Begin by loading a numeric and some Bokeh plotting libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook\n",
    "import bokeh.plotting as bp\n",
    "from bokeh.models import ColorBar, SingleIntervalTicker, FixedTicker, Range1d, Span\n",
    "from bokeh.palettes import Spectral10 as cm\n",
    "from bokeh.transform import linear_cmap\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# The following method is needed for bokeh display in a Notebook.\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Subseries in the Data\n",
    "\n",
    "Engineering data may contain periods of sampling between observations where the returned values do not change. The following function attempts to break up the timeseries by looking for these stretches of unchanging values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_breaks(x_data, y_data, max_flats=5):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_data : pandas.DataFrame\n",
    "        X-axis timeseries data.\n",
    "    y_data : pandas.DataFrame \n",
    "        Y-axis timeseries data.\n",
    "    max_flats : int, default=5\n",
    "        After this many data points with unchanging values, timeseries data will be broken up.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    list of pandas.DataFrame\n",
    "        Each DataFrame contains a continuous set of changing EDB timeseries data with X/Y-paired values.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the MJD and position values out of the DataFrames.\n",
    "    x_vals = x_data['euvalue'].values\n",
    "    x_dates = x_data['MJD'].values\n",
    "    y_vals = y_data['euvalue'].values\n",
    "    y_dates = y_data['MJD'].values\n",
    "    \n",
    "    # Combine the x and y data into a single DataFrame.\n",
    "    xy_frame = pd.DataFrame(data=x_dates, columns=['MJD'])\n",
    "    xy_frame['timestamp'] = x_data['theTime'].values\n",
    "    xy_frame['x_value'] = x_vals\n",
    "    xy_frame['y_value'] = y_vals\n",
    "    \n",
    "    # Scan the timeseries data to look for flat periods of no reading change.\n",
    "    results = []\n",
    "    m = 0\n",
    "    flat = 0\n",
    "    recording = True\n",
    "    \n",
    "    for n in range(1, len(x_vals)):\n",
    "        \n",
    "        # Make sure the x and y timestamps match.\n",
    "        if x_dates[n] == y_dates[n]:\n",
    "            \n",
    "            # Calculate the distance from the current positions to the following.\n",
    "            x_diff = np.abs(x_vals[n-1] - x_vals[n])\n",
    "            y_diff = np.abs(y_vals[n-1] - y_vals[n])\n",
    "            \n",
    "            # Multiple points with no change will stop recording and store the current series.\n",
    "            if (x_diff == 0 and y_diff == 0):\n",
    "                flat += 1\n",
    "                if not recording:\n",
    "                    continue\n",
    "                elif flat >= max_flats:\n",
    "                    size = (n-max_flats) - m\n",
    "                    if size > 1:\n",
    "                        results.append(xy_frame[m:n-(max_flats)])\n",
    "                    recording = False\n",
    "                    \n",
    "            # Start recording if changes detected.\n",
    "            elif (x_diff > 0 or y_diff > 0) and not recording:\n",
    "                flat = 0\n",
    "                m = n\n",
    "                recording = True\n",
    "    \n",
    "    # Capture the final series if still recording.\n",
    "    if recording and (n - m) > 1:\n",
    "            results.append(xy_frame[m:])\n",
    "        \n",
    "    print(\"returning {} timeseries\".format(len(results)))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report the start/end times of each identified subseries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_series = find_breaks(df[0], df[1], max_flats=5)\n",
    "for ss in split_series:\n",
    "    v = ss['timestamp'].values\n",
    "    print(\"    {0} - {1}\".format(v[0], v[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Segmented Timeseries\n",
    "\n",
    "The following function plots a single subseries of the x/y paired data and applies a color gradiant based on the associated time stamps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_x_v_y_color(data):\n",
    "    \"\"\"\n",
    "    Plot x-versus-y timeseries data with color mapping based on the timing.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pandas.DataFrame\n",
    "        A combined x & y timeseries data set.\n",
    "    \"\"\"\n",
    "    \n",
    "    mjd = data['MJD']\n",
    "    n_ticks = 10\n",
    "    \n",
    "    # Create a bokeh.plotting figure object.\n",
    "    n = bp.figure(plot_height=600, plot_width=900, match_aspect=True)\n",
    "    \n",
    "    # Set up a linear color map based on the MJD data.\n",
    "    mapper = linear_cmap(field_name='MJD', palette=cm ,low=min(mjd) ,high=max(mjd))\n",
    "    \n",
    "    # Add lines to make 0 axis a bit more obvious.\n",
    "    lw = 1.3\n",
    "    vline = Span(location=0, dimension='height', line_color='black', line_width=lw)\n",
    "    hline = Span(location=0, dimension='width', line_color='black', line_width=lw)\n",
    "    n.renderers.extend([vline, hline])\n",
    "    \n",
    "    # Add a circle plot of x vs y with the color map applied.\n",
    "    n.circle(source=data, x='x_value', y='y_value', fill_alpha=0.6, fill_color=mapper, line_color=None)\n",
    "    \n",
    "    # Translate legend values from MJD to time stamps.\n",
    "    indices = list(range(0, len(mjd), int(len(mjd)/n_ticks)))\n",
    "    tick_dict = {mjd.values[x]: data['timestamp'].values[x] for x in indices}\n",
    "    ticks = FixedTicker(ticks=list(tick_dict.keys()))\n",
    "    \n",
    "    # Add a color bar legend for the MJD data.\n",
    "    color_bar = ColorBar(color_mapper=mapper['transform'], \n",
    "                         width=12,\n",
    "                         ticker=ticks,\n",
    "                         major_label_overrides=tick_dict,\n",
    "                         location=(0,0), \n",
    "                         label_standoff=45,\n",
    "                         )\n",
    "    n.add_layout(color_bar, 'right')\n",
    "    \n",
    "    # Display the figure.\n",
    "    bp.show(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following command you can update the index to change which timeseries you are plotting. Once the plot renders, use the plot control tools on the upper right to pan, zoom, and save the plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_x_v_y_color(split_series[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Resources\n",
    "* The [JWST Engineering Database Portal](https://mast.stsci.edu/portal_jwst/Mashup/Clients/jwstedb/jwstedb.html)\n",
    "* The JWST Archive Manual chapter Engineering Data\n",
    "\n",
    "## About this Notebook\n",
    "This notebook was developed by MAST staff, chiefly Dick Shaw, Peter Forshay, and Bernie Shiao. \n",
    "\n",
    "Last updated: 2021-Sep-23\n",
    "\n",
    "For support, please contact the Archive HelpDesk at archive@stsci.edu. <img style=\"float: right;\" src=\"https://raw.githubusercontent.com/spacetelescope/notebooks/master/assets/stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"Space Telescope Logo\" width=\"200px\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
