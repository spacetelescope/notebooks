{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"topD\"></a>\n",
    "\n",
    "# Downloading COS Data\n",
    "\n",
    "# Learning Goals\n",
    "<font size=\"5\"> This Notebook is designed to walk the user (<em>you</em>) through: <b>Downloading existing Cosmic Origins Spectrograph (<em>COS</em>) data from the online archive</b></font>\n",
    "\n",
    "**0. [Introduction](#introDl)**\n",
    "\n",
    "\\- 0.1. [A one-cell summary of this Notebook's key points](#onecellDl) \n",
    "\n",
    "**1. [Using the web browser interface](#mastD)**\n",
    "\n",
    "\\- 1.1. [The Classic HST Web Search](#mastD)\n",
    "\n",
    "\\- 1.2. [Searching for a Series of Observations on the Classic Web Search](#WebSearchSeriesD)\n",
    "\n",
    "\\- 1.3. [The MAST Portal](#mastportD)\n",
    "\n",
    "\\- 1.4. [Searching for a Series of Observations on the MAST Portal](#mastportSeriesD)\n",
    "\n",
    "**2. [Using the `Python` module `Astroquery`](#astroqueryD)**\n",
    "\n",
    "\\- 2.1. [Searching for a single source with Astroquery](#Astroquery1D)\n",
    "\n",
    "\\- 2.2. [Narrowing Search with Observational Parameters](#NarrowSearchD)\n",
    "\n",
    "\\- 2.3. [Choosing and Downloading Data Products](#dataprodsD)\n",
    "\n",
    "\\- 2.4. [Using astroquery to find data on a series of sources](#Astroquery2D)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing how to access the data\n",
    "\n",
    "**This Notebook explains three methods of accessing COS data hosted by the STScI Mikulski Archive for Space Telescopes (MAST).**\n",
    "You may read through all three, or you may wish to focus on a particular method which best suits your needs. \n",
    "**Please use the table below to determine which section on which to focus.**\n",
    "\n",
    "||The [HST Mission Search (Web Interface)](https://archive.stsci.edu/hst/search.php)|The [General MAST Portal (Web Interface)](https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html)|The [`Astroquery` (`Python` Interface)](http://astroquery.readthedocs.io/)|\n",
    "|-|-|-|-|\n",
    "||- User-friendly point-and-click searching|- Very user-friendly point-and-click searching|- Requires a bit of `Python` experience|\n",
    "||- Advanced **mission-specific** search parameters, including: central wavelength, detector, etc.|- Lacks some mission-specific search parameters|- Allows for programmatic searching and downloads|\n",
    "||- Easy to download selected data|- Easy to download selected data|- Best for large datasets|\n",
    "|||||\n",
    "|***Use this method if...***   |*...You're unfamiliar with `Python` and need to search for data by cenwave*|*...You're exploring lots of data and you don't need to search by cenwave*|*...You know `Python` and have an idea of what data you're looking for, or you have a lot of data*|\n",
    "|***Described in...***|*[Section 1.1](#mastD)*|*[Section 1.3](#mastportD)*|*[Section 2.1](#astroqueryD)*|\n",
    "\n",
    "*Note* that these are only recommendations, and you may prefer another option. For most purposes, the writer of this tutorial recommends the `Astroquery` `Python` interface, unless you are not at all comfortable using python or you are primarily interested in exploring the available data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=introDl></a>\n",
    "\n",
    "# 0. Introduction\n",
    "**The Cosmic Origins Spectrograph ([*COS*](https://www.nasa.gov/content/hubble-space-telescope-cosmic-origins-spectrograph)) is an ultraviolet spectrograph on-board the Hubble Space Telescope([*HST*](https://www.stsci.edu/hst/about)) with capabilities in the near ultraviolet (*NUV*) and far ultraviolet (*FUV*).**\n",
    "\n",
    "**This tutorial aims to prepare you to access the existing COS data of your choice by walking you through downloading a processed spectrum, as well as various calibration files obtained with COS.**\n",
    "\n",
    "- For an in-depth manual to working with COS data and a discussion of caveats and user tips, see the [COS Data Handbook](https://hst-docs.stsci.edu/display/COSDHB/).\n",
    "- For a detailed overview of the COS instrument, see the [COS Instrument Handbook](https://hst-docs.stsci.edu/display/COSIHB/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=onecellDl></a>\n",
    "\n",
    "### 0.1. A one-cell summary of this Notebook's key points:\n",
    "\n",
    "While the rest of this Notebook will walk you through each step and decision made when downloading COS data, the following code cell serves as a summary for the Notebook. It contains the key material condensed into a single code cell, without much explanation. If this is all the help you need, great! If you still have questions, read on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code cell condenses the key material of the Notebook into a single cell summary.\n",
    "# 1. Import the necessary libraries:\n",
    "# For searching and downloading from the MAST archive:\n",
    "from astroquery.mast import Observations\n",
    "# For handling system paths:\n",
    "from pathlib import Path\n",
    "\n",
    "# 2. Download an example dataset using astroquery:\n",
    "# 2.1. Find all the observations from a single HST Proposal:\n",
    "# We'll search for a program with Proposal ID 15366\n",
    "# A list of search criteria can be found by running: Observations.get_metadata('observations')\n",
    "obs_from_proposal = Observations.query_criteria(proposal_id=\"15366\")\n",
    "\n",
    "# 2.2. Find all the data products for these observations:\n",
    "# These include all the files associated with your observation, from raw data to fully-calibrated spectra or images\n",
    "products_from_proposal = Observations.get_product_list(obs_from_proposal)\n",
    "\n",
    "# 2.3. Tell the user how many total files were found:\n",
    "print(f\"Found {len(products_from_proposal)} data products\")\n",
    "\n",
    "# 2.4. Filter to a specific subset of these products:\n",
    "# Here we filter to (I) the X1DSUM files, which are the final 1-dimensional extracted spectra,\n",
    "# and (II) the association files, which list related exposures which were combined into the X1DSUM\n",
    "products_to_download = Observations.filter_products(\n",
    "    products_from_proposal,\n",
    "    productSubGroupDescription=[\"X1DSUM\", \"ASN\"] # Filters to only the X1DSUM and ASN files\n",
    ")\n",
    "\n",
    "# 2.5. Download the filtered products:\n",
    "download_table = Observations.download_products(products_to_download)\n",
    "\n",
    "# 2.6. Gather the downloaded files:\n",
    "# Turn string paths to the files into python pathlib.Path objects\n",
    "# Then make lists of these local paths, aggregated by type of file, and print to the user.\n",
    "onecell_x1dsum_products = [Path(local_path) for local_path in \\\n",
    "                           download_table[\"Local Path\"] if \"x1dsum\" in local_path]\n",
    "onecell_asn_products = [Path(local_path) for local_path in \\\n",
    "                        download_table[\"Local Path\"] if \"asn\" in local_path]\n",
    "print(\"Downloaded X1DSUM Files: \\n\", onecell_x1dsum_products,\n",
    "      \"\\nDownloaded ASN Files: \\n\", onecell_asn_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, returning to our more detailed walkthrough...\n",
    "\n",
    "<font size=\"5\"> We will define a few directories in which to place our data.</font>\n",
    "\n",
    "And to create new directories, we'll import `pathlib.Path`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import for: working with system paths\n",
    "from pathlib import Path\n",
    "\n",
    "# This will be an important directory for the Notebook, where we save data\n",
    "data_dir = Path('./data/')\n",
    "data_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"downloadD\"></a>\n",
    "# 1. Downloading the data through the browser interface\n",
    "\n",
    "One can search for COS data from both a browser-based Graphical User Interface (*gui*) and a `Python` interface. This Section (1) will examine two web interfaces. [Section 2](#astroqueryD) will explain the `Python` interface.\n",
    "\n",
    "*Note, there are other, more specialized ways to query the mast API not discussed in this Notebook. An in-depth MAST API tutorial can be found [here](https://mast.stsci.edu/api/v0/MastApiTutorial.html).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"mastD\"></a>\n",
    "## 1.1 The Classic HST Web Search\n",
    "**A browser gui for searching *specifically* through [HST archival data can be found here](http://archive.stsci.edu/hst/search.php). We will be discussing *this* HST search in the section below.**\n",
    "As of September, 2021, two other portals also allow access to the same data:\n",
    "* A newer HST-specific search page ([here](https://mast.stsci.edu/search/hst/ui/#/)). Most downloading difficulties have been solved with this new site, and upcoming versions of this tutorial will focus on its use.\n",
    "* A more general MAST gui, which also allows access to data from other telescopes such as TESS, but does not offer all HST-specific search parameters. We will discuss this interface in [Section 1.3](#mastportD).\n",
    "\n",
    "The search page  of the HST interface is laid out as in fig. 1.1:\n",
    "### Fig 1.1\n",
    "<center><img src=./figures/Mast_hst_searchformQSO.png width =\"900\" title=\"MAST Archive search form for a COS data query\"> </center>\n",
    "\n",
    "\n",
    "where here we have indicated we would like to find all archival science data from the **COS far-ultraviolet (FUV) configuration**, taken with any grating while looking at Quasi-Stellar Objects (QSO) within a 3 arcminute radius of (1hr:37':40\", +33d 09m 32s). The output columns we have selected to see are visible in the bottom left of Fig 1.1.\n",
    "\n",
    "Note that if you have a list of coordinates, Observation ID(s), etc. for a series of targets you can click on the \"File Upload Form\" and attach your list of OBSIDs or identifying features. Then specify which type of data your list contains using the \"File Contents\" drop-down menu.\n",
    "\n",
    "Figure 1.2 shows the results of our search shown in Fig 1.1.\n",
    "### Fig 1.2\n",
    "<center><img src=figures/QSO_MastSearchRes.png width =\"900\" title=\"MAST Archive search results for a COS data query\"> </center>\n",
    "\n",
    "\n",
    "**We now choose our dataset.**\n",
    "We rather arbitrarily select **`LCXV13050`** because of its long exposure time, taken under an observing program described as:\n",
    "> \"Project AMIGA: Mapping the Circumgalactic Medium of Andromeda\"\n",
    "\n",
    "This is a Quasar known as [3C48](http://simbad.u-strasbg.fr/simbad/sim-basic?Ident=3c48&submit=SIMBAD+search), one of the first quasars discovered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clicking on the dataset, we are taken to a page displaying a preview spectrum (Fig 1.3).\n",
    "### Fig 1.3\n",
    "\n",
    "<center><img src=./figures/QSOPreviewSpec.png width =\"900\" title=\"MAST Archive preview spectrum of LCXV13050\"> </center>\n",
    "\n",
    "We now return to the [search page](http://archive.stsci.edu/hst/search.php) and enter in LCXV13050 under \"Dataset\" with no other parameters set. Clicking \"search\", now we see a single-rowed table with *just* our dataset, and the option to download datasets. We mark the row we wish to download and click \"Submit marked data for retrieval from STDADS\". See Fig 1.4.\n",
    "\n",
    "### Fig 1.4\n",
    "\n",
    "<center><img src =figures/LCXV13050_res.png width =\"900\" title=\"MAST Archive dataset overview of LCXV13050\"> </center>\n",
    "\n",
    "Now we see a page like in Fig 1.5,\n",
    "where we can either sign in with STScI credentials, or simply provide our email to proceed without credentials. Generally, you may proceed anonymously, unless you are retrieving proprietary data to which you have access. Next, make sure to select \"Deliver the data to the Archive staging area\". Click \"Send Retrieval Request to ST-DADS\" and you will receive an email with instructions on downloading the data.\n",
    "\n",
    "### Fig 1.5\n",
    "<center><img src =figures/DownloadOptions.png width =\"900\" title=\"Download Options for LCXV13050\"> </center>\n",
    "\n",
    "Now the data is \"staged\" on a MAST server, and you need to download it to your local computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the staged data\n",
    "We demonstrate three methods of downloading your staged data: \n",
    "1. If your terminal supports it, you may [use the `wget` tool](#wgetDLD). \n",
    "2. However if that does not work, we recommend [using a secure ftp client application](#download_ftps_cyduckD). \n",
    "3. Finally, if you would instead like to download *staged data* programmatically, you may [use the Python `ftplib` package](#download_ftps_funcD), as described [here](https://archive.stsci.edu/ftp.html) in STScI's documentation of the MAST FTP Service. For your convenience, we have built the `download_anonymous_staged_data` function below, which will download anonymously staged data via ftps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=wgetDLD></a>\n",
    "#### Downloading the staged data with `wget`\n",
    "**If you are connected to the STScI network, either in-person or via a virtual private network (VPN), you should use the `wget` command as in the example below:**\n",
    "\n",
    "`wget -r --ftp-user=anonymous --ask-password ftps://archive.stsci.edu/stage/anonymous/anonymous<directory_number> --directory-prefix=<data_dir>`\n",
    "\n",
    "where `directory_number` is the number at the end of the anonymous path specified in the email you received from MAST and `data_dir` is the local directory where you want the downloaded data. \n",
    "You will be prompted for a password. Type in the email address you used, then press enter/return.\n",
    "\n",
    "Now all the data will be downloaded into a subdirectory of data_dir: `\"./archive.stsci.edu/stage/anonymous/anonymous<directory_number>/\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=download_ftps_cyduckD></a>\n",
    "#### Downloading the staged data with a secure ftp client application (`CyberDuck`)\n",
    "CyberDuck is an application which allows you to securely access data stored on another machine using ftps. To download your staged data using Cyberduck, first download the [Cyberduck](https://cyberduck.io) application (*free, with a recommended donation*). Next, open a new browser window (Safari, Firefox, and Google Chrome have all been shown to work,) and type in the following web address: `ftps://archive.stsci.edu/stage/anonymous<directory_number>`, where `directory_number` is the number at the end of the anonymous path specified in the email you received from MAST. For example, if the email specifies: \n",
    "> \"The data can be found in the directory...  /stage/anonymous/anonymous42822\"\n",
    "\n",
    "then this number is **42822**\n",
    "\n",
    "Your browser will attempt to redirect to the CyberDuck application. Allow it to \"Open CyberDuck.app\", and CyberDuck should open a finder window displaying your files. Select whichever files you want to download by highlighting them (command-click or control-click) then right click one of the highlighted files, and select \"Download To\". This will bring up a file browser allowing you to save the selected files to wherever you wish on your local computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=download_ftps_funcD></a>\n",
    "#### Downloading the staged data with `ftps`\n",
    "To download anonymously staged data programmatically with ftps, you may run the `download_anonymous_staged_data` function as shown here:\n",
    "\n",
    "```python\n",
    "download_anonymous_staged_data(email_used=\"my_email@stsci.edu\", directory_number=80552, outdir=\"./here_is_where_I_want_the_data\")\n",
    "```\n",
    "\n",
    "Which results in:\n",
    "```\n",
    "Downloading lcxv13050_x1dsum1.fits\n",
    "  Done\n",
    "...\n",
    "...\n",
    "Downloading lcxv13gxq_flt_b.fits\n",
    "  Done\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ftplib\n",
    "\n",
    "\n",
    "def download_anonymous_staged_data(email_used, directory_number, outdir=\"./data/ftps_download/\", verbose=True):\n",
    "    \"\"\"\n",
    "    A direct implementation of the MAST FTP Service webpage's ftplib example code.\n",
    "    Downloads anonymously staged data from the MAST servers via ftps.\n",
    "    Inputs:\n",
    "    email_used (str): the email address used to stage the data\n",
    "    directory_number (str or int): The number at the end of the anonymous filepath. i.e. if the email you received includes:\n",
    "      \"The data can be found in the directory...  /stage/anonymous/anonymous42822\", \n",
    "      then this number is 42822\n",
    "    outdir (str): Path to where the file will download locally.\n",
    "    verbose (bool): If True, prints name of each file downloaded.\n",
    "    \"\"\"\n",
    "    ftps = ftplib.FTP_TLS('archive.stsci.edu')  # Set up connection\n",
    "    # Login with anonymous credentials\n",
    "    ftps.login(user=\"anonymous\", passwd=email_used)\n",
    "    ftps.prot_p()  # Add protection to the connection\n",
    "    ftps.cwd(f\"stage/anonymous/anonymous{directory_number}\")\n",
    "    filenames = ftps.nlst()\n",
    "\n",
    "    outdir = Path(outdir)  # Set up the output directory as a path\n",
    "    outdir.mkdir(exist_ok=True)\n",
    "\n",
    "    for filename in filenames:  # Loop through all the staged files\n",
    "        if verbose:\n",
    "            print(\"Downloading \" + filename)\n",
    "        with open(outdir / filename, 'wb') as fp:  # Download each file locally\n",
    "            ftps.retrbinary('RETR {}'.format(filename), fp.write)\n",
    "        if verbose:\n",
    "            print(\"  Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"> <b>Well done making it this far!</b></font>\n",
    "\n",
    "Attempt the exercise below for some extra practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: *Searching the archive for TRAPPIST-1 data*\n",
    "\n",
    "[TRAPPIST-1](https://en.wikipedia.org/wiki/TRAPPIST-1) is a cool red dwarf with a multiple-exoplanet system. \n",
    "- Find its coordinates using the [SIMBAD Basic Search](http://simbad.u-strasbg.fr/simbad/sim-fbasic).\n",
    "- Use those coordinates in the [HST web search](https://archive.stsci.edu/hst/search.php) or the [MAST portal](https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html) to find all COS exposures of the system.\n",
    "- Limit the search terms to find the COS dataset taken in the COS far-UV configuration with the grating G130M.\n",
    "\n",
    "**What is the dataset ID, and how long was the exposure?**\n",
    "\n",
    "Place your answer in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=WebSearchSeriesD></a>\n",
    "## 1.2. Searching for a Series of Observations on the Classic HST Web Search\n",
    "\n",
    "Now let's try using the web interface's [file upload form](http://archive.stsci.edu/hst/search.php?form=fuf) to search for a series of observations by their dataset IDs. We're going to look for three observations of the same object, the white dwarf WD1057+719, taken with three different COS gratings. Two are in the FUV and one in the NUV. The dataset IDs are\n",
    "- LDYR52010\n",
    "- LBNM01040\n",
    "- LBBD04040\n",
    "\n",
    "So that we have an example list of datasets to input to the web search, we make a comma-separated-value txt file with these three obs_ids, and save it as `obsId_list.txt`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The three observation IDs we want to gather\n",
    "obsIdList = ['LDYR52010', 'LBNM01040', 'LBBD04040']\n",
    "obsIdList_length = len(obsIdList)\n",
    "\n",
    "with open('./obsId_list.txt', 'w') as f:  # Open up this new file in \"write\" mode\n",
    "    # We want a newline after each obs_id except the last one\n",
    "    for i, item in enumerate(obsIdList):\n",
    "        if i < obsIdList_length - 1:\n",
    "            f.writelines(item + \",\" + '\\n')\n",
    "        # Make sure we don't end the file with a blank line (below)\n",
    "        if i == obsIdList_length - 1:\n",
    "            f.writelines(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we link to this file under the **Local File Name** browse menu on the file upload form. We must set the **File Contents** term to Data ID, as that is the identifier we have provided in our file, and we change the **delimiter** to a comma.\n",
    "Because we are searching by Dataset ID, we don't need to specify any additional parameters to narrow down the data.\n",
    "\n",
    "### Fig 1.6\n",
    "<center><img src =figures/FUF_search.png width =\"900\" title=\"File Upload Search Form\"> </center>\n",
    "\n",
    "**We now can access all the datasets, as shown in Fig. 1.7:**\n",
    "\n",
    "### Fig 1.7\n",
    "<center><img src =figures/FUF_res.png width =\"900\" title=\"File Upload Search Results\"> </center>\n",
    "\n",
    "Now, to download all of the relevant files, we can check the **mark** box for all of them, and again hit  \"Submit marked data for retrieval from STDADS\". This time, we want to retrieve **all the calibration files** associated with each dataset, so we check the following boxes:\n",
    "- Uncalibrated\n",
    "- Calibrated\n",
    "- Used Reference Files\n",
    "\n",
    "(*See Fig. 1.8*)\n",
    "\n",
    "### Fig 1.8\n",
    "<center><img src =./figures/DownloadOptions_FUF.png width =\"900\" title=\"Download Options for multiple datasets\"> </center>\n",
    "\n",
    "\n",
    "The procedure from here is the same described above in Section 1.1. Now, when we download the staged data, we obtain multiple subdirectories with each dataset separated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = mastportD></a>\n",
    "## 1.3. The MAST Portal\n",
    "\n",
    "STScI hosts another web-based gui for accessing data, the [MAST Portal](https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html). This is a newer interface which hosts data from across many missions and allows the user to visualize the target in survey images, take quick looks at spectra or lightcurves, and manage multiple search tabs at once. Additionally, it handles downloads in a slightly more beginner-friendly manner than the current implementation of the Classic HST Search. This guide will only cover the basics of accessing COS data through the MAST Portal; you can find more in-depth documentation in the form of helpful video guides on the [MAST YouTube Channel](https://www.youtube.com/user/STScIMAST).\n",
    "\n",
    "**Let's find the same data we found in Section 1.1, on the QSO 3C48:**\n",
    "\n",
    "Navigate to the MAST Portal at <https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html>, and you will be greeted by a screen where the top looks like Fig. 1.9. \n",
    "### Fig 1.9\n",
    "<center><img src =figures/mastp_top.png width =\"900\" title=\"Top of MAST Portal Home\"> </center>\n",
    "\n",
    "Click on \"Advanced Search\" (boxed in red in Fig. 1.9). This will open up a new search tab, as shown in Fig. 1.10:\n",
    "### Fig 1.10\n",
    "<center><img src =figures/mastp_adv.png width =\"900\" title=\"The advanced search tab\"> </center>\n",
    "\n",
    "Fig 1.10 (above) shows the default search fields which appear. Depending on what you are looking for, these may or may not be the most helpful search fields. By unchecking some of the fields which we are not interested in searching by right now (boxed in green), and then entering the parameter values by which to narrow the search into each parameter's box, we generate Fig. 1.11 (below). One of the six fields (Mission) by which we are narrowing is boxed in a dashed blue line. The list of applied filters is boxed in red. A dashed pink box at the top left indicates that 2 records were found matching all of these parameters. To its left is an orange box around the \"Search\" button to press to bring up the list of results\n",
    "\n",
    "Here we are searching by:\n",
    "\n",
    "|**Search Parameter**|**Value**|\n",
    "|-|-|\n",
    "|Mission|HST|\n",
    "|Instrument|COS/FUV|\n",
    "|Filters|G160M|\n",
    "|Target Name|3C48|\n",
    "|Observation ID|LCXV\\* (*the star is a \"wild card\" value, so the search will find any file whose `obs_id` begins with LCXV*)|\n",
    "|Product Type|spectrum|\n",
    "\n",
    "### Fig 1.11\n",
    "<center><img src =figures/mastp_adv_2.png width =\"900\" title=\"The advanced search tab with some selections\"> </center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click the \"Search\" button (boxed in orange), and you will be brought to a page resembling Fig. 1.12. \n",
    "\n",
    "### Fig 1.12\n",
    "<center><img src =figures/mastp_res1.png width =\"900\" title=\"Results of MAST Portal search\"> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\"> <b>Above, in Fig 1.12</b>:</font>\n",
    "- The yellow box to the right shows the AstroView panel, where you can interactively explore the area around your target:\n",
    "  - click and drag to pan around\n",
    "  - scroll to zoom in/out\n",
    "- The dashed-blue box highlights additional filters you can use to narrow your search results.\n",
    "- The red box highlights a button you can click with *some* spectral datasets to pull up an interactive spectrum.\n",
    "- The green box highlights the \"Mark\" checkboxes for each dataset. \n",
    "- The black circle highlights the single dataset download button:\n",
    "   - **If you only need to download one or two datasets, you may simply click this button for each dataset**\n",
    "   - Clicking the single dataset download button will attempt to open a \"pop-up\" window, which you must allow in order to download the file. Some browsers will require you to manually allow pop-ups.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"mastportSeriesD\"></a>\n",
    "## 1.4. Searching for a Series of Observations on the MAST Portal\n",
    "\n",
    "<font size=\"4\"> <b>To download multiple datasets</b>:</font>\n",
    "The MAST portal acts a bit like an online shopping website, where you add your *data products* to the checkout *cart*/*basket*, then open up your cart to *checkout* and download the files.\n",
    "\n",
    "Using the checkboxes, mark all the datasets you wish to download (in this case, we'll download both LCXV13040 and LCXV13050). Then, click the \"Add data products to Download Basket\" button (circled in a dashed-purple line), which will take you to a \"Download Basket\" screen resembling Fig 1.13:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fig 1.13\n",
    "<center><img src =figures/mastp_cart2.png width =\"900\" title=\"MAST Portal Download Basket\"> </center>\n",
    "\n",
    "Each dataset contains *many* files, most of which are calibration files or intermediate processing files. You may or may not want some of these intermediate files in addition to the final product file.\n",
    "In the leftmost \"Filters\" section of the Download Basket page, you can narrow which files will be downloaded (boxed in red).\n",
    "By default, only the **minimum recommended products** (*mrp*) will be selected. In the case of most COS data, this will be the final spectrum `x1dsum` file and association `asn` file for each dataset. The mrp files for the first dataset (`LCXV13040`) are highlighted in yellow. These two mrp filetypes are fine for our purposes here; however if you want to download files associated with specific exposures, or any calibration files or intermediate files, you can select those you wish to download with the checkboxes in the file tree system (boxed in dashed-green)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For this tutorial, we simply select \"Minimum Recommended Products\" at the top left. With this box checked, all of the folders representing individual exposures are no longer visible.**\n",
    "Check the box labelled \"HST\" to select all files included by the filters, and click the \"Download Selected Items\" button at the top right (dashed-black circle). This will bring up a small window asking you what format to download your files as. For datasets smaller than several Gigabytes, the `Zip` format will do fine. Click Download, and a pop-up window will try to open to download the files. If no download begins, make sure to enable this particular pop-up, or allow pop-ups on the MAST page.\n",
    "\n",
    "**Your files should now be downloaded as a compressed `Zip` folder.**\n",
    "If you need help uncompressing the `Zip`ped files, check out these links for: [Windows](https://support.microsoft.com/en-us/windows/zip-and-unzip-files-8d28fa72-f2f9-712f-67df-f80cf89fd4e5) and [Mac](https://support.apple.com/guide/mac-help/zip-and-unzip-files-and-folders-on-mac-mchlp2528/mac). There are numerous ways to do this on Linux, however we have not vetted them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = astroqueryD></a>\n",
    "# 2. The Python Package `astroquery.mast`\n",
    "Another way to search for and download archived datasets is from within `Python` using the module [`astroquery.mast`](https://astroquery.readthedocs.io/en/latest/mast/mast.html). We will import one of this module's key submodules: `Observations`.\n",
    "\n",
    "*Please note* that the canonical source of information on this package is the [`astroquery` docs](https://astroquery.readthedocs.io/en/latest/) - please look there for the most up-to-date instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will import the following packages:\n",
    "\n",
    "- `astroquery.mast`'s submodule `Observations` for finding and downloading data from the [MAST](https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html) archive\n",
    "- `csv`'s submodule `reader` for reading in/out from a csv file of source names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading data from archive\n",
    "from astroquery.mast import Observations\n",
    "\n",
    "# Reading in multiple source names from a csv file\n",
    "from csv import reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=Astroquery1D></a>\n",
    "## 2.1. Searching for a single source with Astroquery\n",
    "\n",
    "There are *many* options for searching the archive with astroquery, but we will begin with a very general search using the coordinates we found for WD1057+719 in the last section to find the dataset with the longest exposure time using the COS/FUV mode through the G160M filter. We could also search by object name to have it resolved to a set of coordinates, with the function `Observations.query_object(objectname = '3C48')`.\n",
    "- Our coordinates were:      (11:00:34.126 +71:38:02.80). \n",
    "    - We can search these coordinates as sexagesimal coordinates, or convert them to decimal degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_1 = Observations.query_object(\n",
    "    \"11:00:34.126 +71:38:02.80\", radius=\"5 sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command has generated a table of objects called **\"query_1\"**. We can see what information we have on the objects in the table by printing its *`keys`*, and see how many objects are in the table with `len(query_1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We have table information on {len(query_1)} \"+\n",
    "      \"observations in the following categories/columns:\\n\")\n",
    "q1_keys = (query_1.keys())\n",
    "q1_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=NarrowSearchD></a>\n",
    "## 2.2. Narrowing Search with Observational Parameters\n",
    "Now we narrow down a bit with some additional parameters and sort by exposure time.\n",
    "The parameter limits we add to the search are:\n",
    "- *Only look for sources in the coordinate range between right ascension 165 to 166 degrees and declination +71 to +72 degrees*\n",
    "- *Only find observations in the UV*\n",
    "- *Only find observations taken with the COS instrument (either in its FUV or NUV configuration).*\n",
    "- *Only find spectrographic observations*\n",
    "- *Only find observations made using the COS grating \"G160M\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_2 = Observations.query_criteria(s_ra=[165., 166.], s_dec=[+71., +72.],\n",
    "                                      wavelength_region=\"UV\", instrument_name=[\"COS/NUV\", \"COS/FUV\"],\n",
    "                                      dataproduct_type=\"spectrum\", filters='G160M')\n",
    "\n",
    "# Next lines simplifies the columns of data we see to some useful data we will look at right now\n",
    "limq2 = query_2['obsid', 'obs_id', 'target_name', 'dataproduct_type', 'instrument_name',\n",
    "                'project', 'filters', 'wavelength_region', 't_exptime']\n",
    "# This is the index list in order of exposure time, increasing\n",
    "sort_order = query_2.argsort('t_exptime')\n",
    "print(limq2[sort_order])\n",
    "chosenObs = limq2[sort_order][-1]  # Grab the last value of the sorted list\n",
    "print(f\"\\n\\nThe longest COS/FUV exposure with the G160M filter is:\"+\n",
    "      f\"\\n\\n{chosenObs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Caution! </font>\n",
    "    \n",
    "<img src=./figures/warning.png width =\"60\" title=\"CAUTION\"> \n",
    "\n",
    "Please note that these queries are `Astropy` tables and do not always respond as expected for other data structures like `Pandas DataFrames`. For instance, the first way of filtering a table shown below is correct, but the second will consistently produce the *wrong result*. You *must* search and filter these tables by masking them, as in the first example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searching a table generated with a query\n",
    "# First, correct way using masking\n",
    "mask = (query_1['obs_id'] == 'lbbd01020')  # NOTE, obs_id must be lower-case\n",
    "print(\"Correct way yields: \\n\", query_1[mask]['obs_id'], \"\\n\\n\")\n",
    "\n",
    "# Second INCORRECT way\n",
    "print(\"Incorrect way yields: \\n\",\n",
    "      query_1['obs_id' == 'LBBD01020']['obs_id'], \"\\nwhich is NOT what we're looking for!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=dataprodsD></a>\n",
    "## 2.3. Choosing and Downloading Data Products\n",
    "\n",
    "**Now we can choose and download our data products from the archive dataset.**\n",
    "\n",
    "We will first generate a list of data products in the dataset: `product_list`. This will generate a large list, but we will only show the first 10 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_list = Observations.get_product_list(chosenObs)\n",
    "product_list[:10]  # Not the whole dataset, just first 10 lines/observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will download *just the* **minimum recommended products** (*mrp*) which are the fully calibrated spectrum (denoted by the suffix `_x1d` or here `x1dsum`) and the association file (denoted by the suffix `_asn`). We do this by setting the parameter `mrp_only` to True. The association file contains no data, but rather the metadata explaining which exposures produced the `x1dsum` dataset. The `x1dsum` file is the final product summed across all of the [fixed pattern noise positions](https://hst-docs.stsci.edu/cosdhb/chapter-1-cos-overview/1-1-instrument-capabilities-and-design#id-1.1InstrumentCapabilitiesandDesign-GratingOffset(FP-POS)GratingOffsetPositions(FP-POS)) (`FP-POS`). The `x1d` and `x1dsum<n>` files are intermediate spectra. Much more information can be found in the [COS Instrument Handbook](https://hst-docs.stsci.edu/display/COSIHB/).\n",
    "\n",
    "We would set `mrp_only` to False, if we wanted to download ***all*** the data from the observation, including: \n",
    "- support files such as the spacecraft's pointing data over time (`jit` files).\n",
    "- intermediate data products such as calibrated TIME-TAG data (`corrtag` or `corrtag_a`/`corrtag_b` files) and extracted 1-dimensional spectra averaged over exposures with a specific `FP-POS` value (`x1dsum<n>` files).\n",
    "\n",
    "<img src=./figures/warning.png width =\"60\" title=\"CAUTION\">\n",
    "\n",
    "However, use caution with downloading all files, as in this case, setting `mrp_only` to False results in the transfer of **7 Gigabytes** of data, which can take a long time to transfer and eat away at your computer's storage! In general, only download the files you need. On the other hand, often researchers will download only the raw data, so that they can process it for themselves. Since here we only need the final `x1dsum` and `asn` files, we only need to download 2 Megabytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloads = Observations.download_products(product_list, download_dir=str(\n",
    "    data_dir), extension='fits', mrp_only=True, cache=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: *Download the raw counts data on TRAPPIST-1*\n",
    "\n",
    "In the previous exercise, we found an observation COS took on TRAPPIST-1 system. In case you skipped Exercise 1, the observation's Dataset ID is `LDLM40010`.\n",
    "\n",
    "Use `Astroquery.mast` to download the raw `TIME-TAG` data, rather than the x1d spectra files. See the [COS Data Handbook Ch. 2](https://hst-docs.stsci.edu/cosdhb/chapter-2-cos-data-files/2-4-cos-data-products) for details on TIME-TAG data files. Make sure to get the data from both segments of the FUV detector (i.e. both `RAWTAG_A` and `RAWTAG_B` files). If you do this correctly, there should be five data files for each detector segment.\n",
    "\n",
    "*Note that some of the obs_id may appear in the table as slightly different, i.e.: ldlm40alq and ldlm40axq, rather than ldlm40010. The main obs_id they fall under is still ldlm40010, and this will still work as a search term. They are linked together by the association file described here in section 2.3.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=Astroquery2D></a>\n",
    "## 2.4. Using astroquery to find data on a series of sources\n",
    "In this case, we'll look for COS data around several bright globular clusters:\n",
    "- Omega Centauri\n",
    "- M5\n",
    "- M13\n",
    "- M15\n",
    "- M53\n",
    "\n",
    "We will first write a comma-separated-value (csv) file `objectname_list.csv` listing these sources by their common name. This is a bit redundant here, as we will immediately read back in what we have written; however it is done here to deliberately teach both sides of the writing/reading process, and as many users will find themselves with a csv sourcelist they must search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 5 sources we want to look for\n",
    "sourcelist = ['omega Centauri', 'M5', 'M13', 'M15', 'M53']\n",
    "# measures the length of the list for if statements below\n",
    "sourcelist_length = len(sourcelist)\n",
    "\n",
    "with open('./objectname_list.csv', 'w') as f:  # Open this new file in \"write\" mode\n",
    "    # We want a comma after each source name except the last one\n",
    "    for i, item in enumerate(sourcelist):\n",
    "        if i < sourcelist_length - 1:\n",
    "            f.writelines(item + \",\")\n",
    "        if i == sourcelist_length - 1:  # No comma after the last entry\n",
    "            f.writelines(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file we just wrote in \"read\" mode\n",
    "with open('./objectname_list.csv', 'r', newline='') as csvFile:\n",
    "    # This is the exact same list as `sourcelist`!\n",
    "    objList = list(reader(csvFile, delimiter=','))[0]\n",
    "\n",
    "print(\"The input csv file contained the following sources:\\n\", objList)\n",
    "\n",
    "# Make a dictionary, where each source name (i.e. \"M15\") corresponds to a list of its observations with COS\n",
    "globular_cluster_queries = {}\n",
    "for obj in objList:  # each \"obj\" is a source name\n",
    "    query_x = Observations.query_criteria(objectname=obj, radius=\"5 min\", instrument_name=[\n",
    "                                          'COS/FUV', 'COS/NUV'])  # query the area in +/- 5 arcminutes\n",
    "    # add this entry to the dictionary\n",
    "    globular_cluster_queries[obj] = (query_x)\n",
    "\n",
    "globular_cluster_queries  # show the dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excellent! You've now done the hardest part - finding and downloading the right data.** From here, it's generally straightforward to read in and plot the spectrum. We recommend you look into our tutorial on [Viewing a COS Spectrum](https://github.com/spacetelescope/notebooks/blob/master/notebooks/COS/ViewData/ViewData.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You finished this Notebook!\n",
    "### There are more COS data walkthrough Notebooks on different topics. You can find them [here](https://spacetelescope.github.io/COS-Notebooks/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## About this Notebook\n",
    "**Author:** Nat Kerman <nkerman@stsci.edu>\n",
    "\n",
    "**Updated On:** 2022-02-25\n",
    "\n",
    "> *This tutorial was generated to be in compliance with the [STScI style guides](https://github.com/spacetelescope/style-guides) and would like to cite the [Jupyter guide](https://github.com/spacetelescope/style-guides/blob/master/templates/example_notebook.ipynb) in particular.*\n",
    "\n",
    "## Citations\n",
    "\n",
    "If you use `astropy`, `matplotlib`, `astroquery`, or `numpy` for published research, please cite the\n",
    "authors. Follow these links for more information about citations:\n",
    "\n",
    "* [Citing `astropy`/`numpy`/`matplotlib`](https://www.scipy.org/citing.html)\n",
    "* [Citing `astroquery`](https://astroquery.readthedocs.io/en/latest/)\n",
    "\n",
    "---\n",
    "\n",
    "[Top of Page](#topD)\n",
    "<img style=\"float: right;\" src=\"https://raw.githubusercontent.com/spacetelescope/notebooks/master/assets/stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"Space Telescope Logo\" width=\"200px\"/> \n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Solutions:\n",
    "Note, that for many of these, there are multiple ways to get an answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will import:**\n",
    "- numpy to handle array functions\n",
    "- astropy.table Table for creating tidy tables of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulating arrays\n",
    "import numpy as np\n",
    "# Reading in data\n",
    "from astropy.table import Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex. 1 solution:\n",
    "dataset_id_ = 'LDLM40010'\n",
    "exptime_ = 12403.904\n",
    "print(f\"The TRAPPIST-1 COS data is in dataset {dataset_id_},\"+\n",
    "      f\" taken with an exosure time of {exptime_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ex. 2 solution:\n",
    "query_3 = Observations.query_criteria(obs_id='LDLM40010',\n",
    "                                      wavelength_region=\"UV\", instrument_name=\"COS/FUV\", filters='G130M')\n",
    "\n",
    "product_list2 = Observations.get_product_list(query_3)\n",
    "rawRowsA = np.where(product_list2['productSubGroupDescription'] == \"RAWTAG_A\")\n",
    "rawRowsB = np.where(product_list2['productSubGroupDescription'] == \"RAWTAG_B\")\n",
    "rawRows = np.append(rawRowsA, rawRowsB)\n",
    "!mkdir ./data/Ex2/\n",
    "downloads2 = Observations.download_products(product_list2[rawRows], download_dir=str(\n",
    "    data_dir/'Ex2/'), extension='fits', mrp_only=False, cache=True)\n",
    "downloads3 = Observations.download_products(product_list2, download_dir=str(\n",
    "    data_dir/'Ex2/'), extension='fits', mrp_only=True, cache=True)\n",
    "\n",
    "asn_data = Table.read(\n",
    "    './data/Ex2/mastDownload/HST/ldlm40010/ldlm40010_asn.fits', hdu=1)\n",
    "print(asn_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
