{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "given-census",
   "metadata": {},
   "source": [
    "<a id=\"topE\"></a>\n",
    "\n",
    "# Editing the extraction boxes in a spectral extraction file (XTRACTAB)\n",
    "\n",
    "# Learning Goals\n",
    "### This Notebook is designed to walk the user (*you*) through: **Altering the extraction box used to extract your spectrum from a COS `TIME-TAG` exposure file.**\n",
    "   #### 1. [**Investigating the exposure**](#invE)\n",
    "   ##### - 1.1. [Getting the first glimpse of a 2D spectrum](#lookE)\n",
    "   ##### - 1.2. [Defining some useful functions](#funE)\n",
    "   ##### - 1.3. [Examining the extraction boxes](#boxE)\n",
    "\n",
    "#### 2. [**Editing the extraction boxes**](#editE)\n",
    "   ##### - 2.1. [Defining an editing function](#edfnE)\n",
    "   ##### - 2.2. [Make the edits](#mkedE)\n",
    "   ##### - 2.3. [Confirming the changes](#confE)\n",
    "  \n",
    "#### 3. [**Running the CalCOS Pipeline with the new XTRACTAB**](#calexE)\n",
    "   ##### - 3.1. [Edit the XTRACTAB header value](#edhdrE)\n",
    "   ##### - 3.2. [Run the pipeline](#runcE)\n",
    "\n",
    "#### 4. [**Example using FUV Data**](#fuvE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-modem",
   "metadata": {},
   "source": [
    "\n",
    "# 0. Introduction\n",
    "#### The Cosmic Origins Spectrograph ([*COS*](https://www.nasa.gov/content/hubble-space-telescope-cosmic-origins-spectrograph)) is an ultraviolet spectrograph on-board the Hubble Space Telescope ([*HST*](https://www.stsci.edu/hst/about)) with capabilities in the near ultraviolet (*NUV*) and far ultraviolet (*FUV*).\n",
    "\n",
    "#### This tutorial aims to prepare you to work with the COS data of your choice by walking you through altering the extraction box sizes in the XTRACTAB/`_1dx` file to make sure you are extracting the cleanest possible signal from your source and background. We will demonstrate this in both the NUV and FUV. *Note* that some COS modes can also be extracted using the [TWOZONE method](https://hst-docs.stsci.edu/cosdhb/chapter-3-cos-calibration/3-2-pipeline-processing-overview), which is not directly discussed in this notebook.\n",
    "\n",
    "- For an in-depth manual to working with COS data and a discussion of caveats and user tips, see the [COS Data Handbook](https://hst-docs.stsci.edu/display/COSDHB/).\n",
    "- For a detailed overview of the COS instrument, see the [COS Instrument Handbook](https://hst-docs.stsci.edu/display/COSIHB/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-fleet",
   "metadata": {},
   "source": [
    "## We will import the following packages:\n",
    "\n",
    "- `numpy` to handle arrays and functions\n",
    "- `astropy.io fits` and `astropy.table Table` for accessing FITS files\n",
    "- `glob`, `os`, and `shutil` for working with system files\n",
    "- `astroquery.mast Observations` for finding and downloading data from the [MAST](https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html) archive\n",
    "- `matplotlib.pyplot` for plotting\n",
    "- `matplotlib.image` for reading in images\n",
    "- `calcos` to run the CalCOS pipeline for COS data reduction\n",
    "- `scipy.interpolate interp1d` for interpolating datasets to the same sampling\n",
    "\n",
    "These python packages are installed standard with the the STScI conda distribution. For more information, see our notebook tutorial on [setting up an environment](https://github.com/spacetelescope/COS-Notebooks/blob/master/Setup/Setup.ipynb).\n",
    "\n",
    "We'll also filter out two unhelpful warnings about a deprecation and dividing by zero which do not affect our data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-lexington",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for array manipulation\n",
    "import numpy as np\n",
    "# for reading fits files\n",
    "from astropy.table import Table\n",
    "from astropy.io import fits\n",
    "# For downloading the data\n",
    "from astroquery.mast import Observations as Obs\n",
    "# Plotting\n",
    "from matplotlib import pyplot as plt\n",
    "# For showing images from within Python\n",
    "from matplotlib import image as mpimg\n",
    "# For dealing with system files\n",
    "import glob, os, shutil\n",
    "# For running the CalCOS pipeline\n",
    "import calcos\n",
    "# For comparing the old and new CalCOS values\n",
    "from scipy.interpolate import interp1d \n",
    "\n",
    "# We will also suppress a warning that won't affect our data processing:\n",
    "np.seterr(divide = 'ignore') \n",
    "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-morocco",
   "metadata": {},
   "source": [
    "## We will also define a few directories we will need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-eugene",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These will be important directories for the notebook\n",
    "datadir = './data/'\n",
    "outputdir = './output/'\n",
    "plotsdir = './output/plots/'\n",
    "\n",
    "# Make the directories in case they don't exist\n",
    "!mkdir ./output\n",
    "!mkdir ./output/plots\n",
    "!mkdir ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-project",
   "metadata": {},
   "source": [
    "## And we will need to download the data we wish to work with:\n",
    "We choose the exposures with the association obs_id: `LE4B04010` and download all the `_rawtag` data. This dataset happens to be COS/NUV data taken with the G185M grating, observing the star: [LS IV -13 30](https://simbad.u-strasbg.fr/simbad/sim-id?Ident=%402582869&Name=LS%20%20IV%20-13%20%20%2030&submit=submit).\n",
    "For more information on downloading COS data, see our [notebook tutorial on downloading COS data](https://github.com/spacetelescope/COS-Notebooks/blob/master/DataDL/DataDl.ipynb).\n",
    "##### *Note*, we're working with the `_rawtags` because they are smaller files and quicker to download than the `_corrtag` files. However, this workflow translates very well to using `_corrtag` files, as you likely will want to do when working with your actual data. If you wish to use the default corrections converting from raw to corrected `TIME-TAG` data, you may instead download and work with `CORRTAG` files directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incomplete-newsletter",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Obs.get_product_list(Obs.query_criteria(obs_id='LE4B04010'))\n",
    "masked_pl = pl[np.isin(pl['productSubGroupDescription'],['RAWTAG', 'ASN', 'X1DSUM'])] # You could put 'CORRTAG' here\n",
    "# Now download:\n",
    "Obs.download_products(masked_pl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-runner",
   "metadata": {},
   "source": [
    "We gather a list of all the `_rawtag` files we have downloaded, as well as the `_asnfile` and `_x1dsum` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-abraham",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawtags = glob.glob('./mastDownload/HST/**/*_rawtag.fits', \n",
    "                    recursive=True)\n",
    "asnfile = glob.glob('./mastDownload/HST/**/*_asn.fits', \n",
    "                    recursive=True)[0]\n",
    "old_x1dsum = glob.glob('./mastDownload/HST/**/*_x1dsum.fits', \n",
    "                    recursive=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detected-bolivia",
   "metadata": {},
   "source": [
    "<a id = invE></a>\n",
    "# 1. Investigating the exposure\n",
    "\n",
    "<a id = lookE></a>\n",
    "## 1.1. Getting the first glimpse of a 2D spectrum\n",
    "The raw data from the COS instrument is a series of events, each corresponding to a photon interacting with the detector at a specific X, Y point, (*and at a specific time if in `TIME-TAG` mode*). We generally wish to translate this to a 1-dimensional spectrum (*Flux or Intensity on the y axis vs. Wavelength on the x axis*). To do this, we can plot all the X,Y points of the spectrum onto a 2D image of the detector. The different spectra (i.e. of the NUV of FUV target, the wavelength calibration source) then appear of stripes of high count density on this image. We can then simply draw extraction boxes around these stripes, and integrate to collapse the data onto the wavelenth axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-rapid",
   "metadata": {},
   "source": [
    "### We need to see where the NUV stripes fall in order to determine where we should place the extraction boxes. First, let's plot this as a 2D image of the raw counts.\n",
    "To begin, we grab and plot the raw counts data from the 0th rawtag file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data from the first rawtag\n",
    "rawtag = rawtags[0]\n",
    "rtd = Table.read(rawtag,1)\n",
    "###\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "# Plot the raw counts:\n",
    "plt.scatter(rtd['RAWX'],rtd['RAWY'], s= 0.1, alpha = 0.1, c= 'C0')\n",
    "\n",
    "# plot Lines roughly centered on the 3 NUV stripes:\n",
    "for i, (line,label) in enumerate(zip([187,285,422],['NUVA', 'NUVB', 'NUVC'])): \n",
    "    plt.axhline(line, color = 'myr'[i], linewidth = 3, alpha = 0.8, linestyle = 'dotted', label = label)\n",
    "\n",
    "plt.xlim(0,1024)\n",
    "plt.ylim(0,1024)\n",
    "\n",
    "plt.xlabel('Dispersion axis Pixel', size = 20)\n",
    "plt.ylabel('Cross-dispersion axis Pixel', size = 20)\n",
    "plt.title(\"Fig 1.1\\n2D spectrum of all raw (unfiltered) counts\", size = 25)\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-circulation",
   "metadata": {},
   "source": [
    "#### The dense stripes in the lower half of Fig 1.1 (*highlighted by the dotted lines*) are the actual science data raw counts, while the patchy stripes towards the top are the wavelength calibration counts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-arcade",
   "metadata": {},
   "source": [
    "### Now we'll need to see where the original `XTRACTAB` places its extraction boxes:\n",
    "Find the name of the `XTRACTAB` used by this first `_rawtag` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-monthly",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_xtractab = fits.getheader(rawtag)['XTRACTAB']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-hollow",
   "metadata": {},
   "source": [
    "### If you have an existing `lref` directory with a cache of reference files:\n",
    "Give the system the `lref` system variable, which points to the reference file directory, uncomment the cell below (beginning with \"`#### YES lref?`\"), and comment out the following code cell (beginning with \"`#### NO lref?`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-brass",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### YES lref?\n",
    "\n",
    "# lref = '/path/to/your/lref/'\n",
    "# %env lref /path/to/your/lref/\n",
    "# orig_xtractab = lref + orig_xtractab.split('$')[1] # This is the full path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unable-boost",
   "metadata": {},
   "source": [
    "### If you don't have an existing `lref` directory with a cache of reference files:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guilty-biology",
   "metadata": {},
   "source": [
    "If you do not have a local copy of the reference files, (i.e. an lref directory,) you may, for the purposes of this notebook, download just the `XTRACTAB` using the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-sharp",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### NO lref?\n",
    "\n",
    "%env CRDS_PATH ./data\n",
    "%env CRDS_SERVER_URL https://hst-crds.stsci.edu\n",
    "%env lref ./data/references/hst/cos/\n",
    "lref = './data/references/hst/cos/'\n",
    "! crds sync --files=w5g1439sl_1dx.fits\n",
    "\n",
    "orig_xtractab = lref + orig_xtractab.split('$')[1] # This is the full path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-charlotte",
   "metadata": {},
   "source": [
    "\n",
    "<a id = funE></a>\n",
    "## 1.2. Defining some useful functions\n",
    "\n",
    "We'll define a few functions to:\n",
    "- Read in the data rows containing relevant extraction boxes from an XTRACTAB file\n",
    "- Plot these extraction boxes over a spectrum \n",
    "  + *for clarity and signal to noise, we'll collapse this spectrum onto the y (cross-dispersion) axis*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chinese-ground",
   "metadata": {},
   "source": [
    "### First, we'll write a function to read in the relavent extraction boxes from an XTRACTAB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "institutional-vancouver",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readxtractab(xtractab, grat, cw, aper):\n",
    "\n",
    "    \"\"\"\n",
    "    Reads in an XTRACTAB row of a particular COS mode and\\\n",
    "    gets extraction box sizes and locations.\n",
    "    Inputs:\n",
    "    xtractab (str) : path to xtractab file.\n",
    "    raw (bool) : default False, meaning that the data is assumed to be corrtag.\n",
    "    grat (string) : grating of relavent row (i.e. \"G185M\")\n",
    "    cw (int or numerical) : cenwave of relavent row (i.e. (1786))\n",
    "    aper (str) : aperture of relavent row (i.e. \"PSA\")\n",
    "    Returns:\n",
    "    y locations of bottoms/tops of extraction boxes\n",
    "        if NUV: stripe NUVA/B/C, and 2 background boxes\n",
    "        elif FUV: FUVA/B, and 2 background boxes for each FUVA/B.\n",
    "    \"\"\"\n",
    "    with fits.open(xtractab) as f:\n",
    "        xtrdata = f[1].data # Get the fits data\n",
    "    \n",
    "    isFUV = fits.getheader(xtractab)['DETECTOR'] == 'FUV'\n",
    "    \n",
    "    if not isFUV: # Then NUV data:\n",
    "        sel_nuva = np.where((xtrdata['segment'] == 'NUVA') & # Find NUVA \n",
    "                            (xtrdata['aperture'] == aper) & # of the right row\n",
    "                            (xtrdata['opt_elem'] == grat) &\n",
    "                            (xtrdata['cenwave'] == cw))\n",
    "\n",
    "        sel_nuvb = np.where((xtrdata['segment'] == 'NUVB') & # Now NUVB\n",
    "                            (xtrdata['aperture'] == aper) &\n",
    "                            (xtrdata['opt_elem'] == grat) &\n",
    "                            (xtrdata['cenwave'] == cw))\n",
    "\n",
    "        sel_nuvc = np.where((xtrdata['segment'] == 'NUVC') & # Now NUVC\n",
    "                            (xtrdata['aperture'] == aper) &\n",
    "                            (xtrdata['opt_elem'] == grat) &\n",
    "                            (xtrdata['cenwave'] == cw))\n",
    "\n",
    "        hgta = xtrdata['HEIGHT'][sel_nuva][0] # get heights\n",
    "        hgtb = xtrdata['HEIGHT'][sel_nuvb][0] #  of spec extract boxes\n",
    "        hgtc = xtrdata['HEIGHT'][sel_nuvc][0]\n",
    "\n",
    "        bspeca = xtrdata['B_SPEC'][sel_nuva][0] # y-intercept (b) of spec \n",
    "        bspecb = xtrdata['B_SPEC'][sel_nuvb][0] #  boxes\n",
    "        bspecc = xtrdata['B_SPEC'][sel_nuvc][0]\n",
    "\n",
    "        boundsa = [bspeca - hgta/2, bspeca + hgta/2] # determine y bounds of boxes \n",
    "        boundsb = [bspecb - hgtb/2, bspecb + hgtb/2]\n",
    "        boundsc = [bspecc - hgtc/2, bspecc + hgtc/2]\n",
    "\n",
    "        bkg1a = xtrdata['B_BKG1'][sel_nuva] # Do the same for the bkg extract boxes\n",
    "        bkg2a = xtrdata['B_BKG2'][sel_nuva]\n",
    "        bhgta = xtrdata['BHEIGHT'][sel_nuva]\n",
    "        bkg1boundsa = [bkg1a - bhgta/2, bkg1a + bhgta/2]\n",
    "        bkg2boundsa = [bkg2a - bhgta/2, bkg2a + bhgta/2]\n",
    "\n",
    "        # the background locations are by default the same for all stripes\n",
    "\n",
    "        return boundsa, boundsb, boundsc, bkg1boundsa, bkg2boundsa\n",
    "    \n",
    "    elif isFUV: # Then FUV data:\n",
    "        sel_fuva = np.where((xtrdata['segment'] == 'FUVA') & # Find NUVA \n",
    "                            (xtrdata['aperture'] == aper) & # of the right row\n",
    "                            (xtrdata['opt_elem'] == grat) &\n",
    "                            (xtrdata['cenwave'] == cw))\n",
    "\n",
    "        sel_fuvb = np.where((xtrdata['segment'] == 'FUVB') & # Now NUVB\n",
    "                            (xtrdata['aperture'] == aper) &\n",
    "                            (xtrdata['opt_elem'] == grat) &\n",
    "                            (xtrdata['cenwave'] == cw))\n",
    "        hgta = xtrdata['HEIGHT'][sel_fuva][0] # get heights\n",
    "        hgtb = xtrdata['HEIGHT'][sel_fuvb][0] #  of spec extract boxes\n",
    "        bspeca = xtrdata['B_SPEC'][sel_fuva][0] # y-intercept (b) of spec \n",
    "        bspecb = xtrdata['B_SPEC'][sel_fuvb][0] #  boxes\n",
    "        boundsa = [bspeca - hgta/2, bspeca + hgta/2] # determine y bounds of boxes \n",
    "        boundsb = [bspecb - hgtb/2, bspecb + hgtb/2]\n",
    "\n",
    "        bkg1a = xtrdata['B_BKG1'][sel_fuva] # Do the same for the bkg extract boxes\n",
    "        bkg2a = xtrdata['B_BKG2'][sel_fuva]\n",
    "        bhgt1a = xtrdata['B_HGT1'][sel_fuva]\n",
    "        bhgt2a = xtrdata['B_HGT2'][sel_fuva]\n",
    "        bkg1boundsa = [bkg1a - bhgt1a/2, bkg1a + bhgt1a/2]\n",
    "        bkg2boundsa = [bkg2a - bhgt2a/2, bkg2a + bhgt2a/2]\n",
    "        \n",
    "        bkg1b = xtrdata['B_BKG1'][sel_fuvb] # Do the same for the bkg extract boxes\n",
    "        bkg2b = xtrdata['B_BKG2'][sel_fuvb]\n",
    "        bhgt1b = xtrdata['B_HGT1'][sel_fuvb]\n",
    "        bhgt2b = xtrdata['B_HGT2'][sel_fuvb]\n",
    "        bkg1boundsb = [bkg1b - bhgt1b/2, bkg1b + bhgt1b/2]\n",
    "        bkg2boundsb = [bkg2b - bhgt2b/2, bkg2b + bhgt2b/2]\n",
    "\n",
    "        return boundsa, boundsb, bkg1boundsa, bkg2boundsa, bkg1boundsb, bkg2boundsb\n",
    "# We'll note the returned values correspond to these extraction boxes\n",
    "box_names = ['NUVA','NUVB','NUVC','BKG-1','BKG-2']\n",
    "box_names_fuv = ['FUVA','FUVB','BKG-1A','BKG-2A','BKG-1B','BKG-2B']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-setup",
   "metadata": {},
   "source": [
    "### We'll now need two functions in order to plot\n",
    "The first function (`makeims()`) is a helper function for the second: `collapsey()`.\n",
    "\n",
    "`collapsey()` takes a list of either `_rawtag` or `_corrtag` exposure files, as well as an `XTRACTAB` file, and creates a summary plot, with the 2D spectrum collapsed onto the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeims(xarr, yarr):\n",
    "    \"\"\"\n",
    "    Helper function for collapsey(): converts counts to image.\n",
    "    \"\"\"\n",
    "    new_img = np.zeros((1024, 1024))\n",
    "    xbin = np.asarray(np.floor((xarr + 0.5)), dtype=np.int)\n",
    "    ybin = np.asarray(np.floor((yarr + 0.5)), dtype=np.int)\n",
    "    # Add a count for each x,y pair\n",
    "    for x, y in zip(xbin, ybin):\n",
    "        try:\n",
    "            new_img[y, x] += 1\n",
    "        except IndexError:\n",
    "            continue\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-entry",
   "metadata": {},
   "source": [
    "### Collapse in y axis function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapsey(tagfiles, xtractab, raw = False, save = True, savename = False, display = True, fignum = False): # assumes corrtag, but will work with rawtag if raw=True\n",
    "    \"\"\"\n",
    "    Takes a corrtag (default) or rawtag and makes a plot of the 2D spectrum collapsed to the y axis\\\n",
    "    i.e. summed over rows of pixels in the dispersion direction\\\n",
    "    then it overplots the extraction regions from a provided xtractab.\n",
    "    The behavior is the same for CORRTAG/RAWTAG, only the data columns differ.\n",
    "    \n",
    "    Inputs:\n",
    "    tagfiles (list of str) : list of rawtag or corrtag file paths.\n",
    "    xtractab (str) : path to xtractab.\n",
    "    raw (bool) : default False, meaning that the data is assumed to be corrtag.\n",
    "    save (bool) : Do you want to save the image of the plot? Default True\n",
    "    savename (str if specified) : name to save file as in plotsdir, if save == True.\n",
    "    display (bool) : Display the image? Default True.\n",
    "    fignum  (str if specified) : Figure number to include in figtitle. Dafault is False.\n",
    "    \n",
    "    Outputs:\n",
    "    yprof (numpy array of floats) : the 2D spectrum collapsed onto the y axis.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    for numfile, myfile in enumerate(tagfiles): # go through all the tag files\n",
    "\n",
    "        with fits.open(myfile) as f: # Grab data from file\n",
    "            data = f[1].data\n",
    "            h0 = f[0].header\n",
    "\n",
    "        fppos = h0['FPPOS'] # get important header keys to determin row\n",
    "        rootname = h0['ROOTNAME']\n",
    "        target = h0['TARGNAME']\n",
    "        grating = h0['OPT_ELEM']\n",
    "        cenwave = h0['CENWAVE']\n",
    "        \n",
    "        if not raw: # grab corrected or raw time-tag points x and y locations\n",
    "            xcorr = data['XCORR']\n",
    "            ycorr = data['YCORR']\n",
    "\n",
    "        elif raw:\n",
    "            rawx = data['RAWX']\n",
    "            rawy = data['RAWY']\n",
    "            \n",
    "        if raw: # call helper function on time tag data\n",
    "            nuvim = makeims(rawx, rawy)\n",
    "        else:\n",
    "            nuvim = makeims(xcorr, ycorr)\n",
    "\n",
    "        yprof = np.sum(nuvim, axis=1) # collapse onto the y axis\n",
    "\n",
    "        # Make the main y-axis spectrum plot\n",
    "        yaxis = np.arange(0, 1024)\n",
    "        plt.plot(yprof, yaxis, label=f'{rootname} fppos = {fppos}')\n",
    "        if numfile == 0: # Add in the plot formatting (just once - on the 0th file)\n",
    "            if raw:\n",
    "                plt.ylabel('RAWY Pixel', size = 18)\n",
    "            else:\n",
    "                plt.ylabel('YCORR Pixel', size = 18)\n",
    "\n",
    "            plt.xlabel('Counts summed along X', size = 18)\n",
    "            fig_title = f\"Target: {target} spectrum;\" +\"\\n\"+f\"XTRACTAB: {os.path.basename(xtractab)}\"\n",
    "            if fignum:\n",
    "                fig_title = f\"Fig {fignum}\" + \"\\n\" + fig_title\n",
    "            plt.title(fig_title, fontsize = 23)\n",
    "            psaboundsa, psaboundsb, psaboundsc, psabkg1, psabkg2 = readxtractab(xtractab, grating, cenwave, 'PSA')\n",
    "            wcaboundsa, wcaboundsb, wcaboundsc, wcabkg1, wcabkg2 = readxtractab(xtractab, grating, cenwave, 'WCA')\n",
    "\n",
    "            span = plt.axhspan(psaboundsa[0], psaboundsa[1], color='lightgray', label = 'PSA regions', alpha=0.7)\n",
    "            plt.axhspan(psaboundsb[0], psaboundsb[1], color='lightgray', alpha=0.7)\n",
    "            plt.axhspan(psaboundsc[0], psaboundsc[1], color='lightgray', alpha=0.7)\n",
    "\n",
    "            span = plt.axhspan(psabkg1[0], psabkg1[1], color='lightblue', label = 'Background regions' , alpha=0.7)\n",
    "            plt.axhspan(psabkg2[0], psabkg2[1], color='lightblue', alpha=0.7)\n",
    "            span = plt.axhspan(wcaboundsa[0], wcaboundsa[1], color='lightgreen', label = 'WCA regions', alpha=0.7)\n",
    "            plt.axhspan(wcaboundsb[0], wcaboundsb[1], color='lightgreen', alpha=0.7)\n",
    "            plt.axhspan(wcaboundsc[0], wcaboundsc[1], color='lightgreen', alpha=0.7)\n",
    "    \n",
    "    plt.legend(loc = 'upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    ### Saving the figure:\n",
    "    if save: # Do we want to save the image at all?\n",
    "        if not savename: # Save in the default manner\n",
    "            plt.savefig(plotsdir+f\"{target}_regions.png\", dpi = 200, bbox_inches = 'tight')\n",
    "        elif savename: # Save with input savename\n",
    "            plt.savefig(plotsdir+f\"{savename}.png\", dpi = 200, bbox_inches = 'tight')\n",
    "    if display:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "    plt.clf()\n",
    "    \n",
    "    return yprof"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-prisoner",
   "metadata": {},
   "source": [
    "<a id = boxE></a>\n",
    "## 1.3. Examining the extraction boxes\n",
    "### Now let's make a plot showing where these original `XTRACTAB` boxes fall on the raw count image:\n",
    "\n",
    "### It's important to note that each extraction box also has a slope associated with it. This slope is generally very small, and we will not plot the boxes with their slopes while determining the box centers and heights. However, for the purposes of actual extractions, these slopes should be incorporated to determine final extraction bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-engineer",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_bounds = readxtractab(orig_xtractab, # bounds of all boxes...\n",
    "                           grat='G185M', cw=1786, aper='PSA') # ...for these conditions\n",
    "\n",
    "plt.figure(figsize=(10,8)) # Set up figure\n",
    "\n",
    "plt.scatter(rtd['RAWX'],rtd['RAWY'], # image of the raw counts\n",
    "            s= 0.1, alpha = 0.1, c= 'C0')\n",
    "\n",
    "for i, (box, bname) in enumerate(zip(read_bounds, box_names)): # add all the boxes\n",
    "    plt.axhspan(box[0],box[1], color = 'cmykr'[i], alpha = 0.3 , label = bname)\n",
    "\n",
    "plt.legend(loc = 'upper right') # Add plot formatting\n",
    "plt.xlim(0,1024)\n",
    "plt.ylim(0,1024)\n",
    "plt.xlabel('Dispersion axis Pixel', size = 20)\n",
    "plt.ylabel('Cross-dispersion axis Pixel', size = 20)\n",
    "plt.suptitle(\"Fig 1.2\\n2D spectrum of all raw (unfiltered) counts\\n\"+\\\n",
    "             \"with original extraction boxes\", size = 25)\n",
    "plt.tight_layout()\n",
    "plt.savefig(plotsdir+'/2D_spec_orig_boxes.png', dpi = 200, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-plain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function to plot the original boxes over the y-axis spectrum\n",
    "flat_yspec = collapsey(tagfiles = rawtags, xtractab = orig_xtractab, raw = True,\n",
    "                      save = True, savename = \"orig_xtractab_col_y\", fignum = \"1.3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "favorite-update",
   "metadata": {},
   "source": [
    "<a id = editE></a>\n",
    "# 2. Editing the extraction boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-rally",
   "metadata": {},
   "source": [
    "#### Now that we know how to show the location of the extraction boxes, we can get to the actual editing. We'll define another function to edit the existing XTRACTAB and save to a new file:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-festival",
   "metadata": {},
   "source": [
    "<a id = edfnE></a>\n",
    "## 2.1. Defining an editing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_xtractab(xtractab, gratlist, cwlist, h_dict, b_dict, new_filename):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to actually edit the XTRACTAB itself\\\n",
    "    Change the height and y-intercepts of the extraction boxes,\\\n",
    "    and save to new XTRACTAB (1dx) file.\n",
    "    Inputs:\n",
    "    xtractab (str) : path to the XTRACTAB to edit\n",
    "    gratlist (list of str) : all the gratings whose rows you would like to edit\n",
    "    cwlist (list of str) : all the cenwave whose rows you would like to edit\n",
    "    h_dict (dict of numerical) : heights of NUV A,B,C extraction boxes. Should be ODD!\n",
    "    b_dict (dict) : dict of the y-intercepts - i.e. box center locations\n",
    "    new_filename : filename/local path to new XTRACTAB file to create\n",
    "    \"\"\"\n",
    "    \n",
    "    f = fits.open(xtractab)\n",
    "\n",
    "    xtrdata = f[1].data\n",
    "    isFUV = fits.getheader(xtractab)['DETECTOR'] == 'FUV'\n",
    "    \n",
    "    for height in h_dict: # Print warning if even height is specified\n",
    "        if h_dict[height] % 2 == 0:\n",
    "            print(\"WARNING \" + f\"Height of {height} is currently even ({h_dict[height]}), but \" +\n",
    "                  \"should be ODD. Allowed change, but unadvised.\")\n",
    "    \n",
    "    for grat in gratlist:\n",
    "\n",
    "        for cw in cwlist:\n",
    "            if not isFUV: # Then NUV data:\n",
    "\n",
    "                sel_nuva = np.where((xtrdata['segment'] == 'NUVA') &\n",
    "                                    (xtrdata['aperture'] == 'PSA') &\n",
    "                                    (xtrdata['opt_elem'] == grat) &\n",
    "                                    (xtrdata['cenwave'] == cw))\n",
    "\n",
    "                sel_nuvb = np.where((xtrdata['segment'] == 'NUVB') &\n",
    "                                    (xtrdata['aperture'] == 'PSA') &\n",
    "                                    (xtrdata['opt_elem'] == grat) &\n",
    "                                    (xtrdata['cenwave'] == cw))\n",
    "\n",
    "                sel_nuvc = np.where((xtrdata['segment'] == 'NUVC') &\n",
    "                                    (xtrdata['aperture'] == 'PSA') &\n",
    "                                    (xtrdata['opt_elem'] == grat) &\n",
    "                                    (xtrdata['cenwave'] == cw))\n",
    "\n",
    "                # change the background region locations:\n",
    "\n",
    "                xtrdata['B_BKG1'][sel_nuva] = b_dict['bbkg1']\n",
    "                xtrdata['B_BKG2'][sel_nuva] = b_dict['bbkg2']\n",
    "\n",
    "                xtrdata['B_BKG1'][sel_nuvb] = b_dict['bbkg1']\n",
    "                xtrdata['B_BKG2'][sel_nuvb] = b_dict['bbkg2']\n",
    "\n",
    "                xtrdata['B_BKG1'][sel_nuvc] = b_dict['bbkg1']\n",
    "                xtrdata['B_BKG2'][sel_nuvc] = b_dict['bbkg2']\n",
    "\n",
    "                # change the extraction heights\n",
    "                \n",
    "                xtrdata['HEIGHT'][sel_nuva] = h_dict['h_a']\n",
    "                xtrdata['HEIGHT'][sel_nuvb] = h_dict['h_b']\n",
    "                xtrdata['HEIGHT'][sel_nuvc] = h_dict['h_c']\n",
    "\n",
    "                # change the B_SPEC\n",
    "\n",
    "                xtrdata['B_SPEC'][sel_nuva] = b_dict['bspa']\n",
    "                xtrdata['B_SPEC'][sel_nuvb] = b_dict['bspb']\n",
    "                xtrdata['B_SPEC'][sel_nuvc] = b_dict['bspc']\n",
    "                \n",
    "                \n",
    "            elif isFUV: # Then FUV data:\n",
    "                sel_fuva = np.where((xtrdata['segment'] == 'FUVA') &\n",
    "                                    (xtrdata['aperture'] == 'PSA') &\n",
    "                                    (xtrdata['opt_elem'] == grat) &\n",
    "                                    (xtrdata['cenwave'] == cw))\n",
    "\n",
    "                sel_fuvb = np.where((xtrdata['segment'] == 'FUVB') &\n",
    "                                    (xtrdata['aperture'] == 'PSA') &\n",
    "                                    (xtrdata['opt_elem'] == grat) &\n",
    "                                    (xtrdata['cenwave'] == cw))\n",
    "                # change the background region locations:\n",
    "                xtrdata['B_BKG1'][sel_fuva] = b_dict['bbkg1a']\n",
    "                xtrdata['B_BKG2'][sel_fuva] = b_dict['bbkg2a']\n",
    "                #\n",
    "                xtrdata['B_BKG1'][sel_fuvb] = b_dict['bbkg1b']\n",
    "                xtrdata['B_BKG2'][sel_fuvb] = b_dict['bbkg2b']\n",
    "                # change the extraction heights\n",
    "                xtrdata['HEIGHT'][sel_fuva] = h_dict['h_a']\n",
    "                xtrdata['HEIGHT'][sel_fuvb] = h_dict['h_b']\n",
    "                # change the B_SPEC\n",
    "                xtrdata['B_SPEC'][sel_fuva] = b_dict['bspa']\n",
    "                xtrdata['B_SPEC'][sel_fuvb] = b_dict['bspb']\n",
    "                \n",
    "    # save and close the file\n",
    "\n",
    "    f.writeto(new_filename, overwrite=True)\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-strength",
   "metadata": {},
   "source": [
    "<a id = mkedE></a>\n",
    "## 2.2. Make the edits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-tender",
   "metadata": {},
   "source": [
    "### Now we'll need to actually edit the XTRACTAB file to have different sizes and locations of the extraction boxes using `edit_xtractab()`.\n",
    "\n",
    "For the purposes of this example, we'll **arbitrarily** set our y-intercepts and heights, just trying to roughly cover the NUV stripes, and show the different heights we can set the boxes to. *Note* that this function does not stop us from setting the boxes to overlap - but, dependent on your data, this may be a bad idea. \n",
    "\n",
    "The scope of this notebook is merely to explain *how* to alter the extraction boxes, not to determine the best box locations for any given dataset. While we cannot give specific rules to fit every single dataset, the general rules suggest you: \n",
    "* define spectral extraction boxes which contain as much flux from the target as possible while including very little of the background region\n",
    "* define background extraction boxes as close to your target as possible without the possibility of overlap\n",
    "* avoid detector hotspots and regions of poor sensitivity.\n",
    "* box heights should be odd, so that there is a central pixel.\n",
    "\n",
    "#### First we'll set up the values to which we'll edit the box parameters, and then run the function on the original XTRACTAB to change our G185M extraction boxes in the rows for cenwaves 1786 and 1817:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-prospect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These will be the values we set the box params to - fairly arbitrarily chosen values in this case:\n",
    "intercept_dict = {\"bbkg1\":900., \"bbkg2\":60., # centers of the background extract regions\n",
    "                  'bspa':195., 'bspb':285., 'bspc':415.} # centers of NUV stripe extract regions\n",
    "hgt_dict = {'h_a':41, 'h_b':51, 'h_c':61}\n",
    "\n",
    "#Now edit using the edit_xtractab() function\n",
    "                                    # change G185M grating for cenwaves 1786, 1817:\n",
    "edit_xtractab(xtractab=orig_xtractab, gratlist = ['G185M'], cwlist = [1786,1817], # data and rows to edit\n",
    "              h_dict = hgt_dict, # new (arbitrary) heights to set boxes to\n",
    "              b_dict=intercept_dict, new_filename = './edit_1dx.fits') # new (somewhat arbitrary) y-intercepts (y axis locations) for boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-monthly",
   "metadata": {},
   "source": [
    "<a id = confE></a>\n",
    "## 2.3. Confirming the changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-cotton",
   "metadata": {},
   "source": [
    "### Now let's plot the old and new extraction boxes side-by-side to compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-uganda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the plot\n",
    "fig, (ax0,ax1) = plt.subplots(1,2,figsize=(14,8), sharey=True)\n",
    "# add raw count images\n",
    "ax0.scatter(rtd['RAWX'],rtd['RAWY'], s= 0.1, alpha = 0.1, c= 'C0')\n",
    "ax1.scatter(rtd['RAWX'],rtd['RAWY'], s= 0.1, alpha = 0.1, c= 'C0')\n",
    "\n",
    "# First deal with the original XTRACTAB \n",
    "read_bounds = readxtractab(orig_xtractab, grat='G185M', cw=1786, aper='PSA')\n",
    "for i, box in enumerate(read_bounds): #plot each box\n",
    "    ax0.axhspan(box[0],box[1], color = 'cmykr'[i], alpha = 0.3 , label = box_names[i]+'_new')\n",
    "# Now with the newly edited XTRACTAB\n",
    "plt.rcParams['hatch.linewidth'] = 3 # Make the hatch more visible\n",
    "read_bounds = readxtractab('./edit_1dx.fits', grat='G185M', cw=1786, aper='PSA')\n",
    "for i, box in enumerate(read_bounds):\n",
    "    ax1.axhspan(box[0],box[1], color = 'cmykr'[i], alpha = 0.3 , hatch = 'x', label = box_names[i]+'_old')\n",
    "\n",
    "    # Now some plot formatting\n",
    "ax0.legend(loc = 'upper right')\n",
    "ax1.legend(loc = 'upper right')\n",
    "\n",
    "ax0.set_xlim(0,1024)\n",
    "ax0.set_ylim(0,1024)\n",
    "ax1.set_xlim(ax0.get_xlim())\n",
    "\n",
    "fig.text(0.42,-.01,'Dispersion axis Pixel', size = 20)\n",
    "ax0.set_ylabel('Cross-dispersion axis Pixel', size = 20)\n",
    "plt.suptitle(\"Fig 2.1\\n2D spectrum of all raw (unfiltered) counts\\n\"+\\\n",
    "             \"with original ($left$) and new ($right$) extraction boxes\", size = 25)\n",
    "plt.tight_layout()\n",
    "plt.savefig(plotsdir + '2D_spec_both_box_sets.png', dpi = 200, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generic-scholarship",
   "metadata": {},
   "source": [
    "### We'll also make a plot of the new boxes over the spectrum collapsed onto the y-axis, and we'll plot it side-by-side with Fig 1.3, which shows the original extraction boxes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-mystery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function to plot the original boxes over the y-axis spectrum\n",
    "flat_yspec = collapsey(tagfiles = rawtags, xtractab = './edit_1dx.fits', raw = True,\n",
    "                      save = True, display = False, savename = \"edit_xtractab_col_y\", fignum = \"2.2\")\n",
    "# Now plot both together\n",
    "fig, (ax0,ax1) = plt.subplots(1,2,figsize =(25,18))\n",
    "ax0.imshow(mpimg.imread('./output/plots/orig_xtractab_col_y.png'))\n",
    "ax1.imshow(mpimg.imread('./output/plots/edit_xtractab_col_y.png'))\n",
    "ax0.axis('off')\n",
    "ax1.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-software",
   "metadata": {},
   "source": [
    "<a id = calexE></a>\n",
    "# 3. Running the CalCOS Pipeline with the new XTRACTAB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-mechanics",
   "metadata": {},
   "source": [
    "<a id = edhdrE></a>\n",
    "## 3.1. Edit the XTRACTAB header value\n",
    "More detailed information on changing header parameters can be found in our [walkthrough notebook on `CalCOS`](https://github.com/spacetelescope/COS-Notebooks/blob/master/CalCOS/CalCOS.ipynb).\n",
    "\n",
    "Here, we just need to tell the pipeline to use our newly edited XTRACTAB. We do this by editing one of the header key values in all of the affected files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-seminar",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    for rawtag in rawtags:\n",
    "        os.rename(rawtag, datadir + os.path.basename(rawtag))\n",
    "except FileNotFoundError:\n",
    "    print ('No files')\n",
    "try: \n",
    "    os.rename(asnfile, datadir + os.path.basename(asnfile))\n",
    "except FileNotFoundError:\n",
    "    print ('No files')\n",
    "rawtags = glob.glob(datadir + '*rawtag*')\n",
    "asnfile = glob.glob(datadir + '*asn*')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-segment",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rawtag in rawtags:\n",
    "    print(\"changing XTRACTAB for \", os.path.basename(rawtag))\n",
    "    print(\"\\tOriginally: \", fits.getheader(rawtag)['XTRACTAB'])\n",
    "    fits.setval(filename=rawtag, keyword='XTRACTAB', value= './edit_1dx.fits' )\n",
    "    print(\"\\tNow set to: \", fits.getheader(rawtag)['XTRACTAB'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-cylinder",
   "metadata": {},
   "source": [
    "<a id = runcE></a>\n",
    "## 3.2. Run the pipeline\n",
    "We will also largely gloss over the details of running the pipeline, `CalCOS`, in this notebook. Once again, much more detailed information on running the `CalCOS` pipeline can be found in our [walkthrough notebook on `CalCOS`](https://github.com/spacetelescope/COS-Notebooks/blob/master/CalCOS/CalCOS.ipynb).\n",
    "\n",
    "If you don't have an `lref` directory with all your COS reference files, the following cells will fail to run and you should see our tutorial on [Setting up an environment to work with COS data](https://spacetelescope.github.io/COS-Notebooks/Setup.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-fighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment var to find all other ref files\n",
    "%env lref /grp/hst/cdbs/lref/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-priest",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr \n",
    "# Above, capture the output and save it in the next cell\n",
    "\n",
    "# This line actually runs the pipeline:\n",
    "calcos.calcos(asnfile, verbosity = 1, outdir = outputdir+\"calcos_run1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-disaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outputdir+'output_calcos_1.txt', 'w') as f: # This file now contains the output of the last cell\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cellular-carroll",
   "metadata": {},
   "source": [
    "### We'll finish up by plotting the new and original `x1dsum` spectra as extracted with the new and original extraction boxes:\n",
    "*Note* that we can ignore the UnitsWarning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-meaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up figure\n",
    "fig = plt.figure(figsize = (20, 7))\n",
    "gs = fig.add_gridspec(nrows = 5, ncols = 3) # Using gridspec to let us control panel sizes and locations\n",
    "\n",
    "for i in range(3):\n",
    "    ax0 = fig.add_subplot(gs[0:4,i])\n",
    "    ax1 = fig.add_subplot(gs[4:5,i])\n",
    "    new_wvln, new_flux = Table.read('./output/calcos_run1/le4b04010_x1dsum.fits')[i]['WAVELENGTH', 'FLUX']\n",
    "    old_wvln, old_flux, seg = Table.read(old_x1dsum)[i]['WAVELENGTH', 'FLUX', 'SEGMENT']\n",
    "    \n",
    "    # Interpolate the new wvln onto the old wvln's sampling:\n",
    "    new_flux_interp = interp1d(x = new_wvln, y = new_flux, fill_value=\"extrapolate\")(old_wvln)\n",
    "\n",
    "    # give max difference:\n",
    "    print(f\"Stripe {seg} differs by up to: \\\n",
    "    {max(new_flux - old_flux)/np.mean(abs(old_flux)):.3f}%\")\n",
    "\n",
    "    # Plotting - upper panel\n",
    "    ax0.plot(new_wvln,new_flux, linewidth = .5, label = '$New$ extracted spectrum')\n",
    "    ax0.plot(old_wvln,old_flux, linewidth = .5, label = '$Original$ extracted spectrum')\n",
    "    # Plotting - lower panel\n",
    "    ax1.plot(new_wvln,old_flux - new_flux_interp, linewidth = .5, label = 'Residual')\n",
    "    # Some formatting:\n",
    "    ax0.set_title(f\"Segment {seg}\", fontsize = 20)\n",
    "    ax0.set_xticks([])\n",
    "    ax0.legend(loc = 'lower center')\n",
    "    ax1.legend(loc = 'lower center')\n",
    "    if i == 0: # Add axis labels to the plot\n",
    "        ax0.set_ylabel(\"Flux\\n[$erg\\ \\AA^{-1}\\ cm^{-2}\\ s^{-1}$]\", fontsize = 20)\n",
    "    if i == 1:\n",
    "        plt.xlabel(\"Wavelength\", fontsize = 20)\n",
    "plt.suptitle(\"Fig 3.1\\nComparing the old and new extracted spectra for each segment\", fontsize = 25)\n",
    "plt.tight_layout()\n",
    "plt.savefig(plotsdir+\"comp_extracted.png\", dpi = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-notebook",
   "metadata": {},
   "source": [
    "<a id = fuvE></a>\n",
    "# 4. Example using FUV data\n",
    "\n",
    "### Let's go through doing all of the above with an FUV dataset and corresponding FUV XTRACTAB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-suggestion",
   "metadata": {},
   "source": [
    "### First download the FUV data, we'll grab an FUV/G160M/C1533 dataset from the same proposal as the NUV dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-solution",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Obs.get_product_list(Obs.query_criteria(proposal_id=15869, obs_id = 'LE4B01040'))\n",
    "masked_pl = pl[np.isin(pl['productSubGroupDescription'],['RAWTAG_A','RAWTAG_B', 'ASN', 'X1DSUM'])]\n",
    "\n",
    "# Now download:\n",
    "Obs.download_products(masked_pl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-stopping",
   "metadata": {},
   "source": [
    "#### We gather a list of all the `_rawtag` files we have downloaded, as well as the `_asnfile` and `_x1dsum` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-courage",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawtags_a = glob.glob('./mastDownload/HST/le4b01*/**/*_rawtag_a.fits', \n",
    "                    recursive=True)\n",
    "rawtags_b = glob.glob('./mastDownload/HST/le4b01*/**/*_rawtag_b.fits', \n",
    "                    recursive=True)\n",
    "rawtags_ab = rawtags_a + rawtags_b\n",
    "asnfile = glob.glob('./mastDownload/HST/le4b01040/**/*_asn.fits', \n",
    "                    recursive=True)[0]\n",
    "old_x1dsum = glob.glob('./mastDownload/HST/le4b01040/**/*_x1dsum.fits', \n",
    "                    recursive=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-chair",
   "metadata": {},
   "source": [
    "#### Move the files and index them again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-egyptian",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ./fuv_data\n",
    "\n",
    "fdatadir = './fuv_data/' # Move all this FUV data, except the calibrated x1dsum, which we don't need to\n",
    "[os.rename(rta, fdatadir+ os.path.basename(rta)) for rta in rawtags_a]\n",
    "[os.rename(rtb, fdatadir+ os.path.basename(rtb)) for rtb in rawtags_b]\n",
    "os.rename(asnfile, fdatadir+ os.path.basename(asnfile))\n",
    "\n",
    "# re-find all the data now that it's moved\n",
    "rawtags_a = glob.glob('./fuv_data/*_rawtag_a.fits', \n",
    "                    recursive=True)\n",
    "rawtags_b = glob.glob('./fuv_data/*_rawtag_b.fits', \n",
    "                    recursive=True)\n",
    "rawtags_ab = rawtags_a + rawtags_b\n",
    "asnfile = glob.glob('./fuv_data/*_asn.fits', \n",
    "                    recursive=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-indicator",
   "metadata": {},
   "source": [
    "### We need to see where the FUV spectra fall in order to determine where we should place the extraction boxes.\n",
    "#### We'll first plot this as a 2D image of the raw counts.\n",
    "We grab and plot the raw counts data from the 0th `rawtag_a` and `rawtag_b` files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-timber",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data from the first rawtag\n",
    "rtda = Table.read(rawtags_a[0],1)\n",
    "rtdb = Table.read(rawtags_b[0],1)\n",
    "###\n",
    "\n",
    "fig, (ax0,ax1) = plt.subplots(1,2,figsize=(16,8))\n",
    "ax0.scatter(rtdb['RAWX'],rtdb['RAWY'], s= 0.1, alpha = 0.1, c= 'C0')\n",
    "ax1.scatter(rtda['RAWX'],rtda['RAWY'], s= 0.1, alpha = 0.1, c= 'C0')\n",
    "\n",
    "ax0.set_title(\"Segment FUVB\", fontsize = 20)\n",
    "ax1.set_title(\"Segment FUVA\", fontsize = 20)\n",
    "\n",
    "ax0.set_xlabel('Dispersion axis Pixel',size = 20)\n",
    "ax1.set_xlabel('Dispersion axis Pixel',size = 20)\n",
    "ax0.set_ylabel('Cross-dispersion axis Pixel', size = 20)\n",
    "plt.suptitle(\"Fig 4.1\\n2D spectrum of all raw (unfiltered) counts\", size = 25)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig(plotsdir+'fuv_2Dspectrum.png', dpi = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "searching-seeking",
   "metadata": {},
   "source": [
    "#### We need to get the right XTRACTAB. \n",
    "The next cell tells you what this *should* be, and you download it in the cell that follows. Make sure these filenames match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-talent",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_fuv_1dx = fits.getheader(rawtags_a[0])['XTRACTAB'].split(\"$\")[1]\n",
    "print(\"Make sure the next line is set to download: \", correct_fuv_1dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-jerusalem",
   "metadata": {},
   "outputs": [],
   "source": [
    "! crds sync --files=2bj2256il_1dx.fits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-bride",
   "metadata": {},
   "source": [
    "### Now we can plot the original fuv boxes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-venice",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuv_xtractab = f'./data/references/hst/cos/{correct_fuv_1dx}'\n",
    "read_bounds = readxtractab(fuv_xtractab, grat='G160M', cw=1533, aper = 'PSA')\n",
    "fig, (ax0,ax1) =plt.subplots(2,1, figsize=(10,8), sharex=True) # Set up figure\n",
    "\n",
    "ax1.scatter(rtda['RAWX'],rtda['RAWY'], # image of the raw counts\n",
    "            s= 0.1, alpha = 0.1, c= 'C0') # Rawtag A\n",
    "ax0.scatter(rtdb['RAWX'],rtdb['RAWY'], # image of the raw counts\n",
    "            s= 0.1, alpha = 0.1, c= 'C0') # Rawtag B\n",
    "\n",
    "\n",
    "for i, (box, bname) in enumerate(zip(read_bounds, box_names_fuv)): # add all the boxes\n",
    "    if 'A' not in bname: # FUVA in ax1 (right), FUVB in ax0 (left)\n",
    "        ax0.axhspan(box[0],box[1], color = 'cmkyky'[i], hatch = '/\\+x+x'[i], alpha = 0.3 , label = bname)\n",
    "    else:\n",
    "        ax1.axhspan(box[0],box[1], color = 'cmkyky'[i], hatch = '/\\+x+x'[i], alpha = 0.3 , label = bname)\n",
    "\n",
    "# Add plot formatting\n",
    "ax0.legend(loc = 'upper right') \n",
    "ax1.legend(loc = 'upper right') \n",
    "ax0.set_xlim(920,15450)\n",
    "ax0.set_ylim(300,700)\n",
    "ax1.set_ylim(ax0.get_ylim())\n",
    "ax1.set_xlabel('Dispersion axis Pixel', size = 20)\n",
    "fig.text(-0.01,0.2,'Cross-dispersion axis Pixel', size = 20, rotation = 'vertical')\n",
    "plt.suptitle(\"Fig 4.2\\n2D spectrum of all raw (unfiltered) counts\\n\"+\\\n",
    "             \"with original extraction boxes in the FUV\", size = 25)\n",
    "plt.tight_layout()\n",
    "# Save it\n",
    "plt.savefig(plotsdir+'/2D_spec_orig_boxes_fuv.png', dpi = 200, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dietary-affect",
   "metadata": {},
   "source": [
    "### Here we make the edits to the XTRACTAB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-navigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "## These will be the values we set the box params to:\n",
    "intercept_dict_fuv = {\"bbkg1a\":550., \"bbkg2a\":340.,# centers of the background extract regions\n",
    "                  \"bbkg1b\":350., \"bbkg2b\":665.,\n",
    "                  'bspa':415., 'bspb':469.} # centers of NUV stripe extract regions\n",
    "hgt_dict_fuv = {'h_a':51, 'h_b':41}\n",
    "\n",
    "#Now edit using the edit_xtractab() function\n",
    "\n",
    "edit_xtractab(xtractab=fuv_xtractab, gratlist = ['G160M'], cwlist = [1533], # data and rows to edit\n",
    "              h_dict = hgt_dict_fuv, # new heights to set boxes to\n",
    "              b_dict=intercept_dict_fuv, new_filename = './edit_fuv_1dx.fits') # new y-intercepts (y axis locations) for boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integral-receipt",
   "metadata": {},
   "source": [
    "### We'll finish up with a plot showing the old and new extraction boxes side-by-side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_bounds = readxtractab(fuv_xtractab, grat='G160M', cw=1533, aper = 'PSA') # original boxes\n",
    "read_bounds_fuv_edit = readxtractab('./edit_fuv_1dx.fits', grat='G160M', cw=1533, aper = 'PSA') # edited boxes\n",
    "\n",
    "     # Orig      New/Edited\n",
    "fig, ((ax0,ax1), (ax2,ax3)) = plt.subplots(2,2, figsize=(20,10), sharex=True, sharey=True) # Set up figure\n",
    "\n",
    "# The original \n",
    "ax2.scatter(rtda['RAWX'],rtda['RAWY'], # image of the raw counts\n",
    "            s= 0.1, alpha = 0.1, c= 'C0') # Rawtag A\n",
    "ax0.scatter(rtdb['RAWX'],rtdb['RAWY'], # image of the raw counts\n",
    "            s= 0.1, alpha = 0.1, c= 'C0') # Rawtag B\n",
    "\n",
    "ax3.scatter(rtda['RAWX'],rtda['RAWY'], # image of the raw counts\n",
    "            s= 0.1, alpha = 0.1, c= 'C0') # Rawtag A\n",
    "ax1.scatter(rtdb['RAWX'],rtdb['RAWY'], # image of the raw counts\n",
    "            s= 0.1, alpha = 0.1, c= 'C0') # Rawtag B\n",
    "\n",
    "\n",
    "for i, (oldbox, newbox, bname) in enumerate(zip(read_bounds, read_bounds_fuv_edit, box_names_fuv)): # add all the boxes\n",
    "    if 'A' not in bname: # FUVA in ax0,1 (top left/right) \n",
    "        ax0.axhspan(oldbox[0],oldbox[1], color = 'cmkyky'[i], hatch = '/\\+x+x'[i], alpha = 0.3 , label = bname)\n",
    "        ax1.axhspan(newbox[0],newbox[1], color = 'cmkyky'[i], hatch = '/\\+x+x'[i], alpha = 0.3 , label = bname)\n",
    "    else: # FUVB in ax2,3 (bottom left/right)\n",
    "        ax2.axhspan(oldbox[0],oldbox[1], color = 'cmkyky'[i], hatch = '/\\+x+x'[i], alpha = 0.3 , label = bname)\n",
    "        ax3.axhspan(newbox[0],newbox[1], color = 'cmkyky'[i], hatch = '/\\+x+x'[i], alpha = 0.3 , label = bname)\n",
    "\n",
    "# Add plot formatting\n",
    "ax0.legend(loc = 'upper right') \n",
    "ax1.legend(loc = 'upper right')\n",
    "ax2.legend(loc = 'upper right') \n",
    "ax3.legend(loc = 'upper right')\n",
    "\n",
    "ax0.set_xlim(920,15450)\n",
    "ax0.set_ylim(300,700)\n",
    "ax1.set_ylim(ax0.get_ylim())\n",
    "\n",
    "ax0.set_title(\"Original extraction boxes\", fontsize = 20)\n",
    "ax1.set_title(\"Edited extraction boxes\", fontsize = 20)\n",
    "\n",
    "fig.text(-0.01,0.2,'Cross-dispersion axis Pixel', size = 20, rotation = 'vertical')\n",
    "fig.text(0.45, -0.01,'Dispersion axis Pixel', size = 20)\n",
    "\n",
    "plt.suptitle(\"Fig 4.3\\n2D spectrum of all raw (unfiltered) counts\\n\"+\\\n",
    "             \"with original and edited extraction boxes in the FUV\", size = 25)\n",
    "plt.tight_layout()\n",
    "# Save it\n",
    "plt.savefig(plotsdir+'/2D_spec_origedit_boxes_fuv.png', dpi = 200, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-canadian",
   "metadata": {},
   "source": [
    "## Congratulations! You finished this notebook!\n",
    "### There are more COS data walkthrough notebooks on different topics. You can find them [here](https://github.com/spacetelescope/COS-Notebooks)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-maine",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## About this Notebook\n",
    "**Author:** Nat Kerman <nkerman@stsci.edu>\n",
    "\n",
    "**Contributors:** Elaine Mae Frazer\n",
    "\n",
    "**Updated On:** 2021-03-15\n",
    "\n",
    "> *This tutorial was generated to be in compliance with the [STScI style guides](https://github.com/spacetelescope/style-guides) and would like to cite the [Jupyter guide](https://github.com/spacetelescope/style-guides/blob/master/templates/example_notebook.ipynb) in particular.*\n",
    "\n",
    "## Citations\n",
    "\n",
    "If you use `astropy`, `matplotlib`, `astroquery`, or `numpy` for published research, please cite the\n",
    "authors. Follow these links for more information about citations:\n",
    "\n",
    "* [Citing `astropy`/`numpy`/`matplotlib`](https://www.scipy.org/citing.html)\n",
    "* [Citing `astroquery`](https://astroquery.readthedocs.io/en/latest/)\n",
    "\n",
    "---\n",
    "\n",
    "[Top of Page](#topE)\n",
    "<img style=\"float: right;\" src=\"https://raw.githubusercontent.com/spacetelescope/notebooks/master/assets/stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"Space Telescope Logo\" width=\"200px\"/> \n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
