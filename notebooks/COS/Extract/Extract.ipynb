{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "detected-representation",
   "metadata": {},
   "source": [
    "<a id=\"topE\"></a>\n",
    "\n",
    "# Editing the extraction boxes in a spectral extraction file (XTRACTAB)\n",
    "\n",
    "# Learning Goals\n",
    "<font size=\"4 \"> This Notebook is designed to walk the user (<em>you</em>) through: <b>Altering the extraction box used to extract your spectrum from a COS `TIME-TAG` exposure file.</b></font>\n",
    "\n",
    "**1. [Investigating the exposure](#invE)**\n",
    "\n",
    "\\- 1.1. [Understanding the XTRACTAB and examining a 2D spectrum](#lookE)\n",
    "\n",
    "\\- 1.2. [Defining some useful functions](#funE)\n",
    "\n",
    "\\- 1.3. [Examining the extraction boxes](#boxE)\n",
    "\n",
    "\n",
    "**2. [Editing the extraction boxes](#editE)**\n",
    "\n",
    "\\- 2.1. [Defining an editing function](#edfnE)\n",
    "\n",
    "\\- 2.2. [Making the edits](#mkedE)\n",
    "\n",
    "\\- 2.3. [Confirming the changes](#confE)\n",
    "  \n",
    "\n",
    "**3. [Running the CalCOS Pipeline with the new XTRACTAB](#calexE)**\n",
    "\n",
    "\\- 3.1. [Editing the XTRACTAB header value](#edhdrE)\n",
    "\n",
    "\\- 3.2. [Running the pipeline](#runcE)\n",
    "\n",
    "\n",
    "**4. [Example using FUV Data](#fuvE)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-syracuse",
   "metadata": {},
   "source": [
    "\n",
    "# 0. Introduction\n",
    "**The Cosmic Origins Spectrograph ([*COS*](https://www.nasa.gov/content/hubble-space-telescope-cosmic-origins-spectrograph)) is an ultraviolet spectrograph on-board the Hubble Space Telescope ([*HST*](https://www.stsci.edu/hst/about)) with capabilities in the near ultraviolet (*NUV*) and far ultraviolet (*FUV*).**\n",
    "\n",
    "**This tutorial aims to prepare you to work with the COS data of your choice by walking you through altering the extraction box sizes in the XTRACTAB/`_1dx` file to make sure you are extracting the cleanest possible signal from your source and background.** We will demonstrate this in both the NUV and FUV. \n",
    "\n",
    "*Note* that some COS modes which use the FUV detector can be better extracted using the [TWOZONE method](https://hst-docs.stsci.edu/cosdhb/chapter-3-cos-calibration/3-2-pipeline-processing-overview), which is not directly discussed in this Notebook. All COS/NUV modes use the [BOXCAR method](https://hst-docs.stsci.edu/cosdhb/chapter-3-cos-calibration/3-2-pipeline-processing-overview#id-3.2PipelineProcessingOverview-3.2.1OverviewofTWOZONEextraction) discussed in this Notebook.\n",
    "\n",
    "- For an in-depth manual to working with COS data and a discussion of caveats and user tips, see the [COS Data Handbook](https://hst-docs.stsci.edu/display/COSDHB/).\n",
    "- For a detailed overview of the COS instrument, see the [COS Instrument Handbook](https://hst-docs.stsci.edu/display/COSIHB/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-oliver",
   "metadata": {},
   "source": [
    "## We will import the following packages:\n",
    "\n",
    "- `numpy` to handle arrays and functions\n",
    "- `astropy.io fits` and `astropy.table Table` for accessing FITS files\n",
    "- `glob`, `os`, and `shutil` for working with system files\n",
    "- `astroquery.mast Observations` for finding and downloading data from the [MAST](https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html) archive\n",
    "- `matplotlib.pyplot` for plotting\n",
    "- `matplotlib.image` for reading in images\n",
    "- `calcos` to run the CalCOS pipeline for COS data reduction\n",
    "- `scipy.interpolate interp1d` for interpolating datasets to the same sampling\n",
    "- `pathlib Path` for managing system paths\n",
    "\n",
    "New versions of `CalCOS` are currently incompatible with astroconda. To create a Python environment capable of running all the data analyses in these COS Notebooks, please see Section 1 of our Notebook tutorial on [setting up an environment](https://github.com/spacetelescope/notebooks/blob/master/notebooks/COS/Setup/Setup.ipynb).\n",
    "\n",
    "We'll also filter out two unhelpful warnings about a deprecation and dividing by zero which do not affect our data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-scottish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import for: array manipulation\n",
    "import numpy as np\n",
    "# Import for: reading fits files\n",
    "from astropy.table import Table\n",
    "from astropy.io import fits\n",
    "\n",
    "# Import for: downloading the data\n",
    "from astroquery.mast import Observations\n",
    "\n",
    "# Import for: plotting\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Import for: showing images from within Python\n",
    "from matplotlib import image as mpimg\n",
    "\n",
    "# Import for: dealing with system files\n",
    "import glob, os, shutil\n",
    "\n",
    "# Import for: running the CalCOS pipeline\n",
    "import calcos\n",
    "\n",
    "# Import for: comparing the old and new CalCOS values\n",
    "from scipy.interpolate import interp1d \n",
    "\n",
    "#Import for: working with system paths\n",
    "from pathlib import Path\n",
    "\n",
    "# We will also suppress a warning that won't affect our data processing:\n",
    "np.seterr(divide = 'ignore') \n",
    "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banner-hypothesis",
   "metadata": {},
   "source": [
    "## We will also define a few directories we will need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-camel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These will be important directories for the Notebook\n",
    "datadir = Path('./data/')\n",
    "outputdir = Path('./output/')\n",
    "plotsdir = Path('./output/plots/')\n",
    "\n",
    "# Make the directories if they don't exist\n",
    "datadir.mkdir(exist_ok=True), outputdir.mkdir(exist_ok=True), plotsdir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-carry",
   "metadata": {},
   "source": [
    "## And we will need to download the data we wish to work with:\n",
    "We choose the exposures with the association obs_id: `LE4B04010` and download all the `_rawtag` data. This dataset happens to be COS/NUV data taken with the G185M grating, observing the star: [LS IV -13 30](https://simbad.u-strasbg.fr/simbad/sim-id?Ident=%402582869&Name=LS%20%20IV%20-13%20%20%2030&submit=submit).\n",
    "For more information on downloading COS data, see our [notebook tutorial on downloading COS data](https://github.com/spacetelescope/notebooks/blob/master/notebooks/COS/DataDl/DataDl.ipynb).\n",
    "\n",
    "*Note*, we're working with the `_rawtags` because they are smaller files and quicker to download than the `_corrtag` files. However, this workflow translates very well to using `_corrtag` files, as you likely will want to do when working with your actual data. If you wish to use the default corrections converting from raw to corrected `TIME-TAG` data, you may instead download and work with `CORRTAG` files directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-seattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Observations.get_product_list(Observations.query_criteria(obs_id='LE4B04010'))\n",
    "masked_pl = pl[np.isin(pl['productSubGroupDescription'],['RAWTAG', 'ASN', 'X1DSUM'])] # You could put 'CORRTAG' here\n",
    "# Now download:\n",
    "Observations.download_products(masked_pl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loving-washington",
   "metadata": {},
   "source": [
    "We gather a list of all the `_rawtag` files we have downloaded, as well as the `_asnfile` and `_x1dsum` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-oklahoma",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawtags = glob.glob('./mastDownload/HST/**/*_rawtag.fits', \n",
    "                    recursive=True)\n",
    "asnfile = glob.glob('./mastDownload/HST/**/*_asn.fits', \n",
    "                    recursive=True)[0]\n",
    "old_x1dsum = glob.glob('./mastDownload/HST/**/*_x1dsum.fits', \n",
    "                    recursive=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantitative-valuable",
   "metadata": {},
   "source": [
    "<a id = invE></a>\n",
    "# 1. Investigating the exposure\n",
    "\n",
    "<a id = lookE></a>\n",
    "## 1.1. Understanding the XTRACTAB and examining a 2D spectrum\n",
    "The raw data from the COS instrument is a series of events, each corresponding to a photon interacting with the detector at a specific X, Y point, (*and at a specific time if in `TIME-TAG` mode*). We generally wish to translate this to a 1-dimensional spectrum (***Flux** or Intensity on the y axis vs. **Wavelength** on the x axis*). To do this, we can first make a 2-dimensional spectrum, by plotting all the X,Y points of the spectrum onto a 2D image of the detector. The different spectra (i.e. of the NUV of FUV target, the wavelength calibration source) then appear of stripes of high count density on this image. We can then simply draw extraction boxes around these stripes, and integrate to collapse the data onto the wavelenth axis.\n",
    "\n",
    "**The XTRACTAB is a fits file which contains a series of parallelogram \"boxes\" to be used for different COS modes.**\n",
    "\n",
    "These are the boxes which we collapse to create a 1-dimensional spectrum. For each combination of COS lifetime position, grating, cenwave, etc., the extraction box is specified by giving the slope and y-intercept of a line, and the height of the parallelogram which should be centered on the line. Similar boxes are specified for background regions. For more information on the XTRACTAB, see the [COS Data Handbook](https://hst-docs.stsci.edu/cosdhb/chapter-3-cos-calibration/3-7-reference-files#id-3.7ReferenceFiles-3.7.12XTRACTAB:1-DSpectralExtractionTablehttps://hst-docs.stsci.edu/cosdhb/chapter-3-cos-calibration/3-7-reference-files#id-3.7ReferenceFiles-3.7.12XTRACTAB:1-DSpectralExtractionTable)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-gallery",
   "metadata": {},
   "source": [
    "**For many reasons, we may wish to use an extraction box different from the one specified by the default XTRACTAB, and instead set the boxes manually.**\n",
    "\n",
    "We need to see where the NUV stripes fall in order to determine where we should place the extraction boxes. First, let's plot this as a 2D image of the raw counts.\n",
    "To begin, we select and plot the raw counts data from the 0th rawtag file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lucky-decimal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from the first rawtag\n",
    "rawtag = rawtags[0]\n",
    "rtd=Table.read(rawtag,1)\n",
    "###\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "# Plot the raw counts:\n",
    "plt.scatter(rtd['RAWX'],rtd['RAWY'], s= 0.1, alpha=0.1, c='C0')\n",
    "\n",
    "# Plot lines roughly centered on the 3 NUV stripes:\n",
    "for i, (line,label) in enumerate(zip([187,285,422],['NUVA', 'NUVB', 'NUVC'])): \n",
    "    plt.axhline(line, color='myr'[i], linewidth=3, alpha=0.8, linestyle='dotted', label=label)\n",
    "\n",
    "plt.xlim(0,1024)\n",
    "plt.ylim(0,1024)\n",
    "\n",
    "plt.xlabel('Dispersion axis Pixel', size=20)\n",
    "plt.ylabel('Cross-dispersion axis Pixel', size=20)\n",
    "plt.title(\"Fig 1.1\\n2D spectrum of all raw (unfiltered) counts\", size=25)\n",
    "plt.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-diploma",
   "metadata": {},
   "source": [
    "**The dense stripes in the lower half of Fig 1.1 (*highlighted by the dotted lines*) are the actual science data raw counts, while the *patched* stripes towards the top of the plot are the wavelength calibration counts.** For a diagram of a NUV 2D spectrum, see COS Data Handbook [Figure 1.10](https://hst-docs.stsci.edu/cosdhb/chapter-1-cos-overview/1-2-cos-physical-configuration#id-1.2COSPhysicalConfiguration-Figure1.10)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-madrid",
   "metadata": {},
   "source": [
    "Now we'll need to see where the original `XTRACTAB` places its extraction boxes:\n",
    "\n",
    "Find the name of the `XTRACTAB` used by this first `_rawtag` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_xtractab = fits.getheader(rawtag)['XTRACTAB']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-jersey",
   "metadata": {},
   "source": [
    "**If you have an existing `lref` directory with a cache of reference files:**\n",
    "Give the system the `lref` system variable, which points to the reference file directory, uncomment the cell below (beginning with \"`#### YES lref:`\"), and comment out the following code cell (beginning with \"`#### NO lref:`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### YES lref:\n",
    "\n",
    "# lref = '/path/to/your/lref/'\n",
    "# %env lref /path/to/your/lref/\n",
    "# orig_xtractab = lref + orig_xtractab.split('$')[1] # This is the full path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-elements",
   "metadata": {},
   "source": [
    "**If you don't have an existing `lref` directory with a cache of reference files:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-editor",
   "metadata": {},
   "source": [
    "If you do not have a local copy of the reference files, (i.e. an lref directory,) you may, for the purposes of this Notebook, download just the `XTRACTAB` using the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-transcription",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### NO lref:\n",
    "\n",
    "%env CRDS_PATH ./data\n",
    "%env CRDS_SERVER_URL https://hst-crds.stsci.edu\n",
    "%env lref ./data/references/hst/cos/\n",
    "lref = './data/references/hst/cos/'\n",
    "! crds sync --files=w5g1439sl_1dx.fits\n",
    "\n",
    "orig_xtractab = lref + orig_xtractab.split('$')[1] # This is the full path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominant-programming",
   "metadata": {},
   "source": [
    "\n",
    "<a id = funE></a>\n",
    "## 1.2. Defining some useful functions\n",
    "\n",
    "We'll define a few functions to:\n",
    "- Read in the data rows containing relevant extraction boxes from an XTRACTAB file\n",
    "- Plot these extraction boxes over a spectrum \n",
    "  + *for clarity and signal to noise, we'll collapse this spectrum onto the y (cross-dispersion) axis*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-morris",
   "metadata": {},
   "source": [
    "**First, we'll write a function to read in the relavent extraction boxes from an XTRACTAB:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-hardwood",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readxtractab(xtractab, grat, cw, aper):\n",
    "\n",
    "    \"\"\"\n",
    "    Reads in an XTRACTAB row of a particular COS mode and\\\n",
    "    returns extraction box sizes and locations.\n",
    "    Inputs:\n",
    "    xtractab (str) : path to xtractab file.\n",
    "    raw (bool) : default False, meaning that the data is assumed to be corrtag.\n",
    "    grat (string) : grating of relavent row (i.e. \"G185M\")\n",
    "    cw (int or numerical) : cenwave of relavent row (i.e. (1786))\n",
    "    aper (str) : aperture of relavent row (i.e. \"PSA\")\n",
    "    Returns:\n",
    "    y locations of bottoms/tops of extraction boxes\n",
    "        if NUV: stripe NUVA/B/C, and 2 background boxes\n",
    "        elif FUV: FUVA/B, and 2 background boxes for each FUVA/B.\n",
    "    \"\"\"\n",
    "    with fits.open(xtractab) as f:\n",
    "        xtrdata = f[1].data # Read the fits data\n",
    "    \n",
    "    isFUV = fits.getheader(xtractab)['DETECTOR'] == 'FUV'\n",
    "    \n",
    "    if not isFUV: # Then NUV data:\n",
    "        sel_nuva = np.where((xtrdata['segment'] == 'NUVA') & # Find NUVA \n",
    "                            (xtrdata['aperture'] == aper) & # of the right row\n",
    "                            (xtrdata['opt_elem'] == grat) &\n",
    "                            (xtrdata['cenwave'] == cw))\n",
    "\n",
    "        sel_nuvb = np.where((xtrdata['segment'] == 'NUVB') & # Now NUVB\n",
    "                            (xtrdata['aperture'] == aper) &\n",
    "                            (xtrdata['opt_elem'] == grat) &\n",
    "                            (xtrdata['cenwave'] == cw))\n",
    "\n",
    "        sel_nuvc = np.where((xtrdata['segment'] == 'NUVC') & # Now NUVC\n",
    "                            (xtrdata['aperture'] == aper) &\n",
    "                            (xtrdata['opt_elem'] == grat) &\n",
    "                            (xtrdata['cenwave'] == cw))\n",
    "\n",
    "        hgta = xtrdata['HEIGHT'][sel_nuva][0] # Find heights\n",
    "        hgtb = xtrdata['HEIGHT'][sel_nuvb][0] #  of spec extract boxes\n",
    "        hgtc = xtrdata['HEIGHT'][sel_nuvc][0]\n",
    "\n",
    "        bspeca = xtrdata['B_SPEC'][sel_nuva][0] # y-intercept (b) of spec \n",
    "        bspecb = xtrdata['B_SPEC'][sel_nuvb][0] #  boxes\n",
    "        bspecc = xtrdata['B_SPEC'][sel_nuvc][0]\n",
    "\n",
    "        boundsa = [bspeca - hgta/2, bspeca + hgta/2] # Determine y bounds of boxes \n",
    "        boundsb = [bspecb - hgtb/2, bspecb + hgtb/2]\n",
    "        boundsc = [bspecc - hgtc/2, bspecc + hgtc/2]\n",
    "\n",
    "        bkg1a = xtrdata['B_BKG1'][sel_nuva] # Do the same for the bkg extract boxes\n",
    "        bkg2a = xtrdata['B_BKG2'][sel_nuva]\n",
    "        bhgta = xtrdata['BHEIGHT'][sel_nuva]\n",
    "        bkg1boundsa = [bkg1a - bhgta/2, bkg1a + bhgta/2]\n",
    "        bkg2boundsa = [bkg2a - bhgta/2, bkg2a + bhgta/2]\n",
    "\n",
    "        # The background locations are by default the same for all stripes\n",
    "\n",
    "        return boundsa, boundsb, boundsc, bkg1boundsa, bkg2boundsa\n",
    "    \n",
    "    elif isFUV: # Then FUV data:\n",
    "        sel_fuva = np.where((xtrdata['segment'] == 'FUVA') & # Find NUVA \n",
    "                            (xtrdata['aperture'] == aper) &  # of the right row\n",
    "                            (xtrdata['opt_elem'] == grat) &\n",
    "                            (xtrdata['cenwave'] == cw))\n",
    "\n",
    "        sel_fuvb = np.where((xtrdata['segment'] == 'FUVB') & # Now NUVB\n",
    "                            (xtrdata['aperture'] == aper) &\n",
    "                            (xtrdata['opt_elem'] == grat) &\n",
    "                            (xtrdata['cenwave'] == cw))\n",
    "        hgta = xtrdata['HEIGHT'][sel_fuva][0] # Find heights\n",
    "        hgtb = xtrdata['HEIGHT'][sel_fuvb][0] #   of spec extract boxes\n",
    "        bspeca = xtrdata['B_SPEC'][sel_fuva][0] # y-intercept (b) of spec \n",
    "        bspecb = xtrdata['B_SPEC'][sel_fuvb][0] #  boxes\n",
    "        boundsa = [bspeca - hgta/2, bspeca + hgta/2] # determine y bounds of boxes \n",
    "        boundsb = [bspecb - hgtb/2, bspecb + hgtb/2]\n",
    "\n",
    "        bkg1a = xtrdata['B_BKG1'][sel_fuva] # Do the same for the bkg extract boxes\n",
    "        bkg2a = xtrdata['B_BKG2'][sel_fuva]\n",
    "        bhgt1a = xtrdata['B_HGT1'][sel_fuva]\n",
    "        bhgt2a = xtrdata['B_HGT2'][sel_fuva]\n",
    "        bkg1boundsa = [bkg1a - bhgt1a/2, bkg1a + bhgt1a/2]\n",
    "        bkg2boundsa = [bkg2a - bhgt2a/2, bkg2a + bhgt2a/2]\n",
    "        \n",
    "        bkg1b = xtrdata['B_BKG1'][sel_fuvb] # Do the same for the bkg extract boxes\n",
    "        bkg2b = xtrdata['B_BKG2'][sel_fuvb]\n",
    "        bhgt1b = xtrdata['B_HGT1'][sel_fuvb]\n",
    "        bhgt2b = xtrdata['B_HGT2'][sel_fuvb]\n",
    "        bkg1boundsb = [bkg1b - bhgt1b/2, bkg1b + bhgt1b/2]\n",
    "        bkg2boundsb = [bkg2b - bhgt2b/2, bkg2b + bhgt2b/2]\n",
    "\n",
    "        return boundsa, boundsb, bkg1boundsa, bkg2boundsa, bkg1boundsb, bkg2boundsb\n",
    "# We'll note the returned values correspond to these extraction boxes\n",
    "box_names = ['NUVA','NUVB','NUVC','BKG-1','BKG-2']\n",
    "box_names_fuv = ['FUVA','FUVB','BKG-1A','BKG-2A','BKG-1B','BKG-2B']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-october",
   "metadata": {},
   "source": [
    "**We'll now need two functions in order to plot.**\n",
    "\n",
    "The first function: `makeims()` is a helper function for the second: `collapsey()`.\n",
    "\n",
    "The second function: `collapsey()` takes a list of either `_rawtag` or `_corrtag` exposure files, as well as an `XTRACTAB` file, and creates a summary plot, with the 2D spectrum collapsed onto the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeims(xarr, yarr):\n",
    "    \"\"\"\n",
    "    Helper function for collapsey(): converts list of counts to image.\n",
    "    \"\"\"\n",
    "    new_img = np.zeros((1024, 1024))\n",
    "    xbin = np.asarray(np.floor((xarr + 0.5)), dtype=int)\n",
    "    ybin = np.asarray(np.floor((yarr + 0.5)), dtype=int)\n",
    "    # Add a count for each x,y pair\n",
    "    for x, y in zip(xbin, ybin):\n",
    "        try:\n",
    "            new_img[y, x] += 1\n",
    "        except IndexError:\n",
    "            continue\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "insured-going",
   "metadata": {},
   "source": [
    "**Define the \"collapse on y axis\" function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raising-browser",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapsey() assumes corrtag, but will work with rawtag if raw=True\n",
    "def collapsey(tagfiles, xtractab, raw=False, save=True, savename=False, display=True, fignum=False):\n",
    "    \"\"\"\n",
    "    Takes a corrtag (default) or rawtag and makes a plot of the 2D spectrum collapsed to the y axis\\\n",
    "    i.e. summed over rows of pixels along the dispersion direction\\\n",
    "    then it overplots the extraction regions from a provided xtractab.\n",
    "    The behavior is the same for CORRTAG/RAWTAG, only the data columns differ.\n",
    "    \n",
    "    Inputs:\n",
    "    tagfiles (list of str) : list of rawtag or corrtag file paths.\n",
    "    xtractab (str) : path to xtractab.\n",
    "    raw (bool) : default False, meaning that the data is assumed to be corrtag.\n",
    "    save (bool) : Do you want to save the image of the plot? Default True\n",
    "    savename (str if specified) : name to save file as in plotsdir, if save == True.\n",
    "    display (bool) : Display the image? Default True.\n",
    "    fignum  (str if specified) : Figure number to include in figtitle. Dafault is False.\n",
    "    \n",
    "    Outputs:\n",
    "    yprof (numpy array of floats) : the 2D spectrum collapsed onto the y axis.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    for numfile, myfile in enumerate(tagfiles): # go through all the tag files\n",
    "\n",
    "        with fits.open(myfile) as f: # Read data from file\n",
    "            data = f[1].data\n",
    "            h0 = f[0].header\n",
    "\n",
    "        fppos = h0['FPPOS'] # Find important header keys to determine row\n",
    "        rootname = h0['ROOTNAME']\n",
    "        target = h0['TARGNAME']\n",
    "        grating = h0['OPT_ELEM']\n",
    "        cenwave = h0['CENWAVE']\n",
    "        \n",
    "        if not raw: # Select corrected or raw time-tag points x and y locations\n",
    "            xcorr = data['XCORR']\n",
    "            ycorr = data['YCORR']\n",
    "\n",
    "        elif raw:\n",
    "            rawx = data['RAWX']\n",
    "            rawy = data['RAWY']\n",
    "            \n",
    "        if raw: # call helper function on time tag data\n",
    "            nuvim = makeims(rawx, rawy)\n",
    "        else:\n",
    "            nuvim = makeims(xcorr, ycorr)\n",
    "\n",
    "        yprof = np.sum(nuvim, axis=1) # collapse onto the y axis\n",
    "\n",
    "        # Make the main y-axis spectrum plot\n",
    "        yaxis = np.arange(0, 1024)\n",
    "        plt.plot(yprof, yaxis, label=f'{rootname} fppos={fppos}')\n",
    "        if numfile == 0: # Add in the plot formatting (just once - on the 0th file)\n",
    "            if raw:\n",
    "                plt.ylabel('RAWY Pixel', size=18)\n",
    "            else:\n",
    "                plt.ylabel('YCORR Pixel', size=18)\n",
    "\n",
    "            plt.xlabel('Counts summed along X', size=18)\n",
    "            fig_title = f\"Target: {target} spectrum;\" +\"\\n\"+f\"XTRACTAB: {os.path.basename(xtractab)}\"\n",
    "            if fignum:\n",
    "                fig_title = f\"Fig {fignum}\" + \"\\n\" + fig_title\n",
    "            plt.title(fig_title, fontsize=23)\n",
    "            psaboundsa, psaboundsb, psaboundsc, psabkg1, psabkg2 = readxtractab(xtractab, grating, cenwave, 'PSA')\n",
    "            wcaboundsa, wcaboundsb, wcaboundsc, wcabkg1, wcabkg2 = readxtractab(xtractab, grating, cenwave, 'WCA')\n",
    "\n",
    "            span = plt.axhspan(psaboundsa[0], psaboundsa[1], color='lightgray', label='PSA regions', alpha=0.7)\n",
    "            plt.axhspan(psaboundsb[0], psaboundsb[1], color='lightgray', alpha=0.7)\n",
    "            plt.axhspan(psaboundsc[0], psaboundsc[1], color='lightgray', alpha=0.7)\n",
    "\n",
    "            span = plt.axhspan(psabkg1[0], psabkg1[1], color='lightblue', label='Background regions' , alpha=0.7)\n",
    "            plt.axhspan(psabkg2[0], psabkg2[1], color='lightblue', alpha=0.7)\n",
    "            span = plt.axhspan(wcaboundsa[0], wcaboundsa[1], color='lightgreen', label='WCA regions', alpha=0.7)\n",
    "            plt.axhspan(wcaboundsb[0], wcaboundsb[1], color='lightgreen', alpha=0.7)\n",
    "            plt.axhspan(wcaboundsc[0], wcaboundsc[1], color='lightgreen', alpha=0.7)\n",
    "    \n",
    "    plt.legend(loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    ### Saving the figure:\n",
    "    if save: # Do we want to save the image at all?\n",
    "        if not savename: # Save in the default manner\n",
    "            plt.savefig(str(plotsdir / f\"{target}_regions.png\"), dpi=200, bbox_inches='tight')\n",
    "        elif savename: # Save with input savename\n",
    "            plt.savefig(str(plotsdir / f\"{savename}.png\"), dpi=200, bbox_inches='tight')\n",
    "    if display:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "    plt.clf()\n",
    "    \n",
    "    return yprof"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-birthday",
   "metadata": {},
   "source": [
    "<a id = boxE></a>\n",
    "## 1.3. Examining the extraction boxes\n",
    "\n",
    "Now let's make a plot showing where these original `XTRACTAB` boxes fall on the raw count image:\n",
    "\n",
    "*It's important to note that each extraction box also has a slope associated with it.* This slope is generally very small, and we will not plot the boxes with their slopes while determining the box centers and heights. However, for the purposes of actual extractions, these slopes should be incorporated to determine final extraction bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-fault",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_bounds = readxtractab(orig_xtractab, # bounds of all boxes...\n",
    "                           grat='G185M', cw=1786, aper='PSA') # ...for these conditions\n",
    "\n",
    "plt.figure(figsize=(10,8)) # Set up figure\n",
    "\n",
    "plt.scatter(rtd['RAWX'],rtd['RAWY'], # image of the raw counts\n",
    "            s= 0.1, alpha=0.1, c= 'C0')\n",
    "\n",
    "for i, (box, bname) in enumerate(zip(read_bounds, box_names)): # Add all boxes\n",
    "    plt.axhspan(box[0],box[1], color='cmykr'[i], alpha=0.3 , label=bname)\n",
    "\n",
    "plt.legend(loc='upper right') # Add plot formatting\n",
    "plt.xlim(0,1024)\n",
    "plt.ylim(0,1024)\n",
    "plt.xlabel('Dispersion axis Pixel', size=20)\n",
    "plt.ylabel('Cross-dispersion axis Pixel', size=20)\n",
    "plt.suptitle(\"Fig 1.2\\n2D spectrum of all raw (unfiltered) counts\\n\"+\\\n",
    "             \"with original extraction boxes\", size=25)\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(plotsdir / '2D_spec_orig_boxes.png'), dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-corporation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function to plot the original boxes over the y-axis spectrum\n",
    "flat_yspec = collapsey(tagfiles=rawtags, xtractab=orig_xtractab, raw=True,\n",
    "                      save=True, savename=\"orig_xtractab_col_y\", fignum=\"1.3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-boxing",
   "metadata": {},
   "source": [
    "<a id = editE></a>\n",
    "# 2. Editing the extraction boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-millennium",
   "metadata": {},
   "source": [
    "Now that we know how to show the location of the extraction boxes, we can begin actually editing the XTRACTAB file.\n",
    "\n",
    "We'll define another function to edit the existing XTRACTAB and save to a new file:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-alaska",
   "metadata": {},
   "source": [
    "<a id = edfnE></a>\n",
    "## 2.1. Defining an editing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-moore",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_xtractab(xtractab, gratlist, cwlist, h_dict, b_dict, new_filename):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to actually edit the XTRACTAB itself\\\n",
    "    Change the height and y-intercepts of the extraction boxes,\\\n",
    "    and save to new XTRACTAB (1dx) file.\n",
    "    Inputs:\n",
    "    xtractab (str) : path to the XTRACTAB to edit\n",
    "    gratlist (list of str) : all the gratings whose rows you would like to edit\n",
    "    cwlist (list of str) : all the cenwave whose rows you would like to edit\n",
    "    h_dict (dict of numerical) : heights of NUV A,B,C extraction boxes. Should be ODD!\n",
    "    b_dict (dict) : dict of the y-intercepts - i.e. box center locations\n",
    "    new_filename : filename/local path to new XTRACTAB file to create\n",
    "    \"\"\"\n",
    "    \n",
    "    f = fits.open(xtractab)\n",
    "\n",
    "    xtrdata = f[1].data\n",
    "    isFUV = fits.getheader(xtractab)['DETECTOR'] == 'FUV'\n",
    "    \n",
    "    for height in h_dict: # Print warning if even height is specified\n",
    "        if h_dict[height] % 2 == 0:\n",
    "            print(\"WARNING \" + f\"Height of {height} is currently even ({h_dict[height]}), but \" +\n",
    "                  \"should be ODD. Allowed change, but unadvised.\")\n",
    "    \n",
    "    for grat in gratlist:\n",
    "\n",
    "        for cw in cwlist:\n",
    "            if not isFUV: # Then NUV data:\n",
    "\n",
    "                sel_nuva = np.where((xtrdata['segment'] == 'NUVA') &\n",
    "                                    (xtrdata['aperture'] == 'PSA') &\n",
    "                                    (xtrdata['opt_elem'] == grat) &\n",
    "                                    (xtrdata['cenwave'] == cw))\n",
    "\n",
    "                sel_nuvb = np.where((xtrdata['segment'] == 'NUVB') &\n",
    "                                    (xtrdata['aperture'] == 'PSA') &\n",
    "                                    (xtrdata['opt_elem'] == grat) &\n",
    "                                    (xtrdata['cenwave'] == cw))\n",
    "\n",
    "                sel_nuvc = np.where((xtrdata['segment'] == 'NUVC') &\n",
    "                                    (xtrdata['aperture'] == 'PSA') &\n",
    "                                    (xtrdata['opt_elem'] == grat) &\n",
    "                                    (xtrdata['cenwave'] == cw))\n",
    "\n",
    "                # Change the background region locations:\n",
    "\n",
    "                xtrdata['B_BKG1'][sel_nuva] = b_dict['bbkg1']\n",
    "                xtrdata['B_BKG2'][sel_nuva] = b_dict['bbkg2']\n",
    "\n",
    "                xtrdata['B_BKG1'][sel_nuvb] = b_dict['bbkg1']\n",
    "                xtrdata['B_BKG2'][sel_nuvb] = b_dict['bbkg2']\n",
    "\n",
    "                xtrdata['B_BKG1'][sel_nuvc] = b_dict['bbkg1']\n",
    "                xtrdata['B_BKG2'][sel_nuvc] = b_dict['bbkg2']\n",
    "\n",
    "                # Change the extraction heights\n",
    "                \n",
    "                xtrdata['HEIGHT'][sel_nuva] = h_dict['h_a']\n",
    "                xtrdata['HEIGHT'][sel_nuvb] = h_dict['h_b']\n",
    "                xtrdata['HEIGHT'][sel_nuvc] = h_dict['h_c']\n",
    "\n",
    "                # Change the B_SPEC\n",
    "\n",
    "                xtrdata['B_SPEC'][sel_nuva] = b_dict['bspa']\n",
    "                xtrdata['B_SPEC'][sel_nuvb] = b_dict['bspb']\n",
    "                xtrdata['B_SPEC'][sel_nuvc] = b_dict['bspc']\n",
    "                \n",
    "                \n",
    "            elif isFUV: # Then FUV data:\n",
    "                sel_fuva = np.where((xtrdata['segment'] == 'FUVA') &\n",
    "                                    (xtrdata['aperture'] == 'PSA') &\n",
    "                                    (xtrdata['opt_elem'] == grat) &\n",
    "                                    (xtrdata['cenwave'] == cw))\n",
    "\n",
    "                sel_fuvb = np.where((xtrdata['segment'] == 'FUVB') &\n",
    "                                    (xtrdata['aperture'] == 'PSA') &\n",
    "                                    (xtrdata['opt_elem'] == grat) &\n",
    "                                    (xtrdata['cenwave'] == cw))\n",
    "                # Change the background region locations:\n",
    "                xtrdata['B_BKG1'][sel_fuva] = b_dict['bbkg1a']\n",
    "                xtrdata['B_BKG2'][sel_fuva] = b_dict['bbkg2a']\n",
    "                #\n",
    "                xtrdata['B_BKG1'][sel_fuvb] = b_dict['bbkg1b']\n",
    "                xtrdata['B_BKG2'][sel_fuvb] = b_dict['bbkg2b']\n",
    "                # Change the extraction heights\n",
    "                xtrdata['HEIGHT'][sel_fuva] = h_dict['h_a']\n",
    "                xtrdata['HEIGHT'][sel_fuvb] = h_dict['h_b']\n",
    "                # Change the B_SPEC\n",
    "                xtrdata['B_SPEC'][sel_fuva] = b_dict['bspa']\n",
    "                xtrdata['B_SPEC'][sel_fuvb] = b_dict['bspb']\n",
    "                \n",
    "    # save and close the file\n",
    "\n",
    "    f.writeto(new_filename, overwrite=True)\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-touch",
   "metadata": {},
   "source": [
    "<a id = mkedE></a>\n",
    "## 2.2. Making the edits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-opportunity",
   "metadata": {},
   "source": [
    "Now we'll edit the XTRACTAB file to have different sizes and locations of the extraction boxes using `edit_xtractab()`.\n",
    "\n",
    "For the purposes of this example, we'll **arbitrarily** set our y-intercepts and heights, just trying to roughly cover the NUV stripes, and show the different heights we can set the boxes to. *Note* that this function does not stop us from setting the boxes to overlap - but, dependent on your data, this may be a bad idea. \n",
    "\n",
    "The scope of this Notebook is merely to explain *how* to alter the extraction boxes, not to determine the best box locations for any given dataset. While we cannot give specific rules to fit every single dataset, the general rules suggest you: \n",
    "* Define spectral extraction boxes which contain as much flux from the target as possible while including very little of the background region\n",
    "* Define background extraction boxes as close to your target as possible without the possibility of overlap\n",
    "* Avoid detector hotspots and regions of poor sensitivity.\n",
    "* Box heights should be odd, so that there is a central pixel.\n",
    "\n",
    "First we'll set up the values to which we'll edit the box parameters, and then run the function on the original XTRACTAB to change our G185M extraction boxes in the rows for cenwaves 1786 and 1817:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-burst",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These will be the values we set the box params to - fairly arbitrarily chosen values in this case:\n",
    "intercept_dict = {\"bbkg1\":900., \"bbkg2\":60., # centers of the background extract regions\n",
    "                  'bspa':195., 'bspb':285., 'bspc':415.} # centers of NUV stripe extract regions\n",
    "hgt_dict = {'h_a':41, 'h_b':51, 'h_c':61}\n",
    "\n",
    "# Now edit using the edit_xtractab() function\n",
    "                                    # We'll change G185M grating for cenwaves 1786, 1817:\n",
    "edit_xtractab(xtractab=orig_xtractab, gratlist=['G185M'], cwlist=[1786,1817], # data and rows to edit\n",
    "              h_dict=hgt_dict, # new (arbitrary) heights to set boxes to\n",
    "              b_dict=intercept_dict, new_filename='./edit_1dx.fits') # new (somewhat arbitrary) y-intercepts (y axis locations) for boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "substantial-oliver",
   "metadata": {},
   "source": [
    "<a id = confE></a>\n",
    "## 2.3. Confirming the changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-correction",
   "metadata": {},
   "source": [
    "**Now we plot the old and new extraction boxes side-by-side to compare:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-tract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the plot\n",
    "fig, (ax0,ax1) = plt.subplots(1,2,figsize=(14,8), sharey=True)\n",
    "# add raw count images\n",
    "ax0.scatter(rtd['RAWX'],rtd['RAWY'], s= 0.1, alpha=0.1, c= 'C0')\n",
    "ax1.scatter(rtd['RAWX'],rtd['RAWY'], s= 0.1, alpha=0.1, c= 'C0')\n",
    "\n",
    "# First plot the boxes from the original XTRACTAB \n",
    "read_bounds = readxtractab(orig_xtractab, grat='G185M', cw=1786, aper='PSA')\n",
    "for i, box in enumerate(read_bounds): #plot each box\n",
    "    ax0.axhspan(box[0],box[1], color='cmykr'[i], alpha=0.3 , label=box_names[i]+'_new')\n",
    "\n",
    "# Now with the newly edited XTRACTAB\n",
    "plt.rcParams['hatch.linewidth'] = 3 # Make the hatch more visible\n",
    "read_bounds = readxtractab('./edit_1dx.fits', grat='G185M', cw=1786, aper='PSA')\n",
    "for i, box in enumerate(read_bounds):\n",
    "    ax1.axhspan(box[0],box[1], color='cmykr'[i], alpha=0.3 , hatch='x', label=box_names[i]+'_old')\n",
    "\n",
    "    # Now some plot formatting\n",
    "ax0.legend(loc='upper right')\n",
    "ax1.legend(loc='upper right')\n",
    "\n",
    "ax0.set_xlim(0,1024)\n",
    "ax0.set_ylim(0,1024)\n",
    "ax1.set_xlim(ax0.get_xlim())\n",
    "\n",
    "fig.text(0.42,-.01,'Dispersion axis Pixel', size=20)\n",
    "ax0.set_ylabel('Cross-dispersion axis Pixel', size=20)\n",
    "plt.suptitle(\"Fig 2.1\\n2D spectrum of all raw (unfiltered) counts\\n\"+\\\n",
    "             \"with original ($left$) and new ($right$) extraction boxes\", size=25)\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(plotsdir / '2D_spec_both_box_sets.png'), dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premium-debut",
   "metadata": {},
   "source": [
    "**We'll also make a plot of the new boxes over the spectrum collapsed onto the y-axis, and we'll plot it side-by-side with Fig 1.3, which shows the original extraction boxes:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-fitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function to plot the original boxes over the y-axis spectrum\n",
    "flat_yspec = collapsey(tagfiles=rawtags, xtractab='./edit_1dx.fits', raw=True,\n",
    "                      save=True, display=False, savename=\"edit_xtractab_col_y\", fignum=\"2.2\")\n",
    "# Now plot both together\n",
    "fig, (ax0,ax1) = plt.subplots(1,2,figsize =(25,18))\n",
    "ax0.imshow(mpimg.imread('./output/plots/orig_xtractab_col_y.png'))\n",
    "ax1.imshow(mpimg.imread('./output/plots/edit_xtractab_col_y.png'))\n",
    "ax0.axis('off')\n",
    "ax1.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-ontario",
   "metadata": {},
   "source": [
    "<a id = calexE></a>\n",
    "# 3. Running the CalCOS Pipeline with the new XTRACTAB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-channel",
   "metadata": {},
   "source": [
    "<a id = edhdrE></a>\n",
    "## 3.1. Editing the XTRACTAB header value\n",
    "More detailed information on changing header parameters can be found in our [walkthrough Notebook on `CalCOS`](https://github.com/spacetelescope/notebooks/blob/master/notebooks/COS/CalCOS/CalCOS.ipynb).\n",
    "\n",
    "Here, we just need to tell the pipeline to use our newly edited XTRACTAB. We do this by editing one of the header key values in all of the affected files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-checklist",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    for rawtag in rawtags:\n",
    "        os.rename(rawtag, datadir / os.path.basename(rawtag))\n",
    "except FileNotFoundError:\n",
    "    print ('No files')\n",
    "try: \n",
    "    os.rename(asnfile, datadir / os.path.basename(asnfile))\n",
    "except FileNotFoundError:\n",
    "    print ('No files')\n",
    "rawtags = glob.glob(str(datadir / '*rawtag*'))\n",
    "asnfile = glob.glob(str(datadir / '*asn*'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-trail",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rawtag in rawtags:\n",
    "    print(\"changing XTRACTAB for \", os.path.basename(rawtag))\n",
    "    print(\"\\tOriginally: \", fits.getheader(rawtag)['XTRACTAB'])\n",
    "    fits.setval(filename=rawtag, keyword='XTRACTAB', value= './edit_1dx.fits' )\n",
    "    print(\"\\tNow set to: \", fits.getheader(rawtag)['XTRACTAB'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-counter",
   "metadata": {},
   "source": [
    "<a id = runcE></a>\n",
    "## 3.2. Running the pipeline\n",
    "We will also largely gloss over the details of running the pipeline, `CalCOS`, in this Notebook. Once again, much more detailed information on running the `CalCOS` pipeline can be found in our [walkthrough Notebook on using `CalCOS`](https://github.com/spacetelescope/notebooks/blob/master/notebooks/COS/CalCOS/CalCOS.ipynb).\n",
    "\n",
    "**If you don't have an `lref` directory with all your COS reference files, the following cells will fail to run** and you should see our tutorial on [Setting up an environment to work with COS data](https://github.com/spacetelescope/notebooks/blob/master/notebooks/COS/Setup/Setup.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-eclipse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up environment var to find all other ref files\n",
    "# Your lref will likely be different, and you will need to edit this path:\n",
    "%env lref /grp/hst/cdbs/lref/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-square",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr \n",
    "# Above ^ capture the output and save it in the next cell\n",
    "\n",
    "# This line actually runs the pipeline:\n",
    "calcos.calcos(asnfile, verbosity=1, outdir=str(outputdir / \"calcos_run1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-kazakhstan",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(str(outputdir/'output_calcos_1.txt'), 'w') as f: # This file now contains the output of the last cell\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-freight",
   "metadata": {},
   "source": [
    "**We'll finish up by plotting the new and original `x1dsum` spectra as extracted with the new and original extraction boxes:**\n",
    "\n",
    "*Note* that we can ignore the UnitsWarning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-continent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up figure:\n",
    "fig = plt.figure(figsize=(20, 7))\n",
    "gs = fig.add_gridspec(nrows=5, ncols=3) # Using gridspec to control panel sizes and locations\n",
    "\n",
    "for i in range(3):\n",
    "    ax0 = fig.add_subplot(gs[0:4,i])\n",
    "    ax1 = fig.add_subplot(gs[4:5,i])\n",
    "    new_wvln, new_flux = Table.read('./output/calcos_run1/le4b04010_x1dsum.fits')[i]['WAVELENGTH', 'FLUX']\n",
    "    old_wvln, old_flux, seg = Table.read(old_x1dsum)[i]['WAVELENGTH', 'FLUX', 'SEGMENT']\n",
    "    \n",
    "    # Interpolate the new wvln onto the old wvln's sampling:\n",
    "    new_flux_interp = interp1d(x=new_wvln, y=new_flux, fill_value=\"extrapolate\")(old_wvln)\n",
    "\n",
    "    # Print max difference to user:\n",
    "    print(f\"Stripe {seg} differs by up to: \\\n",
    "    {100 * max(new_flux - old_flux)/np.mean(abs(old_flux)):.3f}%\")\n",
    "\n",
    "    # Plotting - upper panel\n",
    "    ax0.plot(new_wvln,new_flux, linewidth=.5, label='$New$ extracted spectrum')\n",
    "    ax0.plot(old_wvln,old_flux, linewidth=.5, label='$Original$ extracted spectrum')\n",
    "    # Plotting - lower panel\n",
    "    ax1.plot(new_wvln,old_flux - new_flux_interp, linewidth=.5, label='Residual')\n",
    "    # Some formatting:\n",
    "    ax0.set_title(f\"Segment {seg}\", fontsize=20)\n",
    "    ax0.set_xticks([])\n",
    "    ax0.legend(loc='lower center')\n",
    "    ax1.legend(loc='lower center')\n",
    "    if i == 0: # Add axis labels to the plot\n",
    "        ax0.set_ylabel(\"Flux\\n[$erg\\ \\AA^{-1}\\ cm^{-2}\\ s^{-1}$]\", fontsize=20)\n",
    "    if i == 1:\n",
    "        plt.xlabel(\"Wavelength\", fontsize=20)\n",
    "plt.suptitle(\"Fig 3.1\\nComparing the old and new extracted spectra for each segment\", fontsize=25)\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(plotsdir / \"comp_extracted.png\"), dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-commodity",
   "metadata": {},
   "source": [
    "<a id = fuvE></a>\n",
    "# 4. Example using FUV data\n",
    "\n",
    "Let's go through doing all of the above with an FUV dataset and corresponding FUV XTRACTAB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-exchange",
   "metadata": {},
   "source": [
    "First download the FUV data; we'll select an FUV/G160M/C1533 dataset from the same proposal as the NUV dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-rehabilitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Observations.get_product_list(Observations.query_criteria(proposal_id=15869, obs_id='LE4B01040'))\n",
    "masked_pl = pl[np.isin(pl['productSubGroupDescription'],['RAWTAG_A','RAWTAG_B', 'ASN', 'X1DSUM'])]\n",
    "\n",
    "# Now download:\n",
    "Observations.download_products(masked_pl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-career",
   "metadata": {},
   "source": [
    "**We gather a list of all the `_rawtag` files we have downloaded, as well as the `_asnfile` and `_x1dsum` file:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-thompson",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawtags_a = glob.glob('./mastDownload/HST/le4b01*/**/*_rawtag_a.fits', \n",
    "                    recursive=True)\n",
    "rawtags_b = glob.glob('./mastDownload/HST/le4b01*/**/*_rawtag_b.fits', \n",
    "                    recursive=True)\n",
    "rawtags_ab = rawtags_a + rawtags_b\n",
    "asnfile = glob.glob('./mastDownload/HST/le4b01040/**/*_asn.fits', \n",
    "                    recursive=True)[0]\n",
    "old_x1dsum = glob.glob('./mastDownload/HST/le4b01040/**/*_x1dsum.fits', \n",
    "                    recursive=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medical-morning",
   "metadata": {},
   "source": [
    "Move the files and index them again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-partnership",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdatadir = Path('./fuv_data/') # Aggregate all this FUV data, except the calibrated x1dsum\n",
    "fdatadir.mkdir(exist_ok=True)\n",
    "\n",
    "[os.rename(rta, fdatadir / os.path.basename(rta)) for rta in rawtags_a]\n",
    "[os.rename(rtb, fdatadir / os.path.basename(rtb)) for rtb in rawtags_b]\n",
    "os.rename(asnfile, fdatadir / os.path.basename(asnfile))\n",
    "\n",
    "# re-find all the data now that it's moved\n",
    "rawtags_a = glob.glob(str(fdatadir/'*_rawtag_a.fits'), \n",
    "                    recursive=True)\n",
    "rawtags_b = glob.glob(str(fdatadir/'*_rawtag_b.fits'), \n",
    "                    recursive=True)\n",
    "rawtags_ab = rawtags_a + rawtags_b\n",
    "asnfile = glob.glob(str(fdatadir/'*_asn.fits'), \n",
    "                    recursive=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-might",
   "metadata": {},
   "source": [
    "**We need to see where the FUV spectra fall in order to determine where we should place the extraction boxes.**\n",
    "\n",
    "We'll first plot this as a 2D image of the raw counts.\n",
    "We select and plot the raw counts data from the 0th `rawtag_a` and `rawtag_b` files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-double",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the data from the first rawtag_a/b file\n",
    "rtda = Table.read(rawtags_a[0],1)\n",
    "rtdb = Table.read(rawtags_b[0],1)\n",
    "###\n",
    "\n",
    "fig, (ax0,ax1) = plt.subplots(1,2,figsize=(16,8))\n",
    "ax0.scatter(rtdb['RAWX'],rtdb['RAWY'], s= 0.1, alpha=0.1, c= 'C0')\n",
    "ax1.scatter(rtda['RAWX'],rtda['RAWY'], s= 0.1, alpha=0.1, c= 'C0')\n",
    "\n",
    "ax0.set_title(\"Segment FUVB\", fontsize=20)\n",
    "ax1.set_title(\"Segment FUVA\", fontsize=20)\n",
    "\n",
    "ax0.set_xlabel('Dispersion axis Pixel',size=20)\n",
    "ax1.set_xlabel('Dispersion axis Pixel',size=20)\n",
    "ax0.set_ylabel('Cross-dispersion axis Pixel', size=20)\n",
    "plt.suptitle(\"Fig 4.1\\n2D spectrum of all raw (unfiltered) counts\", size=25)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig(str(plotsdir / 'fuv_2Dspectrum.png'), dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-training",
   "metadata": {},
   "source": [
    "**We now need to download the correct XTRACTAB.**\n",
    "\n",
    "The next cell tells you what this XTRACTAB *should* be, and you download it in the cell that follows. Make sure these filenames match, as the reference files may have changed since this tutorial was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neutral-grace",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_fuv_1dx = fits.getheader(rawtags_a[0])['XTRACTAB'].split(\"$\")[1]\n",
    "print(\"Make sure the next line is set to download: \", correct_fuv_1dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-prisoner",
   "metadata": {},
   "outputs": [],
   "source": [
    "! crds sync --files=2bj2256il_1dx.fits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "independent-onion",
   "metadata": {},
   "source": [
    "**Now we can plot the original fuv boxes:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuv_xtractab = f'./data/references/hst/cos/{correct_fuv_1dx}'\n",
    "read_bounds = readxtractab(fuv_xtractab, grat='G160M', cw=1533, aper='PSA')\n",
    "fig, (ax0,ax1) =plt.subplots(2,1, figsize=(10,8), sharex=True) # Set up figure\n",
    "\n",
    "ax1.scatter(rtda['RAWX'],rtda['RAWY'], # image of the raw counts\n",
    "            s=0.1, alpha=0.1, c='C0') # Rawtag A\n",
    "ax0.scatter(rtdb['RAWX'],rtdb['RAWY'], # image of the raw counts\n",
    "            s=0.1, alpha=0.1, c='C0') # Rawtag B\n",
    "\n",
    "\n",
    "for i, (box, bname) in enumerate(zip(read_bounds, box_names_fuv)): # add all the boxes\n",
    "    if 'A' not in bname: # FUVA in ax1 (right), FUVB in ax0 (left)\n",
    "        ax0.axhspan(box[0],box[1], color='cmkyky'[i], hatch='/\\+x+x'[i], alpha=0.3 , label=bname)\n",
    "    else:\n",
    "        ax1.axhspan(box[0],box[1], color='cmkyky'[i], hatch='/\\+x+x'[i], alpha=0.3 , label=bname)\n",
    "\n",
    "# Add plot formatting\n",
    "ax0.legend(loc='upper right') \n",
    "ax1.legend(loc='upper right') \n",
    "ax0.set_xlim(920,15450)\n",
    "ax0.set_ylim(300,700)\n",
    "ax1.set_ylim(ax0.get_ylim())\n",
    "ax1.set_xlabel('Dispersion axis Pixel', size=20)\n",
    "fig.text(-0.01,0.2,'Cross-dispersion axis Pixel', size=20, rotation='vertical')\n",
    "plt.suptitle(\"Fig 4.2\\n2D spectrum of all raw (unfiltered) counts\\n\"+\\\n",
    "             \"with original extraction boxes in the FUV\", size=25)\n",
    "plt.tight_layout()\n",
    "# Save it\n",
    "plt.savefig(str(plotsdir / '2D_spec_orig_boxes_fuv.png'), dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-indiana",
   "metadata": {},
   "source": [
    "**Here we make the edits to the FUV XTRACTAB:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-details",
   "metadata": {},
   "outputs": [],
   "source": [
    "## These will be the values we set the box params to:\n",
    "intercept_dict_fuv = {\"bbkg1a\":550., \"bbkg2a\":340.,# centers of the background extract regions\n",
    "                  \"bbkg1b\":350., \"bbkg2b\":665.,\n",
    "                  'bspa':415., 'bspb':469.} # centers of NUV stripe extract regions\n",
    "hgt_dict_fuv = {'h_a':51, 'h_b':41}\n",
    "\n",
    "#Now edit using the edit_xtractab() function\n",
    "\n",
    "edit_xtractab(xtractab=fuv_xtractab, gratlist=['G160M'], cwlist=[1533], # data and rows to edit\n",
    "              h_dict=hgt_dict_fuv, # new heights to set boxes to\n",
    "              b_dict=intercept_dict_fuv, new_filename='./edit_fuv_1dx.fits') # new y-intercepts (y axis locations) for boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-hindu",
   "metadata": {},
   "source": [
    "**We'll create a plot showing the old and new extraction boxes side-by-side:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-truck",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_bounds = readxtractab(fuv_xtractab, grat='G160M', cw=1533, aper='PSA') # original boxes\n",
    "read_bounds_fuv_edit = readxtractab('./edit_fuv_1dx.fits', grat='G160M', cw=1533, aper='PSA') # edited boxes\n",
    "\n",
    "     # Orig      New/Edited\n",
    "fig, ((ax0,ax1), (ax2,ax3)) = plt.subplots(2,2, figsize=(20,10), sharex=True, sharey=True) # Set up figure\n",
    "\n",
    "# The original \n",
    "ax2.scatter(rtda['RAWX'],rtda['RAWY'], # image of the raw counts\n",
    "            s= 0.1, alpha=0.1, c= 'C0') # Rawtag A\n",
    "ax0.scatter(rtdb['RAWX'],rtdb['RAWY'], # image of the raw counts\n",
    "            s= 0.1, alpha=0.1, c= 'C0') # Rawtag B\n",
    "\n",
    "ax3.scatter(rtda['RAWX'],rtda['RAWY'], # image of the raw counts\n",
    "            s= 0.1, alpha=0.1, c= 'C0') # Rawtag A\n",
    "ax1.scatter(rtdb['RAWX'],rtdb['RAWY'], # image of the raw counts\n",
    "            s= 0.1, alpha=0.1, c= 'C0') # Rawtag B\n",
    "\n",
    "\n",
    "for i, (oldbox, newbox, bname) in enumerate(zip(read_bounds, read_bounds_fuv_edit, box_names_fuv)): # add all the boxes\n",
    "    if 'A' not in bname: # FUVA in ax0,1 (top left/right) \n",
    "        ax0.axhspan(oldbox[0],oldbox[1], color='cmkyky'[i], hatch='/\\+x+x'[i], alpha=0.3 , label=bname)\n",
    "        ax1.axhspan(newbox[0],newbox[1], color='cmkyky'[i], hatch='/\\+x+x'[i], alpha=0.3 , label=bname)\n",
    "    else: # FUVB in ax2,3 (bottom left/right)\n",
    "        ax2.axhspan(oldbox[0],oldbox[1], color='cmkyky'[i], hatch='/\\+x+x'[i], alpha=0.3 , label=bname)\n",
    "        ax3.axhspan(newbox[0],newbox[1], color='cmkyky'[i], hatch='/\\+x+x'[i], alpha=0.3 , label=bname)\n",
    "\n",
    "# Add plot formatting\n",
    "ax0.legend(loc='upper right') \n",
    "ax1.legend(loc='upper right')\n",
    "ax2.legend(loc='upper right') \n",
    "ax3.legend(loc='upper right')\n",
    "\n",
    "ax0.set_xlim(920,15450)\n",
    "ax0.set_ylim(300,700)\n",
    "ax1.set_ylim(ax0.get_ylim())\n",
    "\n",
    "ax0.set_title(\"Original extraction boxes\", fontsize=20)\n",
    "ax1.set_title(\"Edited extraction boxes\", fontsize=20)\n",
    "\n",
    "fig.text(-0.01,0.2,'Cross-dispersion axis Pixel', size=20, rotation='vertical')\n",
    "fig.text(0.45, -0.01,'Dispersion axis Pixel', size=20)\n",
    "\n",
    "plt.suptitle(\"Fig 4.3\\n2D spectrum of all raw (unfiltered) counts\\n\"+\\\n",
    "             \"with original and edited extraction boxes in the FUV\", size=25)\n",
    "plt.tight_layout()\n",
    "# Save it\n",
    "plt.savefig(str(plotsdir / '2D_spec_origedit_boxes_fuv.png'), dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tired-luxembourg",
   "metadata": {},
   "source": [
    "**Before we could run CalCOS on this file with the new XTRACTAB, (or *any* BOXCAR extraction file, for that matter,) you must change the relevant calibration switches in the file's primary fits header to...**\n",
    "1. perform a BOXCAR extraction\n",
    "2. use the newly edited XTRACTAB file.\n",
    "\n",
    "We must set the switches as follows in the Table:\n",
    "\n",
    "|Header Keyword|Possible Values|Value to set in order to apply this XTRACTAB|What does it tell CalCOS to do?|\n",
    "|-|-|-|-|\n",
    "|XTRCTALG|**BOXCAR**/TWOZONE|BOXCAR|Which extraction method to apply|\n",
    "|TRCECORR|PERFORM/**OMIT**|OMIT|Whether to perform or omit the [trace correction](https://hst-docs.stsci.edu/cosdhb/chapter-3-cos-calibration/3-4-descriptions-of-spectroscopic-calibration-steps#id-3.4DescriptionsofSpectroscopicCalibrationSteps-3.4.14TRCECORR:ApplyTraceCorrection)|\n",
    "|ALGNCORR|PERFORM/**OMIT**|OMIT|Whether to perform or omit the [align correction](https://hst-docs.stsci.edu/cosdhb/chapter-3-cos-calibration/3-4-descriptions-of-spectroscopic-calibration-steps#id-3.4DescriptionsofSpectroscopicCalibrationSteps-3.4.15ALGNCORR:AlignmentCorrection)|\n",
    "|XTRACTAB|Local path to any valid XTRACTAB file|./edit_fuv_1dx.fits|Where to find a local copy of the XTRACTAB to use|\n",
    "\n",
    "We set the switches below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-organization",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuv_keys_dict = { # Dict we'll use to set the values of the header calib switches\n",
    "    'XTRCTALG':'BOXCAR',\n",
    "    'TRCECORR':'OMIT',\n",
    "    'ALGNCORR':'OMIT',\n",
    "    'XTRACTAB':'./edit_fuv_1dx.fits'}\n",
    "\n",
    "verbose = False # change this to True, if you want to see the changes.\n",
    "\n",
    "for rawtag in rawtags_ab: #loop through the rawtag files (fuva and fuvb).\n",
    "    print(\"changing header switches for \", os.path.basename(rawtag))\n",
    "    for fuv_key, fuv_val in fuv_keys_dict.items():\n",
    "        if verbose:\n",
    "            print(\"\\tOriginally: \",fuv_key,'=', fits.getheader(rawtag)[fuv_key])\n",
    "        fits.setval(filename=rawtag, keyword=fuv_key, value=fuv_val)\n",
    "        if verbose:\n",
    "            print(\"\\t       Now: \",fuv_key,'=', fits.getheader(rawtag)[fuv_key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-poker",
   "metadata": {},
   "source": [
    "**You may now run `CalCOS` using this new FUV XTRACTAB.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-necklace",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr \n",
    "# Above, capture the output and save it in the next cell\n",
    "\n",
    "# This line actually runs the pipeline:\n",
    "calcos.calcos(asnfile, verbosity=1, outdir=str(outputdir / \"calcos_fuv_run1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-northern",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(str(outputdir/'output_calcos_fuv_1.txt'), 'w') as f: # This file now contains the output of the last cell\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-patient",
   "metadata": {},
   "source": [
    "**Now let's compare the FUV spectra extracted with the original and new XTRACTABs:**\n",
    "\n",
    "*Note* again, that we can ignore the UnitsWarning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-reliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up figure\n",
    "fig = plt.figure(figsize=(20, 7))\n",
    "gs = fig.add_gridspec(nrows=5, ncols=2) # Using gridspec to let us control panel sizes and locations\n",
    "\n",
    "for i,j in zip([0,1],[1,0]): # use i,j to plot FUVA on the right, not the left, by inverting subplot index\n",
    "    ax0 = fig.add_subplot(gs[0:4,j])\n",
    "    ax1 = fig.add_subplot(gs[4:5,j])\n",
    "    new_wvln, new_flux = Table.read('./output/calcos_fuv_run1/le4b01040_x1dsum.fits')[i]['WAVELENGTH', 'FLUX']\n",
    "    old_wvln, old_flux, seg = Table.read(old_x1dsum)[i]['WAVELENGTH', 'FLUX', 'SEGMENT']\n",
    "    \n",
    "    # Interpolate the new wvln onto the old wvln's sampling:\n",
    "    new_flux_interp = interp1d(x=new_wvln, y=new_flux, fill_value=\"extrapolate\")(old_wvln)\n",
    "\n",
    "    # Print max difference:\n",
    "    print(f\"Stripe {seg} differs by up to: \\\n",
    "    {max(new_flux - old_flux)/np.mean(abs(old_flux)):.3f}%\")\n",
    "\n",
    "    # Plotting - upper panel\n",
    "    ax0.plot(new_wvln,new_flux,\n",
    "             alpha=1, linewidth=.5, c='C1',\n",
    "             label='$New$ extracted spectrum')\n",
    "    ax0.plot(old_wvln, old_flux, linewidth=1, c='C0',\n",
    "             linestyle='dotted', alpha=0.75,\n",
    "             label='$Original$ extracted spectrum')\n",
    "\n",
    "    # Plotting - lower panel\n",
    "    ax1.plot(new_wvln,old_flux - new_flux_interp, linewidth=.5, label='Residual')\n",
    "\n",
    "    # Some formatting:\n",
    "    ax0.set_title(f\"Segment {seg}\", fontsize=20)\n",
    "    ax0.set_xticks([])\n",
    "    ax0.legend(loc='lower center')\n",
    "    ax1.legend(loc='lower center')\n",
    "    if i == 0: # Add axis labels to the plot\n",
    "        ax0.set_ylabel(\"Flux\\n[$erg\\ \\AA^{-1}\\ cm^{-2}\\ s^{-1}$]\", fontsize=20)\n",
    "    if i == 1:\n",
    "        plt.xlabel(\"Wavelength\", fontsize=20)\n",
    "plt.suptitle(\"Fig 4.4\\nComparing the old and new extracted spectra for each segment in the FUV\", fontsize=25)\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(plotsdir / \"comp_fuv_extracted.png\"), dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9149e29-cbdb-47ee-ba27-0ad51a8e794d",
   "metadata": {},
   "source": [
    "# In conclusion\n",
    "* We have learned what the `XTRACTAB` file is and how it affects your calibration of COS spectra\n",
    "* We have learned how to edit your `XTRACTAB` to tailor how `CalCOS` extracts the spectrum of the source and background\n",
    "* We have shown examples of changing the `XTRACTAB` and reprocessing the data with the altered extraction boxes in both the FUV and NUV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-texas",
   "metadata": {},
   "source": [
    "## Congratulations! You finished this Notebook!\n",
    "### There are more COS data walkthrough Notebooks on different topics. You can find them [here](https://spacetelescope.github.io/COS-Notebooks/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stupid-ultimate",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## About this Notebook\n",
    "**Author:** Nat Kerman <nkerman@stsci.edu>\n",
    "\n",
    "**Contributors:** Elaine Mae Frazer\n",
    "\n",
    "**Updated On:** 2021-07-08\n",
    "\n",
    "> *This tutorial was generated to be in compliance with the [STScI style guides](https://github.com/spacetelescope/style-guides) and would like to cite the [Jupyter guide](https://github.com/spacetelescope/style-guides/blob/master/templates/example_notebook.ipynb) in particular.*\n",
    "\n",
    "## Citations\n",
    "\n",
    "If you use `astropy`, `matplotlib`, `astroquery`, or `numpy` for published research, please cite the\n",
    "authors. Follow these links for more information about citations:\n",
    "\n",
    "* [Citing `astropy`/`numpy`/`matplotlib`](https://www.scipy.org/citing.html)\n",
    "* [Citing `astroquery`](https://astroquery.readthedocs.io/en/latest/)\n",
    "\n",
    "---\n",
    "\n",
    "[Top of Page](#topE)\n",
    "<img style=\"float: right;\" src=\"https://raw.githubusercontent.com/spacetelescope/notebooks/master/assets/stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"Space Telescope Logo\" width=\"200px\"/> \n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
