{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "suited-certification",
   "metadata": {},
   "source": [
    "<a id=\"topSp\"></a>\n",
    "\n",
    "# Splitting COS Exposures into sub-exposures with `splittag`\n",
    "\n",
    "# Learning Goals\n",
    "\n",
    "<font size=\"4 \">This Notebook is designed to walk the user (<em>you</em>) through:</font><br>\n",
    "    \n",
    "**Filtering Cosmic Origins Spectrograph (COS) `TIME-TAG` data using the `splittag` tool** by\n",
    "\n",
    "**1. [Examining the data to determine how to split the files](#exSp)**\n",
    "\n",
    "**2. [Using `splittag` to create multiple sub-exposure files](#SpSp)**\n",
    "\n",
    "**3. [Extracting spectra from the sub-exposures using `CalCOS`](#extractSp)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-there",
   "metadata": {},
   "source": [
    "# 0. Introduction\n",
    "**The Cosmic Origins Spectrograph ([*COS*](https://www.nasa.gov/content/hubble-space-telescope-cosmic-origins-spectrograph)) is an ultraviolet spectrograph on-board the Hubble Space Telescope ([*HST*](https://www.stsci.edu/hst/about)) with capabilities in the near ultraviolet (*NUV*) and far ultraviolet (*FUV*).**\n",
    "\n",
    "**This tutorial aims to prepare you to work with the COS data of your choice by walking you through filtering `TIME-TAG` datapoints obtained by COS based on arbitrary times.**\n",
    "\n",
    "COS Data can be taken in [`TIME-TAG`](https://hst-docs.stsci.edu/cosdhb/chapter-1-cos-overview/1-1-instrument-capabilities-and-design) mode, in which each individual encounter with a photon is recorded with its own metadata such as the time of the encounter. You may wish to split a COS exposure into multiple sub-exposure files. For instance, a transit may occur during your exposure, and you may wish to see the difference between the source's spectrum before, during, and after the transit. This is possible with `TIME-TAG` data, and the functionality to do this is built into the [`COSTools` python module](https://github.com/spacetelescope/costools) with the tool `splittag`. \n",
    "\n",
    "- For an in-depth manual to working with COS data and a discussion of caveats and user tips, see the [COS Data Handbook](https://hst-docs.stsci.edu/display/COSDHB/).\n",
    "- For a detailed overview of the COS instrument, see the [COS Instrument Handbook](https://hst-docs.stsci.edu/display/COSIHB/).\n",
    "- The code for the `splittag` tool is found on the [spacetelescope/costools GitHub repository](https://github.com/spacetelescope/costools/blob/master/costools/splittag.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-architecture",
   "metadata": {},
   "source": [
    "<font size=\"5\"> We will import the following packages:</font>\n",
    "\n",
    "- `costools splittag` to select `TIME-TAG` datapoints by their time of encounter\n",
    "- `calcos` to re-process the data\n",
    "- `numpy` to handle array functions\n",
    "- `astropy.io fits` and `astropy.table Table` for accessing FITS files\n",
    "- `glob`, `os`, and `Path` for working with system files\n",
    "- `matplotlib.pyplot` and `gridspec` for plotting data\n",
    "- `astroquery.mast Mast` and `Observations` for finding and downloading data from the [MAST](https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html) archive\n",
    "- `warnings` and `astropy.units Warnings` for suppressing a warning that is not helpful later on.\n",
    "\n",
    "New versions of `CalCOS` are currently incompatible with astroconda. To create a Python environment capable of running all the data analyses in these COS Notebooks, please see Section 1 of our Notebook tutorial on [setting up an environment](https://github.com/spacetelescope/notebooks/blob/master/notebooks/COS/Setup/Setup.ipynb). Your version of `costools` may display a message on input about `TEAL` support (described [here](#tealST)), but you may ignore this as it is largely irrelevant to our discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-alias",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for array manipulation\n",
    "import numpy as np\n",
    "\n",
    "# for reading fits files\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "\n",
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "# for filtering time-tag events by time\n",
    "from costools import splittag\n",
    "# for processing COS data\n",
    "import calcos\n",
    "\n",
    "# for system files\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# for downloading the data\n",
    "from astroquery.mast import Observations\n",
    "\n",
    "# For supressing an unhelpful warning:\n",
    "import warnings\n",
    "from astropy.units import UnitsWarning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-leadership",
   "metadata": {},
   "source": [
    "<font size=\"5\"> We will also define a few directories we will need: </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-ultimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path('./output/')  # Using the pathlib style of system path\n",
    "plots_dir = output_dir / 'plots'\n",
    "# Make the directories in case they don't exist\n",
    "output_dir.mkdir(exist_ok=True), plots_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-fundamentals",
   "metadata": {},
   "source": [
    "<font size=\"5\"> And we will need to download the data we wish to filter and analyze </font>\n",
    "\n",
    "We choose the exposure with obs_id: `lc1va0010`, because we happen to know it contains an exposure taken while the target, [IY UMa](http://simbad.u-strasbg.fr/simbad/sim-id?Ident=IY+UMa), underwent a transit event. For more information on downloading COS data, see our [notebook tutorial on downloading COS data](https://github.com/spacetelescope/notebooks/blob/master/notebooks/COS/DataDl/DataDl.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-grenada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all MAST data on this obs id:\n",
    "pl = Observations.get_product_list(Observations.query_criteria(obs_id='lc1va0010'))\n",
    "\n",
    "# Filter and download the Corrtag TIME-TAG files:\n",
    "pl_filt = Observations.filter_products(\n",
    "    pl, productSubGroupDescription=('CORRTAG_A', 'CORRTAG_B')\n",
    ")\n",
    "downloaded_corrtags = Observations.download_products(pl_filt)['Local Path']\n",
    "\n",
    "# Filter and download the extracted spectra (X1D) files:\n",
    "pl_filt = Observations.filter_products(\n",
    "    pl, productSubGroupDescription=('X1D')\n",
    ")\n",
    "downloaded_x1ds = Observations.download_products(pl_filt)['Local Path']\n",
    "\n",
    "# Let us know how many corrtags were found:\n",
    "print(\n",
    "    f\"#####\\nFound {len(downloaded_corrtags)} corrtag exposure files from the COS FUV detector (segment A only)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-liability",
   "metadata": {},
   "source": [
    "<a id= exSp></a>\n",
    "# 1. Examining the data to determine how to split the files\n",
    "We chose this dataset because of its transit event. However, let's suppose for a moment that we don't know which, if any, of our exposures have transits or other time-variable events. We'll imagine we are simply investigating our data.\n",
    "\n",
    "**To look for transits and other anomalies, we will create and examine a rough lightcurve of our four exposures.**\n",
    "\n",
    "A lightcurve is simply a graph of net light or photon counts over time. We can make one by grabbing the time of all recorded photon events from each exposure, and plotting a histogram of the times. There are packages which can create detailed lightcurves, such as [lightcurve](https://github.com/justincely/lightcurve), but we will make these simple lightcurve plots ourselves. We also do not claim to explain every feature of all the lightcurves created. We will focus on any clear transit shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-skating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the figure structure\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "# Using gridspec to let us control panel sizes and locations\n",
    "gs = fig.add_gridspec(nrows=2, ncols=2)\n",
    "# Get the time data for each exposure\n",
    "binsize = 10  # Number of seconds in a bin\n",
    "for i, ctag in enumerate(downloaded_corrtags):\n",
    "    ax = fig.add_subplot(gs[int(i/2), i % 2])  # make the subplot\n",
    "    ctab = Table.read(ctag, 1)  # read the data into a table\n",
    "    event_times = ctab['TIME']\n",
    "    # plot the histogram of times\n",
    "    hist = ax.hist(\n",
    "        event_times,\n",
    "        bins=np.arange(0, max(event_times)+binsize, binsize),\n",
    "        alpha=0.5, \n",
    "        label=os.path.basename(ctag),\n",
    "        color=['C0', 'C1', 'C2', 'C3'][i]\n",
    "    )\n",
    "    # Add a gray box around the suspected transit:\n",
    "    if \"zgq\" in ctag:\n",
    "        ax.axvspan(\n",
    "            450, 850, \n",
    "            color='k', \n",
    "            alpha=0.15,\n",
    "            label=\"Approximate time of transit\"\n",
    "        )\n",
    "    plt.legend(fontsize=12)\n",
    "# Format the figure and add text:\n",
    "plt.suptitle(\"Fig 1.1\\nRough lightcurves of exposures\", fontsize=20)\n",
    "fig.text(\n",
    "    x=0.42, y=-0.0001,\n",
    "    s=\"Time from exposure start [s]\",\n",
    "    fontsize=14\n",
    ")\n",
    "fig.text(\n",
    "    y=0.42, x=-0.001,\n",
    "    s=f\"Counts in $\\sim${binsize} second bin\",\n",
    "    rotation='vertical',\n",
    "    fontsize=14\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(plots_dir / 'compare_exposures.png', bbox_inches='tight', dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driving-illness",
   "metadata": {},
   "source": [
    "We can see an apparent transit in the exposure `lc1va0zgq`, occurring from about 450 - 850 seconds into the exposure. We highlight this in figure 1.2 below.\n",
    "\n",
    "Exposure `lc1va0yeq` also seems to contain at least the latter part of a transit, but for now we'll focus on `lc1va0zgq`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-arizona",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the path to the right exposure\n",
    "transit_exp = [exp for exp in downloaded_corrtags if \"zgq\" in exp][0]\n",
    "transit_basename = os.path.basename(transit_exp).split('_')[0]\n",
    "\n",
    "# Create the plot:\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Select the data and plot it:\n",
    "binsize = 5 # Binsize in seconds\n",
    "ctab = Table.read(transit_exp, 1)\n",
    "event_times = ctab['TIME']\n",
    "hist = plt.hist(event_times, bins=np.arange(0, max(event_times)+binsize, binsize),\n",
    "                color='k', alpha=0.7)\n",
    "\n",
    "# Add time ranges \"epochs\" or \"windows of time\" as transparent spans:\n",
    "epoch_markers = [(0, 550), (550, 850), (850, max(event_times))]\n",
    "print(f\"The length of the exposure is ~{int(max(event_times))} s\")\n",
    "epoch_labels = [\"Before Transit\", \"During Transit\", \"After Transit\"]\n",
    "for epoch_time, epoch_label, color in zip(epoch_markers, epoch_labels, \"bgr\"):\n",
    "    plt.axvspan(\n",
    "        epoch_time[0], epoch_time[1],\n",
    "        color=color, alpha=0.1, label=epoch_label\n",
    "    )\n",
    "\n",
    "# Format the Figure\n",
    "plt.legend(fontsize=12)\n",
    "plt.title(f\"Fig 1.2\\nRough lightcurves of exposure {transit_basename}\",\n",
    "          size=20)\n",
    "plt.xlabel(\"Time from exposure start [s]\",\n",
    "           fontsize=14)\n",
    "plt.ylabel(f\"Counts in $\\sim${binsize} second bin\",\n",
    "           fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(plots_dir / 'examine_transit.png', bbox_inches='tight', dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-correlation",
   "metadata": {},
   "source": [
    "**We now wish to actually split the file into three sub-exposures with the counts gathered during these three windows of time.**\n",
    "\n",
    "For research purposes, the transit should be measured more carefully than simply looking at this rough lightcurve. However for our purposes, we explicitly and somewhat arbitrarily define the windows, 'by eye', as:\n",
    "\n",
    "|Window|Time Range|\n",
    "|-|-|\n",
    "|Before Transit| 0-550 seconds|\n",
    "|During Transit| 550-850 seconds|\n",
    "|After Transit| 850-1337 seconds|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "under-synthesis",
   "metadata": {},
   "source": [
    "<a id=SpSp></a>\n",
    "# 2. Using `splittag` to create multiple sub-exposure files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-ecology",
   "metadata": {},
   "source": [
    "The next cell creates a directory for the sub-exposure files we're about to create, and uses `splittag` to split the exposures.\n",
    "\n",
    "The `time_list` parameter defines the times at which the exposure will be split. Because we pass this parameter the list `[0,550,850,<time of last recorded count>]`, `splittag` will produce 3 sub-exposure files with data taken from:\n",
    "1. 0-550 seconds\n",
    "2. 550-850 seconds\n",
    "3. 850-1337 seconds (because the `<time of last recorded count>` for this exposure ~1337 s)\n",
    "\n",
    "*Please note* that `splittag` will not overwrite files if you run it multiple times. Instead, it will write a new set of files with increasing numeric suffixes (e.g. `filepath_corrtag_a.fits` --> `filepath_1_corrtag_a.fits`). This can cause issues if you do not update your filepaths to the output files you wish to use. To prevent problems, we delete any older corrtag files in the directory. If you do not wish to delete your old files, set the `delete_old_files` variable to False in the cell below. Alternatively, you may wish to create a new directory for each time you run `splittag`. Please take care to prevent these issues when attempting the exercises, as well. You may ignore any `AstropyDeprecationWarning`s about keywords. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-wrist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the folder in which to store the newly split corrtag files:\n",
    "spec_int_dir = output_dir / 'spec_intervals'\n",
    "# An output directory for files split on specified intervals\n",
    "spec_int_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Use CAUTION when deleting files - as in the next lines\n",
    "# These lines delete existing processed files in the output directory\n",
    "#   if you have run this cell before, this will overwrite previous outputs\n",
    "delete_old_files = True\n",
    "if delete_old_files and any(spec_int_dir.glob(\"*corrtag*fits\")):\n",
    "    print(\"Deleting files from a previous run...\")\n",
    "    [old_file.unlink() for old_file in list(spec_int_dir.glob(\"*corrtag*fits\"))]\n",
    "\n",
    "# Print info to the user:\n",
    "print(\"Creating and writing split files...\")\n",
    "for i, epoch_times in enumerate(epoch_markers):\n",
    "    print(\n",
    "        f\"> File {i+1} contains counts from time:\",\n",
    "        f\"{epoch_times[0]} - {epoch_times[1]} seconds\"\n",
    "    )\n",
    "split_list = [0, 550, 850, max(event_times)]\n",
    "# Run splittag using our specified times:\n",
    "splittag.splittag(infiles=transit_exp,\n",
    "                  outroot=f'./output/spec_intervals/{transit_basename}',\n",
    "                  time_list=split_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-killer",
   "metadata": {},
   "source": [
    "**Excellent! We've now created 3 sub-exposure files.**\n",
    "\n",
    "Above we split an input exposure at a series of specified times. \n",
    "The `splittag` command can also be used to split at regular time intervals. For instance, you can split the file every 100 seconds as shown in the code below:\n",
    "\n",
    "```python\n",
    "# Make the folder in which to store the newly split corrtag files:\n",
    "reg_int_dir = output_dir / 'regular_intervals'\n",
    "reg_int_dir.mkdir(exist_ok=True) # Output directory for intervals specified by start/end/length\n",
    "# Split the file every 100 seconds\n",
    "splittag.splittag(\n",
    "    infiles=chosen_corrtag, \n",
    "    outroot='./output/regular_intervals/lc1va0zgq',\n",
    "    starttime=0., \n",
    "    increment=100,\n",
    "    endtime=1300.\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-sullivan",
   "metadata": {},
   "source": [
    "Below, we show the lightcurves of sub-exposure files which resulted from splitting at the specified intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-personality",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot:\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Gather the split sub-exposure files:\n",
    "spec_outlist = sorted(glob.glob('./output/spec_intervals/*fits'))\n",
    "\n",
    "# Make histogram lightcurves as in previous plots:\n",
    "binsize = 10 # binsize of lightcurve histogram in seconds\n",
    "for splitfile in spec_outlist:  # For each of our newly split up files:\n",
    "    epoch_number = os.path.basename(splitfile).split('_')[1]\n",
    "    # Read in the file as a table of events:\n",
    "    events_table = Table.read(splitfile, 1)\n",
    "    event_times = events_table['TIME']\n",
    "    hist = plt.hist(\n",
    "        event_times, \n",
    "        bins=int((max(event_times)-min(event_times))/binsize),\n",
    "        alpha=1, label=f\"sub-exposure {epoch_number}\"\n",
    "    )\n",
    "\n",
    "# Add time ranges \"epochs\" or \"windows of time\" as transparent spans:\n",
    "for epoch_time, color in zip(epoch_markers, ['C0', 'C1', 'C2']):\n",
    "    plt.axvspan(\n",
    "        epoch_time[0], epoch_time[1],\n",
    "        color=color, alpha=0.1, label=None\n",
    "    )\n",
    "\n",
    "# Format the Figure\n",
    "plt.legend(fontsize=12)\n",
    "plt.title(f\"Fig 2.1\\nExamining the split sub-exposures created from {transit_basename}\",\n",
    "          size=20)\n",
    "plt.xlabel(\"Time from $original$ exposure start [s]\",\n",
    "           fontsize=14)\n",
    "plt.ylabel(f\"Counts in $\\sim${binsize} second bin\",\n",
    "           fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(plots_dir / 'subexps.png', bbox_inches='tight', dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-mathematics",
   "metadata": {},
   "source": [
    "<a id=tealST></a>\n",
    "While not implemented within the Jupyter Notebook framework, you can also run `splittag` from a TEAL graphical user interface (GUI) on a local computer (see Fig 2.2).\n",
    "\n",
    "To generate the GUI, open Python (specifically a Python environment with `costools` installed) on the command line and run the following lines of code:\n",
    "\n",
    "```python\n",
    "import costools\n",
    "from stsci.tools import teal\n",
    "teal.teal('splittag')\n",
    "```\n",
    "\n",
    "### Fig 2.2\n",
    "<center><img src=\"./figures/TEAL_GUI.png\" width =\"900\" title=\"TEAL GUI Interface\"> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cellular-guarantee",
   "metadata": {},
   "source": [
    "Now that we have the three sub-exposure files, we can process them into 1-dimensional spectra using the [COS Calibration Pipeline: `CalCOS`](https://github.com/spacetelescope/calcos)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384a03f3-0429-4383-bc3c-d3d3389efdbf",
   "metadata": {},
   "source": [
    "### Exercise 1: *Practice sub-dividing with `splittag`*\n",
    "\n",
    "Examining Fig 2.1, we see that from approximately 450-550 seconds, there is are in fact 2 drops in flux. Starting from an initial flux similar to that at the start of the exposure, the flux drops first by ~50% at around 450 seconds, and then drops by ~75% at around 550 seconds to its depth for the duration of the transit.\n",
    "\n",
    "Separate out the data taken during this initial drop (from ~450-550 seconds) into its own sub-exposure file using `splittag`. Then, demonstrate your split files with a lightcurve like that in Fig 2.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b20e1cf-1f9c-4a9c-8311-f8e667298ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-planner",
   "metadata": {},
   "source": [
    "<a id=extractSp></a>\n",
    "# 3. Extracting spectra from the sub-exposures using `CalCOS`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-newspaper",
   "metadata": {},
   "source": [
    "While for most circumstances, `CalCOS` is best run on an association file, (a fits table which specifies a series of exposures to calibrate and combine into a spectrum,) the `CalCOS` pipeline can usually be run on individual `rawtag` or `corrtag` files. \n",
    "\n",
    "* More information on running `CalCOS` can be found in [Chapter 3.6 of the COS Instrument Handbook](https://hst-docs.stsci.edu/cosdhb/chapter-3-cos-calibration/3-6-customizing-cos-data-calibration#id-3.6CustomizingCOSDataCalibration-3.6.1MechanicsofTailoredRecalibration)\n",
    "* An interactive walkthrough to running the `CalCOS` can be found in [our notebook on the `CalCOS` pipeline](https://github.com/spacetelescope/notebooks/blob/master/notebooks/COS/CalCOS/CalCOS.ipynb).\n",
    "\n",
    "To run `CalCOS`, your computer will need an `lref` system variable to tell the pipeline where to find your reference files. If you are on the STScI internet network (including via VPN), you may set this to the shared Institute lref directory. However, if you're not on the network, you will need to use the `CRDS` command to download the necessary reference files. This process is described in detail in Chapter 3 of our [notebook on setting up an environment for working with COS data](https://spacetelescope.github.io/COS-Notebooks/Setup.html#crdsS). \n",
    "\n",
    "Once you have downloaded the files, you can set the environment variable to your CRDS cache using the code cell below.\n",
    "The cell attempts to set your `lref` variable to the correct directory, but if you have created your own lref cache, you will need to replace the `<PATH TO YOUR CRDS REFERENCE FILE DIR>` string with the appropriate path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-tradition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is for ensuring you have a valid \"lref\" directory of reference files.\n",
    "if not os.environ.get('lref'):\n",
    "    if os.path.exists('/grp/hst/cdbs/lref/'):  # If on STScI Network/VPN\n",
    "        os.environ['lref'] = '/grp/hst/cdbs/lref/'\n",
    "        print(\"It looks like you are probably on the STScI network; setting lref to '/grp/hst/cdbs/lref/'\")\n",
    "    else:  # If not on STScI Network/VPN\n",
    "        # PLEASE EDIT THIS PATH\n",
    "        os.environ['lref'] = '<PATH TO YOUR CRDS REFERENCE FILE DIR>'\n",
    "        if not os.path.exists(os.environ['lref']):  # Check if that path exists\n",
    "            print(\"It doesn't look like that's a valid path. Deleting it.\")\n",
    "            del os.environ['lref']  # delete this nonexistant path\n",
    "else:\n",
    "    found_lref = Path(os.environ.get('lref'))\n",
    "    print(f\"You already have an lref path in your environment variables -\\\n",
    " It's {found_lref}\\n\")\n",
    "\n",
    "assert os.path.exists(os.environ['lref']), f\"The path to your lref directory is invalid ({os.environ['lref']})\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-volleyball",
   "metadata": {},
   "source": [
    "**We can now run the pipeline on each of our new sub-exposure files to create processed spectra based on data taken in the three time periods.**\n",
    "\n",
    "*Note* that the cell below may take several minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-operator",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split_corrtag in spec_outlist:  # When we run CalCOS on corrtags, we must go 1-by-1\n",
    "    # Define epoch as which chunk of the initial exposure. epoch 2 contains the transit.\n",
    "    epoch_number = os.path.basename(split_corrtag).split('_')[1]\n",
    "    print(f\"Extracting file {split_corrtag} using CalCOS\")\n",
    "    # Make a sub-directory of output/calcos/ named for each epoch:\n",
    "    cal_output_dir = f'./output/calcos/epoch{epoch_number}/'\n",
    "    os.makedirs(cal_output_dir, exist_ok=True)\n",
    "    # Extract the spectrum from each of the sub-exposures:\n",
    "    calcos.calcos(split_corrtag, outdir=cal_output_dir, verbosity=0)\n",
    "# Print a message at the end to let us know it's finished:\n",
    "print(\"Done running the pipeline.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-youth",
   "metadata": {},
   "source": [
    "**Now, we can examine our newly processed spectra**\n",
    "\n",
    "We first examine the entire spectrum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-thousand",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the `x1d` files:\n",
    "processed_files = sorted(glob.glob('output/calcos/epoch*/*x1d.fits'))\n",
    "\n",
    "# Set up figure\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "for i, pfile in enumerate(processed_files):  # Loop through\n",
    "    epoch_label = pfile.split('/')[2]\n",
    "    if \"2\" in epoch_label: # Mark the transit\n",
    "        epoch_label += \" (transit)\"\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore', category=UnitsWarning, append=True)\n",
    "        w, f, ferr, dq = Table.read(\n",
    "            pfile)[0]['WAVELENGTH', 'FLUX', 'ERROR', 'DQ']\n",
    "    dq_mask = np.where(dq == 0) # filter to good quality data\n",
    "    w, f, ferr = w[dq_mask], f[dq_mask], ferr[dq_mask]\n",
    "    plt.plot(w, f,  # Plot each epoch\n",
    "             # Epoch2 should stand out\n",
    "             alpha=[0.5, 1, 0.5][i], c=['C0', 'k', 'c'][i],\n",
    "             label=epoch_label)  # Label with the epoch name\n",
    "# Format plot\n",
    "plt.ylim(-3E-15, 5E-14)\n",
    "plt.title(\"Fig 3.1\\nComparison of processed spectra\", size=22)\n",
    "plt.xlabel(\"Wavelength [$\\AA$]\", size=14)\n",
    "plt.ylabel(\"Flux [$ergs\\ cm^{-2} \\AA^{-1}s^{-1}$]\", size=14)\n",
    "plt.legend()\n",
    "plt.savefig(plots_dir / f\"Compare_spectrum.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-encounter",
   "metadata": {},
   "source": [
    "Now we can take a closer look at two spectral regions the region from 1200 - 1230 and from 1250 - 1350 Angstroms.\n",
    "In the first region, we see the 1215 Angstrom Lyman-alpha line, much of which is [generated by geocoronal emission](https://www.stsci.edu/hst/instrumentation/cos/calibration/airglow). At this line, the flux of the the three epochs is very similar, because the transit in the IY UMa system has no effect on Earth's atmosphere. There are slight differences because the sun's changing position in the sky changes the geocoronal glow. This causes the third sub-exposure to have a slightly higher Lyman-alpha line. However these are small differences compared to the flux of these lines.\n",
    "\n",
    "For this and the following plots, we will plot the errors as well, to see if the apparent differences in flux between epochs are significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe335ef1-1c22-49d6-ac28-7d326a36ec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up figure\n",
    "fig, (ax0, ax1) = plt.subplots(2, 1, figsize=(12, 16), sharex=True)\n",
    "\n",
    "for i, pfile in enumerate(processed_files):\n",
    "    epoch_label = pfile.split('/')[2]\n",
    "    if \"2\" in epoch_label:\n",
    "        epoch_label += \" (transit)\"\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore', category=UnitsWarning, append=True)\n",
    "        w, f, ferr, dq = Table.read(\n",
    "            pfile)[0]['WAVELENGTH', 'FLUX', 'ERROR', 'DQ']\n",
    "    dq_mask = np.where(dq == 0)\n",
    "    # filter to good quality data\n",
    "    w, f, ferr = w[dq_mask], f[dq_mask], ferr[dq_mask]\n",
    "\n",
    "    ax0.plot(w, f,  # Plot each epoch\n",
    "             alpha=[0.5, 1, 0.5][i],  # Epoch2 should stand out\n",
    "             c=['C0', 'k', 'c'][i], linestyle='-',\n",
    "             label=epoch_label)  # Label with the epoch name\n",
    "\n",
    "    ax1.errorbar(w, f, yerr=ferr,  # Plot each epoch\n",
    "                 alpha=[0.5, 1, 0.5][i],  # Epoch2 should stand out\n",
    "                 marker='.', markerfacecolor=['C0', 'r', 'c'][i],\n",
    "                 linestyle='', ecolor=['C0', 'k', 'c'][i],\n",
    "                 label=epoch_label)  # Label with the epoch name\n",
    "\n",
    "    # Format both subplots\n",
    "ax0.set_xlim(1200, 1230)\n",
    "ax0.set_ylim(0, 1.1E-13)\n",
    "ax1.set_ylim(0, 1.1E-13)\n",
    "\n",
    "ax0.set_title(\"Top: Simple plot\", fontsize=16)\n",
    "ax1.set_title(\"Bottom: Errorbar plot\", fontsize=16)\n",
    "plt.suptitle(\n",
    "    \"Fig 3.2\\nComparison of processed spectra - Zoom on atmospheric line\",\n",
    "    size=24\n",
    ")\n",
    "ax1.set_xlabel(\"Wavelength [$\\AA$]\", size=16)\n",
    "ax0.set_ylabel(\"Flux [$ergs\\ cm^{-2} \\AA^{-1}s^{-1}$]\", size=16)\n",
    "ax1.set_ylabel(\"Flux [$ergs\\ cm^{-2} \\AA^{-1}s^{-1}$]\", size=16)\n",
    "ax0.legend()\n",
    "ax1.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(plots_dir / f\"Compare_spectrum_zoom_1215A.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-disease",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up figure\n",
    "fig, (ax0, ax1) = plt.subplots(2, 1, figsize=(12, 16), sharex=True)\n",
    "\n",
    "for i, pfile in enumerate(processed_files):\n",
    "    epoch_label = pfile.split('/')[2]\n",
    "    if \"2\" in epoch_label:\n",
    "        epoch_label += \" (transit)\"\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore', category=UnitsWarning, append=True)\n",
    "        w, f, ferr, dq = Table.read(\n",
    "            pfile)[0]['WAVELENGTH', 'FLUX', 'ERROR', 'DQ']\n",
    "    dq_mask = np.where(dq == 0)\n",
    "    # filter to good quality data\n",
    "    w, f, ferr = w[dq_mask], f[dq_mask], ferr[dq_mask]\n",
    "\n",
    "    ax0.plot(w, f,  # Plot each epoch\n",
    "             alpha=[0.5, 1, 0.5][i],  # Epoch2 should stand out\n",
    "             c=['C0', 'k', 'c'][i], linestyle='-',\n",
    "             label=epoch_label)  # Label with the epoch name\n",
    "\n",
    "    ax1.errorbar(w, f, yerr=ferr,  # Plot each epoch\n",
    "                 alpha=[0.5, 1, 0.5][i],  # Epoch2 should stand out\n",
    "                 marker='.', markerfacecolor=['C0', 'r', 'c'][i],\n",
    "                 linestyle='', ecolor=['C0', 'k', 'c'][i],\n",
    "                 label=epoch_label)  # Label with the epoch name\n",
    "\n",
    "# Format both subplots\n",
    "ax0.set_xlim(1250, 1350)  # Zoom to 1250-1350 Angstrom\n",
    "ax1.set_xlim(1250, 1350)\n",
    "ax0.set_ylim(-5.E-16, 1.1E-14)\n",
    "ax1.set_ylim(-5.E-16, 1.1E-14)\n",
    "\n",
    "ax0.set_title(\"Top: Simple plot\", fontsize=16)\n",
    "ax1.set_title(\"Bottom: Errorbar plot\", fontsize=16)\n",
    "plt.suptitle(\n",
    "    \"Fig 3.3\\nComparison of processed spectra - Zoom on source spectrum\",\n",
    "    size=24\n",
    ")\n",
    "ax1.set_xlabel(\"Wavelength [$\\AA$]\", size=16)\n",
    "ax0.set_ylabel(\"Flux [$ergs\\ cm^{-2} \\AA^{-1}s^{-1}$]\", size=16)\n",
    "ax1.set_ylabel(\"Flux [$ergs\\ cm^{-2} \\AA^{-1}s^{-1}$]\", size=16)\n",
    "ax0.legend()\n",
    "ax1.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(plots_dir / f\"Compare_spectrum_zoom.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premium-mileage",
   "metadata": {},
   "source": [
    "Examining Fig 3.3, we first notice that the very low number of counts in a given wavelength region has limited our spectra's precision. This is especially evidenced by how epoch 2's flux is visibly quantized to several values, corresponding with the very low numbers of counted photons in each wavelength bin.\n",
    "\n",
    "However, we can still detect a significant change in the spectrum during the transit, with certain spectral features absent or suppressed while the transit occurs. During the transit, COS receives almost no photons coming from the source at these spectral features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9873cc-0b30-415d-ad94-69f13d4fb9fc",
   "metadata": {},
   "source": [
    "### Exercise 2: *Examining epoch 1.5*\n",
    "\n",
    "From Exercise 1, you have an additional epoch, from 450-550 seconds, which overlaps with the end of epoch 1, and has a flux between epoch 1 and epoch 2.\n",
    "\n",
    "We wish to know whether the data taken during epoch 1.5 more closely aligns with that during epoch 1 or 2. To analyze this,\n",
    "\n",
    "* **2.1:** Run epoch 1.5's data through `CalCOS`\n",
    "\n",
    "* **2.2:** Plot epoch 1.5 alongside epochs 1 and 2 in the wavelength range around 1275 Å (*i.e. recreate Fig. 3.2 without epoch 3 and with epoch 1.5*).\n",
    "\n",
    "* **2.3:** Briefly analyze whether epoch 1.5 is more in line with epoch 1 or 2, and consider how this knowledge may be useful. Consider whether our approach here to answering this question has any major flaws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cd696c-17fd-4474-b924-a0930e9ac162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fc68ab-daf5-4dc9-96ba-fb2ced7601d1",
   "metadata": {},
   "source": [
    "**This is certainly not an exhaustive analysis,** and we do not claim in this Notebook to have made any measurements confirming or quantifying a transit.\n",
    "\n",
    "However, you should now be equipped to use the `splittag` tool to subdivide exposures to look for time-variable phenomena."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a449c079-d100-42fe-bc67-4ee2d3cfe887",
   "metadata": {},
   "source": [
    "## Congratulations! You finished this Notebook!\n",
    "<font size=\"5\">There are more COS data walkthrough Notebooks on different topics. You can find them <a href=\"https://spacetelescope.github.io/COS-Notebooks/\">here</a>.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3033bd6-e035-4899-ac57-f84002a6df14",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## About this Notebook\n",
    "**Author:** Nat Kerman: <nkerman@stsci.edu>\n",
    "\n",
    "**Contributors:** This Notebook drew from a previously existing [Notebook written by Justin Ely](https://github.com/justincely/AAS224/blob/master/splittag_tutorial.ipynb).\n",
    "\n",
    "**Updated On:** 2022-01-04\n",
    "\n",
    "\n",
    "> *This tutorial was generated to be in compliance with the [STScI style guides](https://github.com/spacetelescope/style-guides) and would like to cite the [Jupyter guide](https://github.com/spacetelescope/style-guides/blob/master/templates/example_notebook.ipynb) in particular.*\n",
    "## Citations\n",
    "\n",
    "If you use `astropy`, `matplotlib`, `astroquery`, or `numpy` for published research, please cite the\n",
    "authors. Follow these links for more information about citations:\n",
    "\n",
    "* [Citing `numpy`](https://numpy.org/citing-numpy/)\n",
    "* [Citing `astropy`](https://www.astropy.org/acknowledging.html)\n",
    "* [Citing `matplotlib`](https://matplotlib.org/3.4.3/citing.html)\n",
    "* [Citing `astroquery`](https://astroquery.readthedocs.io/en/latest/)\n",
    "\n",
    "---\n",
    "\n",
    "[Top of Page](#topSp)\n",
    "<img style=\"float: right;\" src=\"https://raw.githubusercontent.com/spacetelescope/notebooks/master/assets/stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"Space Telescope Logo\" width=\"200px\"/> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccfc54b-b0da-4cba-a8a6-48efbbfbb2df",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e46357-cee7-4b0f-8aea-49aa3986db59",
   "metadata": {},
   "source": [
    "# Exercise Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1350abec-07dd-4529-bba7-249631eca9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1:\n",
    "\n",
    "# Make the folder in which to store the newly split corrtag files:\n",
    "spec_int_dir2 = output_dir / 'spec_intervals_Ex1'\n",
    "# A second output directory for files split on specified intervals\n",
    "spec_int_dir2.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "# List the specified times\n",
    "split_list = [0, 450, 550, 1337]\n",
    "# Run splittag using our specified times:\n",
    "splittag.splittag(infiles=transit_exp,\n",
    "                  outroot=spec_int_dir2 / 'transit_basename',\n",
    "                  time_list=split_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be624d09-be8e-459a-bd5f-e9047810a737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2.1 (CalCOS):\n",
    "\n",
    "# Make a sub-directory of output/calcos/ named for this epoch.\n",
    "# We'll call the epoch \"1.5\" because it's between epochs 1 and 2\n",
    "cal_output_dir = Path('./output/calcos/epoch1.5/')\n",
    "cal_output_dir.mkdir(exist_ok=True)\n",
    "# Extract the spectrum from the 2nd sub-exposure in spec_intervals_Ex1:\n",
    "calcos.calcos(\n",
    "    'output/spec_intervals_Ex1/transit_basename_2_corrtag_a.fits',\n",
    "    outdir=cal_output_dir, verbosity=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385b2234-ad94-4f9f-a457-c147f62902c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2.2 (Plotting):\n",
    "\n",
    "# Set up figure\n",
    "fig, (ax0, ax1) = plt.subplots(2, 1, figsize=(12, 16), sharex=True)\n",
    "\n",
    "processed_files = [  # Specify the files explicitly here\n",
    "    'output/calcos/epoch1/lc1va0zgq_1_x1d.fits',\n",
    "    'output/calcos/epoch1.5/transit_basename_2_x1d.fits',\n",
    "    'output/calcos/epoch2/lc1va0zgq_2_x1d.fits',\n",
    "]\n",
    "\n",
    "for i, pfile in enumerate(processed_files):\n",
    "    epoch_label = pfile.split('/')[2]\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore', category=UnitsWarning, append=True)\n",
    "        w, f, ferr, dq = Table.read(\n",
    "            pfile)[0]['WAVELENGTH', 'FLUX', 'ERROR', 'DQ']\n",
    "    dq_mask = np.where(dq == 0)\n",
    "    # filter to good quality data\n",
    "    w, f, ferr = w[dq_mask], f[dq_mask], ferr[dq_mask]\n",
    "\n",
    "    ax0.scatter(w, f,  # Plot each epoch\n",
    "                alpha=[0.5, 1, 0.5][i],  # Epoch 2 should stand out\n",
    "                c=['C0', 'k', 'c'][i], linestyle='-',\n",
    "                label=epoch_label)  # Label with the epoch name\n",
    "\n",
    "    ax1.errorbar(w, f, yerr=ferr,  # Plot each epoch\n",
    "                 alpha=[0.5, 1, 0.5][i],  # Epoch 2 should stand out\n",
    "                 marker='.', markerfacecolor=['C0', 'r', 'c'][i],\n",
    "                 linestyle='', ecolor=['C0', 'k', 'c'][i],\n",
    "                 label=epoch_label)  # Label with the epoch name\n",
    "\n",
    "# Format both subplots\n",
    "ax0.set_xlim(1250, 1300)  # Zoom to 1225 - 1300 Angstrom\n",
    "ax1.set_xlim(1250, 1300)\n",
    "ax0.set_ylim(-5.E-16, 1.1E-14)\n",
    "ax1.set_ylim(-5.E-16, 1.1E-14)\n",
    "\n",
    "ax0.set_title(\"Top: Simple plot\", fontsize=16)\n",
    "ax1.set_title(\"Bottom: Errorbar plot\", fontsize=16)\n",
    "plt.suptitle(\n",
    "    \"Fig Ex2.1\\nComparison of processed spectra - Zoom on source spectrum\",\n",
    "    size=24\n",
    ")\n",
    "ax1.set_xlabel(\"Wavelength [$\\AA$]\", size=16)\n",
    "ax0.set_ylabel(\"Flux [$ergs\\ cm^{-2} \\AA^{-1}s^{-1}$]\", size=16)\n",
    "ax1.set_ylabel(\"Flux [$ergs\\ cm^{-2} \\AA^{-1}s^{-1}$]\", size=16)\n",
    "ax0.legend()\n",
    "ax1.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    plots_dir / f\"Compare_spectrum_zoom_1275A_Ex2.png\",\n",
    "    dpi=200\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90725b3-80b6-4808-a697-5600a2c2bd05",
   "metadata": {},
   "source": [
    "**Ex 2.3 (Analysis):**\n",
    "\n",
    "From a brief look, it seems that epoch 1.5 shares much more in common with epoch 1 (before the transit) than epoch 2 (during the transit).\n",
    "\n",
    "If we wished to get as good a signal to noise ratio observation of the pre-transit spectrum as possible, we might include epochs 1 and 1.5 together to get additional counts.\n",
    "\n",
    "Note that epoch 1 contains all the counts from epoch 1.5, while epoch 2 does not. Thus this is not a perfect test. However, the vast majority of epoch 1's counts do *not* overlap with epoch 1.5 (see fig  2.1), so this is an acceptable \"first pass\" test. It's also possible that the very low number of counts, especially in epochs 1.5 and 2, does not give us the signal-to-noise we would need to accurately distinguish the epochs."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e5784b3e3be4ffa319eb7c9e4ac489bbbf191ad109372c471204ed1d5c08c61e"
  },
  "kernelspec": {
   "display_name": "Python [conda env:astroconda_plhst_20210505_2] *",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "nbdime-conflicts": {
   "local_diff": [
    {
     "key": "interpreter",
     "op": "add",
     "value": {
      "hash": "e5784b3e3be4ffa319eb7c9e4ac489bbbf191ad109372c471204ed1d5c08c61e"
     }
    },
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "Python 3.9.5 64-bit ('fs2': conda)"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "display_name",
       "op": "patch"
      }
     ],
     "key": "kernelspec",
     "op": "patch"
    }
   ],
   "remote_diff": [
    {
     "key": "interpreter",
     "op": "add",
     "value": {
      "hash": "3037da8978cba1718d73cdc7fb7405da77d21edae646379a1752e6ecf16f8330"
     }
    },
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "Python 3.8.3 64-bit ('base': conda)"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "display_name",
       "op": "patch"
      }
     ],
     "key": "kernelspec",
     "op": "patch"
    }
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
